{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $n=1,...,N$,\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$Z_n \\sim N(0,\\tau^2)$\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$Y_{n,t} \\sim \\text{Bernoulli}\\left(\\frac{1}{1+\\exp(- Z_n - \\beta_0 - \\beta^T x_{n,t})}\\right)$\n",
    "<br>\n",
    "for $t=1, ..., T$. This model carries out dimentionality reduction of binary observations $y_{n,k}$'s. Here, the dimention of $\\beta$ and $x_{n,t}$ is $D$.<br>\n",
    "As variational approximation of the posterior $p(z_n|y_n)$, we use $q(z_n)= N(z_n;\\mu_n, \\sigma_n^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We do not consider the use of Renyi divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import bernoulli, norm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_float_type = tf.float64\n",
    "np_float_type = np.float64\n",
    "as_tf_float = lambda x: tf.cast(x, tf_float_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_logsumexp(ary, axis=1, keepdims=False):\n",
    "    return tf.math.reduce_logsumexp(ary, axis=axis, keepdims=keepdims)\n",
    "\n",
    "def tf_logmeanexp(ary, axis=1, keepdims=False):\n",
    "    return tf.math.reduce_logsumexp(ary, axis=axis, keepdims=keepdims) \\\n",
    "        - tf.math.log(as_tf_float(ary.shape[axis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x:1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "D = 3\n",
    "T = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "# We assume that we have infinite amount of data.\n",
    "# Thus, generator of the data is implemented.\n",
    "def generate_data(N, D, T, beta0, beta, ln_tau):\n",
    "    z = np.random.randn(N) * np.exp(ln_tau)\n",
    "    x = np.random.randn(N*T*D).reshape([N,T,D])\n",
    "    y = bernoulli(p=sigmoid(beta0+x@beta+z.reshape([N,1]))).rvs()\n",
    "    return x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramters\n",
    "ln_tau = np.float64(0.7)\n",
    "beta0 = np.float64(0.)\n",
    "beta  = np.random.randn(D) / np.sqrt(D)\n",
    "param0 = {\n",
    "    'ln_tau': ln_tau,\n",
    "    'beta0': float(beta0),\n",
    "    'beta': beta\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y,z = generate_data(N, D, T, beta0, beta, ln_tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Normal Integral Approximation of Evidence\n",
    "\n",
    "Ref: Barber Bishop(1998), PRML(2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_normal_prob(x, beta0, beta, ln_tau):\n",
    "    N, T, D  = x.shape\n",
    "    kappa = 1 / (1 + np.pi*tf.exp(ln_tau*2)/8)**(1/2)\n",
    "    return tf.math.sigmoid( kappa * (beta0 + tf.reshape( x@tf.reshape(beta, [D,1]), [N, T])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_normal_likelihood(x, y, beta0, beta, ln_tau):\n",
    "    pred_prob = sigmoid_normal_prob(x, beta0, beta, ln_tau)\n",
    "    score = tf.reduce_mean(tf.reduce_sum(\n",
    "        tf.math.log(pred_prob)*y + tf.math.log(1-pred_prob)*(1-y), \n",
    "        axis=1))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Approximation of Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_approx(x, y, beta0, beta, ln_tau):\n",
    "    N, T, D  = x.shape\n",
    "    z = np.zeros([N, 1])\n",
    "    _sig = lambda z: sigmoid( z + beta0 + x@beta )\n",
    "    for i in range(10):\n",
    "        sig = _sig(z)\n",
    "        hessian = 1/np.exp(ln_tau*2) + np.sum( sig*(1-sig), axis=1, keepdims=True)\n",
    "        grad    = z/np.exp(ln_tau*2) + np.sum( sig - y,     axis=1, keepdims=True)\n",
    "        z -= grad / hessian\n",
    "    mu = z.reshape([N])\n",
    "    sigma = (1 / hessian).reshape([N])**(1/2)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.7493583685054985, 1.8282650456550973)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.var(), (z-mu).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IWELBO approximation of Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma):\n",
    "    \"\"\"\n",
    "    Compute IWELBOs for i = 1,...,n using n_MC samples Zn. \n",
    "    Here, we assume that n<N where N is the size of data.\n",
    "    \n",
    "    Arguments:\n",
    "    x: 3-d array of size [N, T, D]\n",
    "    y: 2-d array of size [N, T]\n",
    "    z: 1-d array of size [n_MC, N]\n",
    "    beta: 1-d array of size [D]\n",
    "    mu: 1-d array of [N]\n",
    "    sigma**2: 1-d array of [N]\n",
    "    \n",
    "    Returns:\n",
    "    iwelbo: iwelbo, whose size is [N]\n",
    "    \"\"\"\n",
    "\n",
    "    (N, T, D), (n_MC, n) = x.shape, z.shape\n",
    "    y = np.float64( y.reshape([1,N,T]) )\n",
    "    mu = mu.reshape([1,N])\n",
    "    sigma = sigma.reshape([1,N])\n",
    "    \n",
    "    y_logits = tf.convert_to_tensor( beta0\\\n",
    "                                    + tf.reshape( x@tf.reshape(beta, [D,1]), [1, N, T])\\\n",
    "                                    + tf.reshape(z, [n_MC, N, 1]) \n",
    "                                   )\n",
    "    p_y = tfp.distributions.Bernoulli(logits=y_logits)\n",
    "    p_z = tfp.distributions.Normal(loc=np.zeros([1, N]), scale=tf.exp(ln_tau))\n",
    "    q_z = tfp.distributions.Normal(loc=mu, scale=sigma)\n",
    "    \n",
    "    log_prob_ratio = \\\n",
    "        tf.reduce_sum( p_y.log_prob(y), axis=2)\\\n",
    "        + p_z.log_prob(z)\\\n",
    "        - q_z.log_prob(z)\n",
    "    \n",
    "    iwelbo = tf_logmeanexp(log_prob_ratio, axis=0)\n",
    "    return iwelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC):\n",
    "    N, = mu.shape\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    iwelbo = tf.reduce_mean( pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma) )\n",
    "    return iwelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "signorm_likelihood = sigmoid_normal_likelihood(x, y, beta0, beta, ln_tau).numpy()\n",
    "elbo_likelihood = IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=1).numpy()\n",
    "iwelbo_likelihood = IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=64).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3203896752599162, -1.2723016180869178, -1.253648532390383)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signorm_likelihood, elbo_likelihood, iwelbo_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood by Different Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orthogonalize the covariate with z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training signorm...\n",
      "#iter: 0,\tloss: 1.3862943611198932\n",
      "#iter: 50,\tloss: 1.3151852548766374\n",
      "#iter: 100,\tloss: 1.3137125645426742\n",
      "#iter: 150,\tloss: 1.324545748930499\n",
      "#iter: 200,\tloss: 1.3141075942885732\n",
      "#iter: 250,\tloss: 1.315122492975311\n",
      "#iter: 300,\tloss: 1.3310153518960433\n",
      "#iter: 350,\tloss: 1.345113408896049\n",
      "#iter: 400,\tloss: 1.3194260500563697\n",
      "#iter: 450,\tloss: 1.3225143219234416\n",
      "#iter: 500,\tloss: 1.3236479859736694\n",
      "\n",
      "training elbo...\n",
      "#iter: 0,\tloss: 1.3415605333790197\n",
      "#iter: 50,\tloss: 1.2731602254332437\n",
      "#iter: 100,\tloss: 1.285275571297805\n",
      "#iter: 150,\tloss: 1.2788582109802928\n",
      "#iter: 200,\tloss: 1.2661287597939659\n",
      "#iter: 250,\tloss: 1.2706540211617823\n",
      "#iter: 300,\tloss: 1.2801926866140747\n",
      "#iter: 350,\tloss: 1.2943098665864323\n",
      "#iter: 400,\tloss: 1.2885737504799528\n",
      "#iter: 450,\tloss: 1.2848891639091862\n",
      "#iter: 500,\tloss: 1.279308153718729\n",
      "\n",
      "training iwelbo...\n",
      "#iter: 0,\tloss: 1.3360464222864787\n",
      "#iter: 50,\tloss: 1.274962587998346\n",
      "#iter: 100,\tloss: 1.2680590053145462\n",
      "#iter: 150,\tloss: 1.2523877915008317\n",
      "#iter: 200,\tloss: 1.233153303363013\n",
      "#iter: 250,\tloss: 1.2233180585172476\n",
      "#iter: 300,\tloss: 1.2462902500801734\n",
      "#iter: 350,\tloss: 1.2684662869553407\n",
      "#iter: 400,\tloss: 1.2703265301806512\n",
      "#iter: 450,\tloss: 1.2676884404827233\n",
      "#iter: 500,\tloss: 1.268964798480711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "objectives = {\n",
    "    \"signorm\": lambda beta0, beta, ln_tau, mu, sigma: sigmoid_normal_likelihood(x, y, beta0, beta, ln_tau),\n",
    "    \"elbo\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=1),\n",
    "    \"iwelbo\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=64)\n",
    "}\n",
    "params = {\"ground_truth\": param0}\n",
    "\n",
    "N,T,D = 1000, 2, 3\n",
    "\n",
    "for obj_name, obj_func in objectives.items():\n",
    "    \n",
    "    print(\"training {}...\".format(obj_name))\n",
    "    \n",
    "    beta0_ = tf.Variable(0, dtype=tf.float64)\n",
    "    beta_  = tf.Variable(np.zeros([D]), dtype=tf.float64)\n",
    "    ln_tau_   = tf.Variable(0, dtype=tf.float64)\n",
    "\n",
    "    for t in range(501):\n",
    "        \n",
    "        rho_t = 0.4/(1+t)**0.6\n",
    "        x,y,z = generate_data(N, D, T, beta0, beta, ln_tau)\n",
    "\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch([beta0_, beta_, ln_tau_])\n",
    "            mu, sigma = laplace_approx(x, y, beta0_.numpy(), beta_.numpy(), ln_tau_.numpy())\n",
    "            score = obj_func(beta0_, beta_, ln_tau_, mu, sigma)\n",
    "        dbeta0_, dbeta_, dln_tau_ = g.gradient(score, [beta0_, beta_, ln_tau_])\n",
    "\n",
    "        beta0_ = beta0_ + rho_t*dbeta0_\n",
    "        beta_ = beta_ + rho_t*dbeta_\n",
    "        ln_tau_ = ln_tau_ + dln_tau_\n",
    "        if t%50==0:\n",
    "            print(\"#iter: {},\\tloss: {}\".format(t, -score.numpy()))\n",
    "    \n",
    "    params[obj_name] = {\n",
    "        'ln_tau': ln_tau_.numpy(),\n",
    "        'beta0': beta0_.numpy(),\n",
    "        'beta': beta_.numpy()\n",
    "    }\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ground_truth': {'ln_tau': 0.7,\n",
       "  'beta0': 0.0,\n",
       "  'beta': array([ 0.75288457, -0.37000288, -0.09201359])},\n",
       " 'signorm': {'ln_tau': -0.5859231970542182,\n",
       "  'beta0': -0.0023429182295627475,\n",
       "  'beta': array([ 0.48663008, -0.23394813, -0.05818374])},\n",
       " 'elbo': {'ln_tau': -0.09090616029911061,\n",
       "  'beta0': 0.0013032877725931912,\n",
       "  'beta': array([ 0.54273325, -0.26712958, -0.06530728])},\n",
       " 'iwelbo': {'ln_tau': 0.598227501316516,\n",
       "  'beta0': 0.0017900352768665106,\n",
       "  'beta': array([ 0.64130361, -0.318238  , -0.07404593])}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottom Line: IWELBO gives better estiamte than elbo or sigmoid normal integral approximation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLMC codition check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma):\n",
    "    \n",
    "    (N, T, D), (n_MC, N) = x.shape, z.shape\n",
    "    assert np.log2(n_MC)%1==0\n",
    "    \n",
    "    if n_MC == 1:\n",
    "        scores = pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma)\n",
    "    else:\n",
    "        scores = pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma)\n",
    "        scores -= (1/2.) * pointwise_IWELBO(x, y, z[:n_MC//2 ], beta0, beta, ln_tau, mu, sigma)\n",
    "        scores -= (1/2.) * pointwise_IWELBO(x, y, z[ n_MC//2:], beta0, beta, ln_tau, mu, sigma)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level):\n",
    "    \n",
    "    N, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    \n",
    "    diwelbo = tf.reduce_mean( pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma) )\n",
    "    return diwelbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=8, start_level=0):\n",
    "    \n",
    "    N, T, D = x.shape\n",
    "\n",
    "    levels = np.arange(start_level, max_level+1)\n",
    "    weights = 2.**(-3/2*levels)\n",
    "    weights /= sum(weights)\n",
    "    Ns = np.zeros_like(levels)\n",
    "    Ns = np.array([np.math.ceil(w*N) for w in weights], dtype=np.int)\n",
    "    Ns[0] = N - sum(Ns[1:])\n",
    "    \n",
    "    N_offset = 0\n",
    "    score = 0\n",
    "    for i, l in enumerate(levels):\n",
    "        x_tmp = x[N_offset:N_offset+Ns[i]]\n",
    "        y_tmp = y[N_offset:N_offset+Ns[i]]\n",
    "        mu_tmp = mu[N_offset:N_offset+Ns[i]]\n",
    "        sigma_tmp = sigma[N_offset:N_offset+Ns[i]]\n",
    "        \n",
    "        score += dIWELBO(x_tmp, y_tmp, beta0, beta, ln_tau, mu_tmp, sigma_tmp, level=l)\n",
    "        N_offset += Ns[i]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-1.2732106991752004>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=10, start_level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_stats_dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level=1):\n",
    "    \n",
    "    N, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    \n",
    "    diwelbos = pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma).numpy()\n",
    "    mean_diwelbo = diwelbos.mean()\n",
    "    mean_abs_diwelbo = np.mean(np.abs(diwelbos))\n",
    "    var_diwelbo = diwelbos.var()\n",
    "    \n",
    "    iwelbos = pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma).numpy()\n",
    "    var_iwelbo = iwelbos.var()\n",
    "    \n",
    "    return {'mean_dIWELBO':mean_diwelbo, \n",
    "            'mean_abs_dIWELBO':mean_abs_diwelbo, \n",
    "            'var_dIWELBO':var_diwelbo, \n",
    "            'var_IWELBO':var_iwelbo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv_stats = [conv_stats_dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level=l) for l in range(10)]\n",
    "conv_stats = pd.DataFrame(conv_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(conv_stats[['mean_abs_dIWELBO', 'var_dIWELBO', 'var_IWELBO']])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_dIWELBO</th>\n",
       "      <th>mean_abs_dIWELBO</th>\n",
       "      <th>var_dIWELBO</th>\n",
       "      <th>var_IWELBO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.307070</td>\n",
       "      <td>1.317098</td>\n",
       "      <td>3.044348e-01</td>\n",
       "      <td>0.304435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012357</td>\n",
       "      <td>0.012357</td>\n",
       "      <td>1.167473e-03</td>\n",
       "      <td>0.266922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009924</td>\n",
       "      <td>0.009924</td>\n",
       "      <td>9.748743e-04</td>\n",
       "      <td>0.263227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006704</td>\n",
       "      <td>0.006704</td>\n",
       "      <td>5.076918e-04</td>\n",
       "      <td>0.257265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>8.514586e-05</td>\n",
       "      <td>0.249079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>1.002712e-04</td>\n",
       "      <td>0.248546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>7.926358e-05</td>\n",
       "      <td>0.244455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>6.459834e-06</td>\n",
       "      <td>0.243008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>2.365271e-06</td>\n",
       "      <td>0.243970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>6.953756e-07</td>\n",
       "      <td>0.242552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_dIWELBO  mean_abs_dIWELBO   var_dIWELBO  var_IWELBO\n",
       "0     -1.307070          1.317098  3.044348e-01    0.304435\n",
       "1      0.012357          0.012357  1.167473e-03    0.266922\n",
       "2      0.009924          0.009924  9.748743e-04    0.263227\n",
       "3      0.006704          0.006704  5.076918e-04    0.257265\n",
       "4      0.003567          0.003567  8.514586e-05    0.249079\n",
       "5      0.002643          0.002643  1.002712e-04    0.248546\n",
       "6      0.001826          0.001826  7.926358e-05    0.244455\n",
       "7      0.000823          0.000823  6.459834e-06    0.243008\n",
       "8      0.000429          0.000429  2.365271e-06    0.243970\n",
       "9      0.000265          0.000265  6.953756e-07    0.242552"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMC_ests = []\n",
    "MLMC_ests = []\n",
    "for i in range(10):\n",
    "    x,y,z_ = generate_data(N=200000, D=3, T=2, beta0=beta0, beta=beta, ln_tau=ln_tau)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)\n",
    "    NMC_ests.append( IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=16).numpy() )\n",
    "    MLMC_ests.append( IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=4, start_level=0).numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std-div of NMC estimator:   0.0011831697569174653\n",
      "std-div of MLMC estimator:  0.0017923629487936628\n"
     ]
    }
   ],
   "source": [
    "print(\"std-div of NMC estimator:  \", np.std(NMC_ests))\n",
    "print(\"std-div of MLMC estimator: \", np.std(MLMC_ests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.31 s ± 5.23 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 ms ± 520 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=6, start_level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For finding nice configuration where MLMC wins NMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030590823453341444 2.294868449800949\n",
      "0.4758576083976454 2.0176034291489637\n"
     ]
    }
   ],
   "source": [
    "N,_ = y.shape\n",
    "n_MC = 2\n",
    "z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "\n",
    "diwelbos = pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma).numpy()\n",
    "score1 = np.var(NMC_ests) / diwelbos.mean()**2\n",
    "score2 = np.var(MLMC_ests) / np.var(NMC_ests)\n",
    "print(score1, score2)\n",
    "\n",
    "print(np.std(x@beta, axis=1).mean(), z_.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
