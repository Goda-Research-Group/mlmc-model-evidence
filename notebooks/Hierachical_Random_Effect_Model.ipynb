{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $n=1,...,N$,\n",
    "\\begin{align}\n",
    "Z_n &\\sim N(0,\\tau^2)\\\\ \n",
    "Y_{n,t} &\\sim \\text{Bernoulli}\\left(\\frac{1}{1+\\exp(- Z_n - \\beta_0 - \\beta^T x_{n,t})}\\right)\n",
    "\\end{align}\n",
    "for $t=1, ..., T$. This model carries out dimentionality reduction of binary observations $y_{n,k}$'s. Here, the dimention of $\\beta$ and $x_{n,t}$ is $D$.<br>\n",
    "As variational approximation of the posterior $p(z_n|y_n)$, we use $q(z_n)= N(z_n;\\mu_n, \\sigma_n^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We do not consider the use of Renyi divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import bernoulli, norm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_float_type = tf.float64\n",
    "np_float_type = np.float64\n",
    "as_tf_float = lambda x: tf.cast(x, tf_float_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_logsumexp(ary, axis=1, keepdims=False):\n",
    "    return tf.math.reduce_logsumexp(ary, axis=axis, keepdims=keepdims)\n",
    "\n",
    "def tf_logmeanexp(ary, axis=1, keepdims=False):\n",
    "    return tf.math.reduce_logsumexp(ary, axis=axis, keepdims=keepdims) \\\n",
    "        - tf.math.log(as_tf_float(ary.shape[axis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x:1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramters\n",
    "ln_tau = np.float64(0.7)\n",
    "beta0 = np.float64(0.)\n",
    "beta  = np.random.randn(D) / np.sqrt(D)\n",
    "param0 = {\n",
    "    'ln_tau': ln_tau,\n",
    "    'beta0': float(beta0),\n",
    "    'beta': beta\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "# We assume that we have infinite amount of data.\n",
    "# Thus, generator of the data is implemented.\n",
    "def generate_data(N, D, T, beta0, beta, ln_tau):\n",
    "    z = np.random.randn(N) * np.exp(ln_tau)\n",
    "    x = np.random.randn(N*T*D).reshape([N,T,D])\n",
    "    y = bernoulli(p=sigmoid(beta0+x@beta+z.reshape([N,1]))).rvs()\n",
    "    return x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "D = 3\n",
    "T = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = generate_data(N, D, T, beta0, beta, ln_tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Normal Integral Approximation of Evidence\n",
    "\n",
    "Ref: Barber Bishop(1998), PRML(2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_normal_prob(x, beta0, beta, ln_tau):\n",
    "    n, t, d  = x.shape\n",
    "    kappa = 1 / (1 + np.pi*tf.exp(ln_tau*2)/8)**(1/2)\n",
    "    return tf.math.sigmoid( kappa * (beta0 + tf.reshape( x@tf.reshape(beta, [D,1]), [n, T])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_normal_likelihood(x, y, beta0, beta, ln_tau):\n",
    "    pred_prob = sigmoid_normal_prob(x, beta0, beta, ln_tau)\n",
    "    score = tf.reduce_mean(tf.reduce_sum(\n",
    "        tf.math.log(pred_prob)*y + tf.math.log(1-pred_prob)*(1-y), \n",
    "        axis=1))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Approximation of Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_approx(x, y, beta0, beta, ln_tau):\n",
    "    n, T, D  = x.shape\n",
    "    z = np.zeros([n, 1])\n",
    "    _sig = lambda z: sigmoid( z + beta0 + x@beta )\n",
    "    for i in range(10):\n",
    "        sig = _sig(z)\n",
    "        hessian = 1/np.exp(ln_tau*2) + np.sum( sig*(1-sig), axis=1, keepdims=True)\n",
    "        grad    = z/np.exp(ln_tau*2) + np.sum( sig - y,     axis=1, keepdims=True)\n",
    "        z -= grad / hessian\n",
    "    mu = z.reshape([n])\n",
    "    sigma = (1 / hessian).reshape([n])**(1/2)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.130907347338663, 1.9946040065682895)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.var(), (z-mu).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IWELBO approximation of Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma):\n",
    "    \"\"\"\n",
    "    Compute IWELBOs for i = 1,...,n using n_MC samples Zn. \n",
    "    Here, we assume that n<N where N is the size of data.\n",
    "    \n",
    "    Arguments:\n",
    "    x: 3-d array of size [n, T, D]\n",
    "    y: 2-d array of size [n, T]\n",
    "    z: 1-d array of size [n_MC, n]\n",
    "    beta: 1-d array of size [D]\n",
    "    mu: 1-d array of [n]\n",
    "    sigma**2: 1-d array of [n]\n",
    "    \n",
    "    Returns:\n",
    "    iwelbo: iwelbo, whose size is [n]\n",
    "    \"\"\"\n",
    "\n",
    "    (n, T, D), (n_MC, n) = x.shape, z.shape\n",
    "    y = np.float64( y.reshape([1,n,T]) )\n",
    "    mu = mu.reshape([1,n])\n",
    "    sigma = sigma.reshape([1,n])\n",
    "    \n",
    "    y_logits = tf.convert_to_tensor( beta0\\\n",
    "                                    + tf.reshape( x@tf.reshape(beta, [D,1]), [1, n, T])\\\n",
    "                                    + tf.reshape(z, [n_MC, n, 1]) \n",
    "                                   )\n",
    "    p_y = tfp.distributions.Bernoulli(logits=y_logits)\n",
    "    p_z = tfp.distributions.Normal(loc=np.zeros([1, n]), scale=tf.exp(ln_tau))\n",
    "    q_z = tfp.distributions.Normal(loc=mu, scale=sigma)\n",
    "    \n",
    "    log_prob_ratio = \\\n",
    "        tf.reduce_sum( p_y.log_prob(y), axis=2)\\\n",
    "        + p_z.log_prob(z)\\\n",
    "        - q_z.log_prob(z)\n",
    "    \n",
    "    iwelbo = tf_logmeanexp(log_prob_ratio, axis=0)\n",
    "    return iwelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC):\n",
    "    n, = mu.shape\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, n])\n",
    "    iwelbo = tf.reduce_mean( pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma) )\n",
    "    return iwelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "signorm_likelihood = sigmoid_normal_likelihood(x, y, beta0, beta, ln_tau).numpy()\n",
    "elbo_likelihood = IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=1).numpy()\n",
    "iwelbo_likelihood = IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=64).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3453549355262067, -1.2799727649308008, -1.2631378995992737)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signorm_likelihood, elbo_likelihood, iwelbo_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood by Different Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orthogonalize the covariate with z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training signorm...\n",
      "#iter: 0,\tloss: 1.3862943611198932\n",
      "#iter: 50,\tloss: 1.3481196565879132\n",
      "#iter: 100,\tloss: 1.3447647408257335\n",
      "#iter: 150,\tloss: 1.3518931308006963\n",
      "#iter: 200,\tloss: 1.3486989728276797\n",
      "#iter: 250,\tloss: 1.3516026313018978\n",
      "#iter: 300,\tloss: 1.3402616610446163\n",
      "#iter: 350,\tloss: 1.3551532661281345\n",
      "#iter: 400,\tloss: 1.343664061057097\n",
      "#iter: 450,\tloss: 1.3500466739531285\n",
      "#iter: 500,\tloss: 1.3316452321640018\n",
      "\n",
      "training elbo...\n",
      "#iter: 0,\tloss: 1.3401437165916787\n",
      "#iter: 50,\tloss: 1.2979686663096506\n",
      "#iter: 100,\tloss: 1.2940268439464\n",
      "#iter: 150,\tloss: 1.2825036766565128\n",
      "#iter: 200,\tloss: 1.288800352696763\n",
      "#iter: 250,\tloss: 1.2955594018720673\n",
      "#iter: 300,\tloss: 1.2942937696950572\n",
      "#iter: 350,\tloss: 1.286718374619531\n",
      "#iter: 400,\tloss: 1.2898627608319797\n",
      "#iter: 450,\tloss: 1.2978442480357104\n",
      "#iter: 500,\tloss: 1.309185484765381\n",
      "\n",
      "training iwelbo...\n",
      "#iter: 0,\tloss: 1.3318654060649402\n",
      "#iter: 50,\tloss: 1.2787510637478003\n",
      "#iter: 100,\tloss: 1.2711447095863055\n",
      "#iter: 150,\tloss: 1.3063030768774344\n",
      "#iter: 200,\tloss: 1.2741707243203018\n",
      "#iter: 250,\tloss: 1.281253717786135\n",
      "#iter: 300,\tloss: 1.2832810760779572\n",
      "#iter: 350,\tloss: 1.2659147062434084\n",
      "#iter: 400,\tloss: 1.2870413849779907\n",
      "#iter: 450,\tloss: 1.2729711169673155\n",
      "#iter: 500,\tloss: 1.2582348411100635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "objectives = {\n",
    "    \"signorm\": lambda beta0, beta, ln_tau, mu, sigma: sigmoid_normal_likelihood(x, y, beta0, beta, ln_tau),\n",
    "    \"elbo\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=1),\n",
    "    \"iwelbo\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=64)\n",
    "}\n",
    "params = {\"ground_truth\": param0}\n",
    "\n",
    "N,T,D = 1000, 2, 3\n",
    "\n",
    "for obj_name, obj_func in objectives.items():\n",
    "    \n",
    "    print(\"training {}...\".format(obj_name))\n",
    "    \n",
    "    beta0_ = tf.Variable(0, dtype=tf.float64)\n",
    "    beta_  = tf.Variable(np.zeros([D]), dtype=tf.float64)\n",
    "    ln_tau_   = tf.Variable(0, dtype=tf.float64)\n",
    "\n",
    "    for t in range(501):\n",
    "        \n",
    "        rho_t = 0.4/(1+t)**0.6\n",
    "        x,y,z = generate_data(N, D, T, beta0, beta, ln_tau)\n",
    "\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch([beta0_, beta_, ln_tau_])\n",
    "            mu, sigma = laplace_approx(x, y, beta0_.numpy(), beta_.numpy(), ln_tau_.numpy())\n",
    "            score = obj_func(beta0_, beta_, ln_tau_, mu, sigma)\n",
    "        dbeta0_, dbeta_, dln_tau_ = g.gradient(score, [beta0_, beta_, ln_tau_])\n",
    "\n",
    "        beta0_ = beta0_ + rho_t*dbeta0_\n",
    "        beta_ = beta_ + rho_t*dbeta_\n",
    "        ln_tau_ = ln_tau_ + dln_tau_\n",
    "        if t%50==0:\n",
    "            print(\"#iter: {},\\tloss: {}\".format(t, -score.numpy()))\n",
    "    \n",
    "    params[obj_name] = {\n",
    "        'ln_tau': ln_tau_.numpy(),\n",
    "        'beta0': beta0_.numpy(),\n",
    "        'beta': beta_.numpy()\n",
    "    }\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ground_truth': {'ln_tau': 0.7,\n",
       "  'beta0': 0.0,\n",
       "  'beta': array([-0.49585496, -0.44138983, -0.10935024])},\n",
       " 'signorm': {'ln_tau': -0.4393838742778257,\n",
       "  'beta0': -0.008806776827671782,\n",
       "  'beta': array([-0.32041121, -0.29156639, -0.07400701])},\n",
       " 'elbo': {'ln_tau': -0.19809545847196794,\n",
       "  'beta0': -0.0014466023401008637,\n",
       "  'beta': array([-0.36414611, -0.32299035, -0.07947923])},\n",
       " 'iwelbo': {'ln_tau': 0.6413189267005861,\n",
       "  'beta0': 0.0006609054398471921,\n",
       "  'beta': array([-0.43200339, -0.38468579, -0.0966636 ])}}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottom Line: IWELBO gives better estiamte than elbo or sigmoid normal integral approximation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLMC codition check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma):\n",
    "    \n",
    "    (n, T, D), (n_MC, n) = x.shape, z.shape\n",
    "    assert np.log2(n_MC)%1==0\n",
    "    \n",
    "    if n_MC == 1:\n",
    "        scores = pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma)\n",
    "    else:\n",
    "        scores = pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma)\n",
    "        scores -= (1/2.) * pointwise_IWELBO(x, y, z[:n_MC//2 ], beta0, beta, ln_tau, mu, sigma)\n",
    "        scores -= (1/2.) * pointwise_IWELBO(x, y, z[ n_MC//2:], beta0, beta, ln_tau, mu, sigma)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level):\n",
    "    \n",
    "    n, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, n])\n",
    "    \n",
    "    diwelbo = tf.reduce_mean( pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma) )\n",
    "    return diwelbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=8, start_level=0):\n",
    "    \n",
    "    N, T, D = x.shape\n",
    "\n",
    "    levels = np.arange(start_level, max_level+1)\n",
    "    weights = 2.**(-3/2*levels)\n",
    "    weights /= sum(weights)\n",
    "    Ns = np.zeros_like(levels)\n",
    "    Ns = np.array([np.math.ceil(w*N) for w in weights], dtype=np.int)\n",
    "    Ns[0] = N - sum(Ns[1:])\n",
    "    \n",
    "    N_offset = 0\n",
    "    score = 0\n",
    "    for i, l in enumerate(levels):\n",
    "        x_tmp = x[N_offset:N_offset+Ns[i]]\n",
    "        y_tmp = y[N_offset:N_offset+Ns[i]]\n",
    "        mu_tmp = mu[N_offset:N_offset+Ns[i]]\n",
    "        sigma_tmp = sigma[N_offset:N_offset+Ns[i]]\n",
    "        \n",
    "        score += dIWELBO(x_tmp, y_tmp, beta0, beta, ln_tau, mu_tmp, sigma_tmp, level=l)\n",
    "        N_offset += Ns[i]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-1.2547080764020955>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=10, start_level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_stats_dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level=1):\n",
    "    \n",
    "    n, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, n])\n",
    "    \n",
    "    diwelbos = pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma).numpy()\n",
    "    mean_diwelbo = diwelbos.mean()\n",
    "    mean_abs_diwelbo = np.mean(np.abs(diwelbos))\n",
    "    var_diwelbo = diwelbos.var()\n",
    "    \n",
    "    iwelbos = pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma).numpy()\n",
    "    var_iwelbo = iwelbos.var()\n",
    "    \n",
    "    return {'mean_dIWELBO':mean_diwelbo, \n",
    "            'mean_abs_dIWELBO':mean_abs_diwelbo, \n",
    "            'var_dIWELBO':var_diwelbo, \n",
    "            'var_IWELBO':var_iwelbo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv_stats = [conv_stats_dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level=l) for l in range(10)]\n",
    "conv_stats = pd.DataFrame(conv_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(conv_stats[['mean_abs_dIWELBO', 'var_dIWELBO', 'var_IWELBO']])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_dIWELBO</th>\n",
       "      <th>mean_abs_dIWELBO</th>\n",
       "      <th>var_dIWELBO</th>\n",
       "      <th>var_IWELBO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.286579</td>\n",
       "      <td>1.288297</td>\n",
       "      <td>2.142389e-01</td>\n",
       "      <td>0.214239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006955</td>\n",
       "      <td>0.006955</td>\n",
       "      <td>7.157887e-04</td>\n",
       "      <td>0.204806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>2.228524e-04</td>\n",
       "      <td>0.198314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>1.027039e-04</td>\n",
       "      <td>0.195307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>4.390534e-05</td>\n",
       "      <td>0.193255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>1.455702e-05</td>\n",
       "      <td>0.192045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>4.885327e-06</td>\n",
       "      <td>0.191200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>8.554871e-06</td>\n",
       "      <td>0.190853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>4.492801e-07</td>\n",
       "      <td>0.190480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>2.041902e-07</td>\n",
       "      <td>0.190354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_dIWELBO  mean_abs_dIWELBO   var_dIWELBO  var_IWELBO\n",
       "0     -1.286579          1.288297  2.142389e-01    0.214239\n",
       "1      0.006955          0.006955  7.157887e-04    0.204806\n",
       "2      0.004007          0.004007  2.228524e-04    0.198314\n",
       "3      0.002513          0.002513  1.027039e-04    0.195307\n",
       "4      0.001509          0.001509  4.390534e-05    0.193255\n",
       "5      0.000860          0.000860  1.455702e-05    0.192045\n",
       "6      0.000480          0.000480  4.885327e-06    0.191200\n",
       "7      0.000272          0.000272  8.554871e-06    0.190853\n",
       "8      0.000139          0.000139  4.492801e-07    0.190480\n",
       "9      0.000072          0.000072  2.041902e-07    0.190354"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMC_ests = []\n",
    "MLMC_ests = []\n",
    "for i in range(10):\n",
    "    x,y,z_ = generate_data(N=200000, D=3, T=2, beta0=beta0, beta=beta, ln_tau=ln_tau)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)\n",
    "    NMC_ests.append( IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=16).numpy() )\n",
    "    MLMC_ests.append( IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=4, start_level=0).numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std-div of NMC estimator:   0.0010681426285199416\n",
      "std-div of MLMC estimator:  0.001467850251896148\n"
     ]
    }
   ],
   "source": [
    "print(\"std-div of NMC estimator:  \", np.std(NMC_ests))\n",
    "print(\"std-div of MLMC estimator: \", np.std(MLMC_ests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41 s ± 7.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 ms ± 596 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=6, start_level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For finding nice configuration where MLMC wins NMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011223535213672926 1.7766281227047076\n",
      "0.5869003546656074 2.013010552806195\n"
     ]
    }
   ],
   "source": [
    "n,_ = y.shape\n",
    "n_MC = 2\n",
    "z = norm(loc=mu, scale=sigma).rvs([n_MC, n])\n",
    "\n",
    "diwelbos = pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma).numpy()\n",
    "score1 = np.var(NMC_ests) / diwelbos.mean()**2\n",
    "score2 = np.var(MLMC_ests) / np.var(NMC_ests)\n",
    "print(score1, score2)\n",
    "\n",
    "print(np.std(x@beta, axis=1).mean(), z_.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
