{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse GP Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$f \\sim\\mathcal{GP}_{\\text{FITC}}(K, z_{1:M})$\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$Y_n \\sim \\mathrm{Bernoulli}(\\sigma(f))$,\n",
    "\n",
    "where $K(x_1,x_2) = \\exp\\left(\\beta - \\sum_{d=1,2}\\mathrm{softplus}({\\alpha_d})\\cdot(x_{1d} - x_{2d})^2\\right)$.\n",
    "<br>\n",
    "Here, latent process $f\\sim\\mathcal{GP}_{\\text{FITC}}(K, z_{1:M})$ is defined as:\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$u=f_0\\small{(z_{1:M})}$ for $f_0\\sim\\mathcal{GP}(K)$\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$f(x)\\sim\\mathcal{GP}(K| f\\small{(z_{1:M})}=u)$ <br>\n",
    "Additionally, conditional independence of process $f$ among any points given $u=f_0\\small{(z_{1:M})} = \\left(f_0(z_1), ..., f_0(z_M)\\right)$ is assumed. <br>\n",
    "That is, for any $n_1$ and $n_2$, $f(x_{n_1})\\perp \\!\\!\\! \\perp f(x_{n_1})|u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Marginalization of Evidece Lower Bound\n",
    "By simplifying notation as $f_{1:N} = f(x_{1:N})$ and $u = f(z_{1:M})$, we can write evidence lower bound (ELBO) and locally margianlized likelihood (LM-ELBO)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathrm{LM}\\text{-}\\mathrm{ELBO}\n",
    "&= \\log p(y_{1:N}) - \\mathrm{KL}\\left[\\ q(u)\\ ||\\ p(u|y_{1:N})\\ \\right] \\\\\n",
    "&= \\mathrm{E}_{u\\sim q}\\left[\\ \\log p(y_{1:N}|u)\\ \\right]\n",
    " - \\mathrm{KL}\\left[\\ q(u)\\ ||\\ p(u)\\ \\right] \\\\\n",
    "&\\geq \\mathrm{E}_{u\\sim q}\\left[\\ \\log p(y_{1:N}|u)\n",
    "- \\mathrm{KL}\\left[\\ p(f_{1:N}|u)\\ ||\\ p(f_{1:N}| y_{1:N}, u)\\ \\right]\\ \\right]\n",
    " - \\mathrm{KL}\\left[\\ q(u)\\ ||\\ p(u)\\ \\right] \\\\\n",
    "&= \\log p(y_{1:N}) - \\mathrm{KL}\\left[ p(f_{1:N}|u)q(u) || p(y_{1:N}, f_{1:N}, u) \\right]\\\\\n",
    "&= \\mathrm{E}_{u\\sim q} \\mathrm{E}_{f_{1:N}\\sim p(f_{1:N}|u)}\\left[\n",
    "\\log \\left(\\frac{p(y_{1:N}, f_{1:N}, u)}{p(f_{1:N}| u)q(u)}\\right) \n",
    "\\right] \\\\\n",
    "&= \\sum_{n=1}^N\\mathrm{E}_{u\\sim q} \\mathrm{E}_{f_n\\sim p(f_n|u)}\n",
    "\\left[ \\log p(y_n| f_n) \\right] \n",
    "- \\mathrm{KL}\\left[\\ q(u)\\ ||\\ p(u)\\ \\right] \\\\\n",
    "&= \\mathrm{ELBO}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Datasets\n",
    "- http://archive.ics.uci.edu/ml/datasets/Adult\n",
    "- http://archive.ics.uci.edu/ml/datasets/Bar+Crawl%3A+Detecting+Heavy+Drinking\n",
    "- http://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008\n",
    "- http://archive.ics.uci.edu/ml/datasets/Buzz+in+social+media+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn GPUs off\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1/(1+np.exp(-x))\n",
    "softplus = lambda x: np.log(1+np.exp(x))\n",
    "as_tf_float = lambda x: tf.cast(x, tf.float64)\n",
    "\n",
    "def tf_logsumexp(ary, axis=1, keepdims=False):\n",
    "    return tf.math.reduce_logsumexp(ary, axis=axis, keepdims=keepdims)\n",
    "\n",
    "def tf_logmeanexp(ary, axis=1, keepdims=False):\n",
    "    return tf.math.reduce_logsumexp(ary, axis=axis, keepdims=keepdims) \\\n",
    "        - tf.math.log(as_tf_float(ary.shape[axis]))\n",
    "\n",
    "def timestamp():\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y%m%d%H%M%S\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.data\n",
    "x = (x - x.mean(axis=0)) / x.std(axis=0) # standardization\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D = x.shape\n",
    "M = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_param(D, M):\n",
    "    theta = {\n",
    "    'z': tf.Variable(x[np.random.choice(np.arange(N), size=M, replace=False)]),\n",
    "    'alpha': tf.Variable(np.ones([D]), dtype=tf.float64),\n",
    "    'beta': tf.Variable(1., dtype=tf.float64)\n",
    "    }\n",
    "    phi = {\n",
    "        'm': tf.Variable(np.zeros([M]), dtype=tf.float64),\n",
    "        'CholS': tf.Variable(0.1*np.eye(M), dtype=tf.float64)\n",
    "    }\n",
    "    return theta, phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_K(alpha, beta):\n",
    "    # define Kernel\n",
    "    D = alpha.shape[0]\n",
    "    sp_alpha = tf.reshape( tf.math.softplus( alpha ), [1,1,D])\n",
    "    def K(x1,x2):\n",
    "        n1 = x1.shape[0]\n",
    "        n2 = x2.shape[0]\n",
    "        x1 = tf.reshape(x1, [n1, 1, D])\n",
    "        x2 = tf.reshape(x2, [1 ,n2, D])\n",
    "        return tf.exp(beta - tf.reduce_sum( sp_alpha*(x1-x2)**2, axis=2))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size=20):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression as a Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876977152899824"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x,y)\n",
    "model.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05339203990991728"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.predict_proba(x)[:,1]\n",
    "(y*np.log(p) + (1-y)*np.log(1-p)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELBO(x, y, theta, phi, N_total):\n",
    "    '''\n",
    "    Inputs:\n",
    "    x: 2-d array of shape [N,D]\n",
    "    y: 1-d array of shape [N]\n",
    "    theta: disctionary of model parameters\n",
    "    phi: disctionary of variational parameters\n",
    "    \n",
    "    Returns:\n",
    "    elbo: scalar\n",
    "    '''\n",
    "    \n",
    "    z = theta['z']\n",
    "    alpha = theta['alpha']\n",
    "    beta = theta['beta']\n",
    "    K = get_K(alpha, beta)\n",
    "    \n",
    "    N = y.shape[0]\n",
    "    M = z.shape[0]\n",
    "    \n",
    "    m = phi['m']\n",
    "    CholS = phi['CholS']\n",
    "    \n",
    "    # sample u = f_0(z_1,...,z_M) from q\n",
    "    K_mm = K(z, z) + 1e-6 * tf.eye(M, dtype=tf.float64)\n",
    "    CholK_mm = tf.linalg.cholesky(K_mm)\n",
    "    \n",
    "    p_u = tfp.distributions.MultivariateNormalTriL(loc=0., scale_tril=CholK_mm)\n",
    "    q_u = tfp.distributions.MultivariateNormalTriL(loc=m, scale_tril=CholS)\n",
    "    u = q_u.sample(N)\n",
    "    \n",
    "    \n",
    "    # sample f conditionally given u = f_0(z_1,...,z_M)\n",
    "    inv_CholK_mm = tf.linalg.inv(CholK_mm)\n",
    "    inv_K_mm = tf.transpose(inv_CholK_mm)@inv_CholK_mm\n",
    "    K_nm = K(x, z)\n",
    "    K_mn = tf.transpose(K_nm)\n",
    "    \n",
    "    mean_f = tf.linalg.einsum('ni,ij,nj->n', K_nm, inv_K_mm, u)\n",
    "    var_f = tf.vectorized_map(lambda x:K(x,x), tf.expand_dims(x, axis=1))\n",
    "    var_f = tf.reshape(var_f, [N])\n",
    "    var_f = var_f - tf.linalg.einsum('ni,ij,jn->n', K_nm, inv_K_mm, K_mn)\n",
    "    \n",
    "    q_f = tfp.distributions.Normal(loc=mean_f, scale=var_f)\n",
    "    f = q_f.sample()\n",
    "\n",
    "    # compute ELBO estimate\n",
    "    p_y = tfp.distributions.Bernoulli(logits=f)\n",
    "    kl_qu_pu = tfp.distributions.kl_divergence(q_u, p_u)\n",
    "    elbo = tf.reduce_mean(p_y.log_prob(y)) - kl_qu_pu / N_total\n",
    "    return elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMELBO(x, y, theta, phi, N_total, n_MC):\n",
    "    \n",
    "    z = theta['z']\n",
    "    alpha = theta['alpha']\n",
    "    beta = theta['beta']\n",
    "    K = get_K(alpha, beta)\n",
    "    \n",
    "    N = y.shape[0]\n",
    "    M = z.shape[0]\n",
    "    \n",
    "    m = phi['m']\n",
    "    CholS = phi['CholS']\n",
    "    \n",
    "    # sample u = f_0(z_1,...,z_M) from q\n",
    "    K_mm = K(z, z) + 1e-6 * tf.eye(M, dtype=tf.float64)\n",
    "    CholK_mm = tf.linalg.cholesky(K_mm)\n",
    "    \n",
    "    p_u = tfp.distributions.MultivariateNormalTriL(loc=0., scale_tril=CholK_mm)\n",
    "    q_u = tfp.distributions.MultivariateNormalTriL(loc=m, scale_tril=CholS)\n",
    "    u = q_u.sample(N)\n",
    "    \n",
    "    \n",
    "    # sample f conditionally given u = f_0(z_1,...,z_M)\n",
    "    inv_CholK_mm = tf.linalg.inv(CholK_mm)\n",
    "    inv_K_mm = tf.transpose(inv_CholK_mm)@inv_CholK_mm\n",
    "    K_nm = K(x, z)\n",
    "    K_mn = tf.transpose(K_nm)\n",
    "    \n",
    "    mean_f = tf.linalg.einsum('ni,ij,nj->n', K_nm, inv_K_mm, u)\n",
    "    var_f = tf.vectorized_map(lambda x:K(x,x), tf.expand_dims(x, axis=1))\n",
    "    var_f = tf.reshape(var_f, [N])\n",
    "    var_f = var_f - tf.linalg.einsum('ni,ij,jn->n', K_nm, inv_K_mm, K_mn)\n",
    "    \n",
    "    q_f = tfp.distributions.Normal(loc=mean_f, scale=var_f)\n",
    "    f = q_f.sample(n_MC)\n",
    "\n",
    "    # compute LMELBO estimate\n",
    "    p_y = tfp.distributions.Bernoulli(logits=f)\n",
    "    log_prob_y = tf.reduce_mean( tf_logmeanexp( p_y.log_prob(y) , axis=0) ) \n",
    "    kl_qu_pu = tfp.distributions.kl_divergence(q_u, p_u)\n",
    "    lmelbo = log_prob_y - kl_qu_pu / N_total\n",
    "    return lmelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_dconditional_likelihood(x, y, theta, phi, level):\n",
    "    \n",
    "    z = theta['z']\n",
    "    alpha = theta['alpha']\n",
    "    beta = theta['beta']\n",
    "    K = get_K(alpha, beta)\n",
    "    \n",
    "    N = y.shape[0]\n",
    "    M = z.shape[0]\n",
    "    \n",
    "    m = phi['m']\n",
    "    CholS = phi['CholS']\n",
    "    \n",
    "    # sample u = f_0(z_1,...,z_M) from q\n",
    "    K_mm = K(z, z) + 1e-6 * tf.eye(M, dtype=tf.float64)\n",
    "    CholK_mm = tf.linalg.cholesky(K_mm)\n",
    "    \n",
    "    p_u = tfp.distributions.MultivariateNormalTriL(loc=0., scale_tril=CholK_mm)\n",
    "    q_u = tfp.distributions.MultivariateNormalTriL(loc=m, scale_tril=CholS)\n",
    "    u = q_u.sample(N)\n",
    "    \n",
    "    # sample f conditionally given u = f_0(z_1,...,z_M)\n",
    "    inv_CholK_mm = tf.linalg.inv(CholK_mm)\n",
    "    inv_K_mm = tf.transpose(inv_CholK_mm)@inv_CholK_mm\n",
    "    K_nm = K(x, z)\n",
    "    K_mn = tf.transpose(K_nm)\n",
    "    \n",
    "    mean_f = tf.linalg.einsum('ni,ij,nj->n', K_nm, inv_K_mm, u)\n",
    "    var_f = tf.vectorized_map(lambda x:K(x,x), tf.expand_dims(x, axis=1))\n",
    "    var_f = tf.reshape(var_f, [N])\n",
    "    var_f = var_f - tf.linalg.einsum('ni,ij,jn->n', K_nm, inv_K_mm, K_mn)\n",
    "    \n",
    "    q_f = tfp.distributions.Normal(loc=mean_f, scale=var_f)\n",
    "    n_MC = 2**level\n",
    "    f = q_f.sample(n_MC)\n",
    "\n",
    "    # compute ELBO estimate\n",
    "    p_y = tfp.distributions.Bernoulli(logits=f)\n",
    "    w = p_y.log_prob(y)\n",
    "    w = tf.reshape(w, [n_MC,N])\n",
    "    if level==0:\n",
    "        return tf_logmeanexp(w, axis=0) \n",
    "    else:\n",
    "        return tf_logmeanexp(w, axis=0)\\\n",
    "                - (1/2.) * tf_logmeanexp(w[:n_MC//2 ], axis=0)\\\n",
    "                - (1/2.) * tf_logmeanexp(w[ n_MC//2:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, phi = init_param(D,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5b4366f3aac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_repeated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_repeated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "idx = np.repeat(np.arange(N), 10)\n",
    "x_repeated = x[idx]\n",
    "y_repeated = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$\\\\mathrm{E}||\\\\nabla\\\\ (\\\\Delta \\\\mathrm{LM}$-${ELBO})\\\\ ||_2^2$')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_dcond_L = lambda l: (pointwise_dconditional_likelihood(x_tmp, y_tmp, theta, phi, level=l).numpy()**2).mean()\n",
    "plt.plot([var_dcond_L(l) for l in range(10)])\n",
    "plt.yscale('log')\n",
    "plt.xlabel('level')\n",
    "plt.ylabel(r'$\\mathrm{E}||\\nabla\\ (\\Delta \\mathrm{LM}$-${ELBO})\\ ||_2^2$') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dconditional_likelihood(x, y, mean_f, var_f, level):\n",
    "    \n",
    "    N = y.shape[0]\n",
    "    # sample f_n's\n",
    "    q_f = tfp.distributions.Normal(loc=mean_f, scale=var_f)\n",
    "    n_MC = 2**level\n",
    "    f = q_f.sample(n_MC)\n",
    "    \n",
    "    # sample conditional likelihoods\n",
    "    p_y = tfp.distributions.Bernoulli(logits=f)\n",
    "    w = p_y.log_prob(y)\n",
    "    w = tf.reshape(w, [n_MC,N])\n",
    "    \n",
    "    if level==0:\n",
    "        dL = tf_logmeanexp(w, axis=0) \n",
    "    else:\n",
    "        dL = tf_logmeanexp(w, axis=0)\\\n",
    "                - (1/2.) * tf_logmeanexp(w[:n_MC//2 ], axis=0)\\\n",
    "                - (1/2.) * tf_logmeanexp(w[ n_MC//2:], axis=0)\n",
    "    return tf.reduce_mean( dL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMELBO_MLMC(x, y, theta, phi, N_total, max_level=8, w0=1-2.**(-3/2), b=2, randomize=False):\n",
    "    \"\"\"\n",
    "    Compute IWELBO by MLMC\n",
    "    \n",
    "    Arguments:\n",
    "    x: 3-d array of size [N, T, D]\n",
    "    y: 2-d array of size [N, T]\n",
    "    beta0: scalar\n",
    "    beta: 1-d array of size [D]\n",
    "    alpha: scalar\n",
    "    mu: 1-d array of size [N]\n",
    "    sigma: 1-d array of size [N]\n",
    "    max_level: integer\n",
    "    w0: the proportion of total samples in (x,y) used at the level 0.\n",
    "        in other words, 100*(1-w0) % of the total samples are used for estimating the correction term.\n",
    "    b: scalar. the second moment of the coupled difference estimator (dIWELBO) must decrease at a rate of O(2^(-b*level)).\n",
    "    randomize: whether to use randomization of MLMC.\n",
    "    \n",
    "    Returns:\n",
    "    iwelbo: scalar estimate of average iwelbo over sample points.\n",
    "    \"\"\"\n",
    "    # unpack parameters\n",
    "    z = theta['z']\n",
    "    alpha = theta['alpha']\n",
    "    beta = theta['beta']\n",
    "    K = get_K(alpha, beta)\n",
    "    \n",
    "    N = y.shape[0]\n",
    "    M = z.shape[0]\n",
    "    \n",
    "    m = phi['m']\n",
    "    CholS = phi['CholS']\n",
    "    \n",
    "    # calculate KL divergence of p(u) and q(u) of u = f_0(z_1,...,z_M)\n",
    "    K_mm = K(z, z) + 1e-6 * tf.eye(M, dtype=tf.float64)\n",
    "    CholK_mm = tf.linalg.cholesky(K_mm)\n",
    "    \n",
    "    p_u = tfp.distributions.MultivariateNormalTriL(loc=0., scale_tril=CholK_mm)\n",
    "    q_u = tfp.distributions.MultivariateNormalTriL(loc=m, scale_tril=CholS)\n",
    "    kl_qu_pu = tfp.distributions.kl_divergence(q_u, p_u)\n",
    "      \n",
    "    # calculate distribution of f conditionally on u = f_0(z_1,...,z_M)\n",
    "    u = q_u.sample(N)\n",
    "    inv_CholK_mm = tf.linalg.inv(CholK_mm)\n",
    "    inv_K_mm = tf.transpose(inv_CholK_mm)@inv_CholK_mm\n",
    "    K_nm = K(x, z)\n",
    "    K_mn = tf.transpose(K_nm)\n",
    "    \n",
    "    mean_f = tf.linalg.einsum('ni,ij,nj->n', K_nm, inv_K_mm, u)\n",
    "    var_f = tf.vectorized_map(lambda x:K(x,x), tf.expand_dims(x, axis=1))\n",
    "    var_f = tf.reshape(var_f, [N])\n",
    "    var_f = var_f - tf.linalg.einsum('ni,ij,jn->n', K_nm, inv_K_mm, K_mn)\n",
    "    \n",
    "    # determine proportions of the number of samples among levels\n",
    "    if max_level==0:\n",
    "        levels = np.array([0])\n",
    "        weights = np.array([1.])\n",
    "    else:\n",
    "        weights = 2.**(-(b+1)/2*np.arange(max_level))\n",
    "        weights /= sum(weights)\n",
    "        weights = np.concatenate([[w0], (1-w0)*weights])\n",
    "        levels = np.arange(max_level+1)\n",
    "    \n",
    "    # determine the N_l's\n",
    "    if randomize==True:\n",
    "        Ns = np.random.multinomial(n=N, pvals=weights)    \n",
    "    elif randomize==False:\n",
    "        Ns = np.array([np.math.ceil(w*N) for w in weights], dtype=np.int)\n",
    "        Ns[0] = N - sum(Ns[1:])\n",
    "    else:\n",
    "        raise(Exception(\"Invarid argument for 'randomize' of function IWELBO_MLMC. It must be True or False.\"))\n",
    "    \n",
    "    # compute dIWELBO's using disjoint samples at each level and sum them up\n",
    "    offset = 0\n",
    "    lmelbo = kl_qu_pu / N_total\n",
    "    for i, l in enumerate(levels):\n",
    "        if Ns[i]==0:\n",
    "            continue\n",
    "        x_tmp = x[offset:offset+Ns[i]]\n",
    "        y_tmp = y[offset:offset+Ns[i]]\n",
    "        mean_f_tmp = mean_f[offset:offset+Ns[i]]\n",
    "        var_f_tmp = var_f[offset:offset+Ns[i]]\n",
    "                       \n",
    "        if randomize==True:\n",
    "            lmelbo += dconditional_likelihood(x_tmp, y_tmp, mean_f_tmp, var_f_tmp, level=l) * Ns[i] / N / weights[i]   \n",
    "        elif randomize==False:\n",
    "            lmelbo += dconditional_likelihood(x_tmp, y_tmp, mean_f_tmp, var_f_tmp, level=l)\n",
    "    \n",
    "        offset += Ns[i]\n",
    "          \n",
    "    return lmelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, phi = init_param(D, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#iter: 0-19\t0.9908756272218187\n",
      "#iter: 20-39\t0.6517295144114708\n",
      "#iter: 40-59\t0.29828040918023996\n",
      "#iter: 60-79\t0.09494809144607715\n",
      "#iter: 80-99\t0.07056335120254617\n",
      "#iter: 100-119\t0.06497747820095827\n",
      "#iter: 120-139\t0.06124926035556031\n",
      "#iter: 140-159\t0.057582189851525536\n",
      "#iter: 160-179\t0.054847835008618395\n",
      "#iter: 180-199\t0.051817219559358904\n",
      "#iter: 200-219\t0.050372678756501844\n",
      "#iter: 220-239\t0.04826687438747719\n",
      "#iter: 240-259\t0.046858965889722846\n",
      "#iter: 260-279\t0.04421599513253066\n",
      "#iter: 280-299\t0.04236061000524271\n",
      "#iter: 300-319\t0.041309560973935046\n",
      "#iter: 320-339\t0.040624248888638394\n",
      "#iter: 340-359\t0.03923069317480163\n",
      "#iter: 360-379\t0.03829192465332126\n",
      "#iter: 380-399\t0.03845082724451372\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.05)\n",
    "\n",
    "losses = []\n",
    "for t in range(401):\n",
    "\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch([theta, phi])\n",
    "        loss = - ELBO(x, y, theta, phi, 40000)\n",
    "    dtheta, dphi = g.gradient(loss, [theta, phi])\n",
    "    \n",
    "    gradients = list(dtheta.values()) + list(dphi.values())\n",
    "    variables = list(theta.values()) + list(phi.values())\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    losses.append(loss.numpy())\n",
    "    if t%20==19:\n",
    "        print('#iter: {}-{}\\t{}'.format(t-19,t, np.mean(losses)))\n",
    "        losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, phi = init_param(D, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#iter: 0-19\t0.6854190309795085\n",
      "#iter: 20-39\t0.5960468813278494\n",
      "#iter: 40-59\t0.2767951427118179\n",
      "#iter: 60-79\t0.08132688273993922\n",
      "#iter: 80-99\t0.048172801964581596\n",
      "#iter: 100-119\t0.03953503955640871\n",
      "#iter: 120-139\t0.03386698177437814\n",
      "#iter: 140-159\t0.031028669759984882\n",
      "#iter: 160-179\t0.028807662246323956\n",
      "#iter: 180-199\t0.026577446140311645\n",
      "#iter: 200-219\t0.02563881357130831\n",
      "#iter: 220-239\t0.02489525056327828\n",
      "#iter: 240-259\t0.02389808985647952\n",
      "#iter: 260-279\t0.022465886475968647\n",
      "#iter: 280-299\t0.02173163442931451\n",
      "#iter: 300-319\t0.021266342137426803\n",
      "#iter: 320-339\t0.020411976167229066\n",
      "#iter: 340-359\t0.01985767779640579\n",
      "#iter: 360-379\t0.01905878305407309\n",
      "#iter: 380-399\t0.01853264625626131\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.05)\n",
    "\n",
    "losses = []\n",
    "for t in range(401):\n",
    "\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch([theta, phi])\n",
    "        loss = - LMELBO(x, y, theta, phi, 40000, n_MC=512)\n",
    "    dtheta, dphi = g.gradient(loss, [theta, phi])\n",
    "    \n",
    "    gradients = list(dtheta.values()) + list(dphi.values())\n",
    "    variables = list(theta.values()) + list(phi.values())\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    losses.append(loss.numpy())\n",
    "    if t%20==19:\n",
    "        print('#iter: {}-{}\\t{}'.format(t-19,t, np.mean(losses)))\n",
    "        losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-6f2788f1f955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mELBO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_total\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-6f2788f1f955>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mELBO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_total\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_data' is not defined"
     ]
    }
   ],
   "source": [
    "np.var([ELBO(x, y, theta, phi, N_total=10000) for x,y,_ in [generate_data(N, D, b0, b) for i in range(100)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var([LMELBO(x, y, theta, phi, N_total=10000, n_MC=2**10) for x,y,_ in [generate_data(N, D, b0, b) for i in range(100)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var([LMELBO_MLMC(x, y, theta, phi, N_total=10000, max_level=10) for x,y,_ in [generate_data(N, D, b0, b) for i in range(100)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([ELBO(x, y, theta, phi, N_total=10000) for x,y,_ in [generate_data(N, D, b0, b) for i in range(10)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([LMELBO(x, y, theta, phi, N_total=10000, n_MC=2**10) for x,y,_ in [generate_data(N, D, b0, b) for i in range(10)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([LMELBO_MLMC(x, y, theta, phi, N_total=10000, max_level=10) for x,y,_ in [generate_data(N, D, b0, b) for i in range(10)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "ELBO(x, y, theta, phi, N_total=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "LMELBO(x, y, theta, phi, N_total=10000, n_MC=2**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "LMELBO_MLMC(x, y, theta, phi, N_total=10000, max_level=10, randomize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, phi = init_param(D, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.05)\n",
    "\n",
    "losses = []\n",
    "for t in range(401):\n",
    "    x,y,_ = generate_data(N, D, b0, b)\n",
    "\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch([theta, phi])\n",
    "        loss = - ELBO(x, y, theta, phi, 40000)\n",
    "    dtheta, dphi = g.gradient(loss, [theta, phi])\n",
    "    \n",
    "    gradients = list(dtheta.values()) + list(dphi.values())\n",
    "    variables = list(theta.values()) + list(phi.values())\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    losses.append(loss.numpy())\n",
    "    if t%20==19:\n",
    "        print('#iter: {}-{}\\t{}'.format(t-19,t, np.mean(losses)))\n",
    "        losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, phi = init_param(D, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.05)\n",
    "\n",
    "losses = []\n",
    "for t in range(401):\n",
    "    x,y,_ = generate_data(N, D, b0, b)\n",
    "\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch([theta, phi])\n",
    "        loss = - LMELBO(x, y, theta, phi, 40000, n_MC=64)\n",
    "    dtheta, dphi = g.gradient(loss, [theta, phi])\n",
    "    \n",
    "    gradients = list(dtheta.values()) + list(dphi.values())\n",
    "    variables = list(theta.values()) + list(phi.values())\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    losses.append(loss.numpy())\n",
    "    if t%20==19:\n",
    "        print('#iter: {}-{}\\t{}'.format(t-19,t, np.mean(losses)))\n",
    "        losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve by Different Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda x1, x2 = (gamma * tf.reduce_sum(x1*x2) + coef0)^degree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・Test LMELBO をプロットしないと意味ない<br>\n",
    "・<s>MNISTで、バッチサイズ小さめで検証</s>←カーネルの計算が重いと死ぬ<br>\n",
    "・潜在変数のサンプルは$\\mathcal{O}(1)$。各データ点の処理は$\\mathcal{O}(M^2)$という致命的な問題がある。<br>\n",
    "・MLMCは潜在変数のサンプリングコストが支配的なときに使うもの。<br>\n",
    "・かと言って、潜在変数の空間が複雑だと、カップリングしないという問題もある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結論…$M$を固定して、Small Dataでなんとか頑張って優位性を示す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlmc_cost(N, max_level, b, w0):\n",
    "    # compute the cost of MLMC estimation \n",
    "    # when the size of x (and that of y) is N\n",
    "    if max_level==0:\n",
    "        levels = np.array([0])\n",
    "        weights = np.array([1.])\n",
    "    else:\n",
    "        weights = 2.**(-(b+1)/2*np.arange(max_level))\n",
    "        weights /= sum(weights)\n",
    "        weights = np.concatenate([[w0], (1-w0)*weights])\n",
    "        levels = np.arange(max_level+1)\n",
    "    cost = np.ceil(N * weights[0])\\\n",
    "            + N * sum( np.ceil(weights[1:] * (2**levels[1:] + 2**(levels[1:]-1))) )\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives = {\n",
    "    \"elbo\":      lambda x, y, theta, phi: ELBO(x, y, theta, phi, N_total=40000),\n",
    "    \"lmelbo8\":   lambda x, y, theta, phi: LMELBO(x, y, theta, phi, N_total=40000, n_MC=8),\n",
    "    \"lmelbo64\":  lambda x, y, theta, phi: LMELBO(x, y, theta, phi, N_total=40000, n_MC=64),\n",
    "    \"lmelbo512\": lambda x, y, theta, phi: LMELBO(x, y, theta, phi, N_total=40000, n_MC=512),\n",
    "    \"lmelbo512_mlmc\": lambda x, y, theta, phi: LMELBO(x, y, theta, phi, N_total=40000, n_MC=512),\n",
    "    \"lmelbo512_randmlmc\": lambda x, y, theta, phi: LMELBO(x, y, theta, phi, N_total=40000, n_MC=512),\n",
    "}\n",
    "\n",
    "n_repeat = 10\n",
    "results = {}\n",
    "\n",
    "for name, obj in objectives.items():\n",
    "    loss_seqs = []\n",
    "    for i in range(n_repeat):\n",
    "        print(\"training {}.... #iter:{} \".format(name,i))\n",
    "        optimizer = tf.keras.optimizers.Adam(0.05)\n",
    "        theta, phi = init_param(D,M)\n",
    "        loss_seq = []\n",
    "        \n",
    "        for t in range(400):\n",
    "            x,y,_ = generate_data(N, D, b0, b)\n",
    "\n",
    "            # balance the cost of mlmc and nmc when level=9 (n_MC=512)\n",
    "            if 'mlmc' in name:\n",
    "                cost_nmc  = N * 2**9\n",
    "                cost_mlmc = get_mlmc_cost(N, max_level=9, b=1.8, w0=0.9)\n",
    "                N_mlmc = np.math.ceil(N * (cost_nmc / cost_mlmc))\n",
    "                x,y,_ = generate_data(N_mlmc, D, b0, b)\n",
    "            \n",
    "            # Optimize\n",
    "            with tf.GradientTape() as g:\n",
    "                g.watch([theta, phi])\n",
    "                loss = - obj(x, y, theta, phi)\n",
    "            dtheta, dphi = g.gradient(loss, [theta, phi])\n",
    "            gradients = list(dtheta.values()) + list(dphi.values())\n",
    "            variables = list(theta.values()) + list(phi.values())\n",
    "            optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "            loss_seq.append(loss.numpy())\n",
    "        loss_seqs.append(loss_seq) \n",
    "    results[name] = np.array(loss_seqs)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../out/gaussian_process_classification/train_log_{}.pickel'.format(timestamp()), 'wb') as file:\n",
    "#    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,6])\n",
    "for logs in results.values():\n",
    "    plt.plot(logs.mean(axis=0), alpha=0.5)\n",
    "plt.legend([name for name in results])\n",
    "plt.ylim([0.54, 0.66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "x = data.data\n",
    "x = (x - x.mean(axis=0)) / x.std(axis=0) # standardization\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.repeat(np.arange(x.shape[0]), 100)\n",
    "x_repeated = x[idx]\n",
    "y_repeated = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.gaussian_process_classification import gaussian_process_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc = gaussian_process_classification(N_total=x.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpc.fit(x,y, learning_rate=0.05, n_iter=401, objective='LMELBO', obj_param={'n_MC':512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc = gaussian_process_classification(N_total=x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#iter: 0-39\t0.9103086106193434\n",
      "#iter: 40-79\t0.3121191711189633\n",
      "#iter: 80-119\t0.1408094033981439\n",
      "#iter: 120-159\t0.11529590468374781\n",
      "#iter: 160-199\t0.10600360130249006\n",
      "#iter: 200-239\t0.10123168054719636\n",
      "#iter: 240-279\t0.09878783229470545\n",
      "#iter: 280-319\t0.09326860354120677\n",
      "#iter: 320-359\t0.0943860912112944\n",
      "#iter: 360-399\t0.09125513406476582\n",
      "#iter: 400-439\t0.09153052216153348\n",
      "#iter: 440-479\t0.09026237338266595\n",
      "#iter: 480-519\t0.08789725932350241\n",
      "#iter: 520-559\t0.0824310066834962\n",
      "#iter: 560-599\t0.09229420343429333\n",
      "#iter: 600-639\t0.08733396526812014\n",
      "#iter: 640-679\t0.08732555802368795\n",
      "#iter: 680-719\t0.09056797987932697\n",
      "#iter: 720-759\t0.08303010629177308\n",
      "#iter: 760-799\t0.0877699344604479\n"
     ]
    }
   ],
   "source": [
    "gpc.fit(x_repeated,y_repeated, learning_rate=0.05, n_iter=801, objective='LMELBO_MLMC', obj_param={'max_level':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#iter: 0-39\t0.08274774968376963\n",
      "#iter: 40-79\t0.07997856359173965\n",
      "#iter: 80-119\t0.08467681759755301\n",
      "#iter: 120-159\t0.08335285793519029\n",
      "#iter: 160-199\t0.08318149374294229\n",
      "#iter: 200-239\t0.08330375782456594\n",
      "#iter: 240-279\t0.08256526782674906\n",
      "#iter: 280-319\t0.08013478628508147\n",
      "#iter: 320-359\t0.07875466101493026\n",
      "#iter: 360-399\t0.08111813541810588\n",
      "#iter: 400-439\t0.07737263113508\n",
      "#iter: 440-479\t0.07685041294596309\n",
      "#iter: 480-519\t0.07893655498021808\n",
      "#iter: 520-559\t0.07721814839399085\n",
      "#iter: 560-599\t0.08038779611559896\n",
      "#iter: 600-639\t0.07904832126372296\n",
      "#iter: 640-679\t0.07754442940794096\n",
      "#iter: 680-719\t0.08025222145486971\n",
      "#iter: 720-759\t0.0774671159122188\n",
      "#iter: 760-799\t0.07573900150769121\n"
     ]
    }
   ],
   "source": [
    "gpc.fit(x_repeated,y_repeated, learning_rate=0.05, n_iter=801, objective='LMELBO_MLMC', obj_param={'max_level':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-0.07471497931132799>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpc.score(x_repeated,y_repeated,objective='LMELBO_MLMC', obj_param={'max_level':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-0.08438146992660227>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpc.score(x,y,objective='LMELBO', obj_param={'n_MC':16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-0.04782105083088791>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpc.score(x_repeated,y_repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3hUZdrH8e+dRqSqVCmhhSICCkQ62BUL4qqrYFcELCDuurrq7r7qvuu6rh07CnZBrCtYQLFQBKQp0kFqaAGUqpSQ+/1jhtdsFJgkk5yZzO9zXbmunDNn5vycS7h5ynkec3dERESKIinoACIiEr9UREREpMhUREREpMhUREREpMhUREREpMhSgg5Q2qpVq+YNGjQIOoaISFyZOXPmJnevXvB8whQRM+sJ9MzMzGTGjBlBxxERiStmtvK3zidMd5a7j3b3/lWqVAk6iohImZEwRURERKIvYYqImfU0s6Fbt24NOoqISJmRMEVE3VkiItGXMEVERESiT0VERESKTEVERESKLGGKSHEH1kd8vYovF2+McioRkfiWMEWkOAPre/fl8dq0lfR7aQbjF2wogXQiIvEpYYpIcaQmJ/Fq3w40P6oS1706k4/nrg86kohITFARidDh5dN49doOtKxThRtfn8Xob9cGHUlEJHAqIoVQOT2VV/p2oF3GEQweOZt3Z2cHHUlEJFAqIoVUsVwKL15zPB0bVeWPo75l1PTVQUcSEQlMXBcRM2tkZsPM7K3SvG/5tBSGX3U8XTOrcdvbc3h16m8ubikiUuYFVkTMbLiZ5ZjZ3ALne5jZIjNbama3H+wz3H2Zu/ct2aS/LT01meeuyOLk5jX463tzeWHy8iBiiIgEKsiWyItAj/wnzCwZeBI4E2gB9DGzFmbWyszGFPipUfqR/1t6ajLPXNaOM46pyT2j5zN0wvdBRxIRKVWBbUrl7hPMrEGB0+2Bpe6+DMDMRgK93P0+4Jyi3svM+gP9ATIyMor6Mb8pLSWJJy5pyx/e+IZ/friQPbl5DDy5SVTvISISq2JtTKQOkH+kOjt87jeZWVUzewZoY2Z3HOg6dx8K3APMSktLi1bW/5eanMSjFx/H79rU4cFxi3n4k8W4e9TvIyISa+J6e1x33wxcF+G1o4HRWVlZ/UoiS0pyEg/+/lhSkowh45ewd18et53RDDMriduJiMSEWCsia4B6+Y7rhs8VW/491ktKcpJx/wWtSUtJ4ukvvmdPbh5/PftoFRIRKbNirTtrOtDEzBqaWRrQG3g/Gh9cWptSJSUZ/zivJVd1bsCwScu56/155OWpa0tEyqbAWiJmNgI4EahmZtnAXe4+zMwGAmOBZGC4u8+L0v1KvCWS717c1bMFaSlJDJ2wjD25efzzd61ISlKLRETKFku0AeCsrCyfMWNGqdzL3Xlo3GKe+HwpF7Sty78vbE2yComIxCEzm+nuWQXPx9qYSIkpzZZIvnvypzOakZaSxMOfLGbvvjwevuhYUpJjrRdRRKRoEuZvs9IaE/ktN53ShD/3aM77367lppGz2bsvr9QziIiUBLVESsn1JzYmNdn4xwcL2JM7iycvbUO5lORAsoiIRItaIqXo2m6N+HuvY/h0wQYGvDKTXXv3BZZFRCQaEqaIxIorOjXgvvNb8eXijVz70gx+3qNCIiLxK2GKiJn1NLOhW7duDToKfdpn8MCFx/LV95u4+sWv2bk7N+hIIiJFkjBFJBa6s/K7sF1dHrn4OKav+JErh3/N9l17g44kIlJoCVNEYlGv4+rweJ82fLN6C5cN+5qtP6mQiEh8SZgiEkvdWfmd1eoonrq0LfPXbuXSYVP5ceeeoCOJiEQsYYpIrHVn5Xf6MbUYekUWizfsoM9zU9m0Y3fQkUREIpIwRSTWndSsBsOvPJ4Vm3fSZ+hUcrbtCjqSiMghqYjEkK5NqvHCVe1Zs+Vneg+dyvqtKiQiEttURGJMp8ZVefma9uRs381Fz04h+8efgo4kInJAKiIxKKvBkbzStz0//rSHi5+dyqrNKiQiEpsSpojE6uysA2mTcQQj+nVk555cLh46heWbdgYdSUTkVxKmiMTy7KwDaVmnCq9f25HduXlc9OwUluZsDzqSiMh/SZgiEq9a1K7MyP4dcYeLn53KwvXbgo4kIvL/VETiQNOalXhjQEdSko0+Q6cyacmmoCOJiAAqInGjcfWKjBrQiUrpqVw2bBpXDP+aeWvjY3xHRMquuC4iZnaemT1nZm+Y2elB5ylp9atWYNwfunPnWc35dvUWzh4yiZtHzmb1D5q9JSLBCKyImNlwM8sxs7kFzvcws0VmttTMbj/YZ7j7e+7eD7gOuLgk88aK9NRk+ndvzITbTuL6Exvz0dz1nPzQF9z9/jw2a7kUESll5u7B3NisO7ADeNndW4bPJQOLgdOAbGA60AdIBu4r8BHXuHtO+H0PAa+5+6xD3TcrK8tnzJgRtf+OoK3fuotHP13MqBmrKZ+WQv/ujejbtSEVyiXMzsciUgrMbKa7Z/3qfFBFBMDMGgBj8hWRTsDd7n5G+PgOAHcvWED2v9+AfwGfuPunB7lPf6A/QEZGRruVK1dG8b8iNizN2c4DYxcxdt4GqlUsx+BTMundPoPU5LjusRSRGHGgIhJrf8PUAVbnO84OnzuQQcCpwIVmdt2BLnL3oe6e5e5Z1atXj07SGJNZoxLPXp7F29d3plG1CvztP/M47eEvGTNnLXl5wf1DQUTKtlgrIoXi7kPcvZ27X+fuzxzs2nh7Yr2o2tU/gjcGdGT4VVmUS0lm4OuzOe+pyUxeqmnBIhJ9sVZE1gD18h3XDZ+TQjAzTm5ekw8Hd+Oh3x/L5h17uPT5aVw+bBpz15TtIioipSvWxkRSCA2sn0KoeEwHLnH3edG6Z1kbWI/Err37eHXqSp74fClbftrLucfW5k+nNyOjavmgo4lInIi5MREzGwFMAZqZWbaZ9XX3XGAgMBZYAIyKVgFJlO6s35Kemsy13Rox4baTuPGkxoybv55THg5NC9YuiiJSHIG2RIKQiC2RgjZs28Vj45fwxvTVpKck0a97I67t1oiKmhYsIgcQk1N8S5OZ9QR6ZmZm9luyZEnQcWLC9xt38ODYRXw0dz3VKqYx6OQm9GmfQVpKrA2ViUjQEr6I7KeWyK/NXvUj//poIdOW/0DGkeX50xnNOKfVUSQlWdDRRCRGxNyYSGlL5DGRQ2mTcQQj+3fkhauPp3xaMjeNmM25T07SasEickhqich/yctz/vPtGh4cu5g1W36ma2Y1/tyjOa3qxs9mXiISfQnfEpHIJCUZv2tTl8/+dAJ/O6cF89ZupecTkxg0YjYrN2uLXhH5bwnTEtHAetFs27WX5yYs4/mJy9m7L49LOmQw6OQmVK9ULuhoIlKKNLAepu6soskJTwseOX015VKSuLZbI244sTHpqclBRxORUqDuLCmWGpXTufd3rfjkD905qVkNhoxfQs/HJ7FgnfZ8F0lkKiJSKI2qV+TJS9vySt/2bP15L72emMzwSctJtBatiIQcsoiY2WnhLWiPCx/3j+S1WKMpvtHVrUl1Phrcje5Nq/H3MfO56oXpbNyuJVREEk0kLZFrgFuBy8zsZOC4CF+LKe4+2t37V6miqarRUrViOZ67Iov/Pa8lU5dtpsejE/h8YU7QsUSkFEVSRLa7+xZ3/xNwOnB8hK9JAjAzLu9YnzGDulK9UjmufnE6d78/j1179wUdTURKQSRF5IP9v7j77cDLEb4mCaRJzUq8d2MXrunSkBe/WkGvJyazaP32oGOJSAnTFF+Jui8W5fCnN+ewbdde/nLW0VzRqT5mWodLJJ4V6zkRM8uI8D5b3D0m53zqYcPStWnHbm5981s+X7SRk5vX4N8XtqZaRT2gKBKviltEPo/gHg686O4x3aWllkjpcXde+moF//xoIZXTU3noomM5oWn1oGOJSBHoifUwFZHSt3D9NgaP+IZFG7ZzTZeG/PnMZpRL0ZPuIvHkQEUkoq3sykJ3lgSnea3K/GdgF+77cAHDJy9nyrLNDOl9HE1qVgo6mogUk7qzpFR9tnADt745hx27c/nrOS24rEOGBt1F4kCZ7M4ys6OBwUA1YLy7P32o96iIBC9n+y5ufXMOXy7eyKlH1+TfF7bmyAppQccSkYOIuQUYzWy4meWY2dwC53uY2SIzW2pmtx/sM9x9gbtfB1wEdCnJvBI9NSql88JVx/O3c1owYfFGejw6QbsoisSpIBdgfBHokf+EmSUDTwJnAi2APmbWwsxamdmYAj81wu85l9BDjx+WbnwpjqQko2/Xhrx3YxeqHJbKZcOmce8H89mdqyfdReJJoN1ZZtYAGOPuLcPHnYC73f2M8PEdAO5+XwSf9YG7n32A1/oD/QEyMjLarVy5Mir5JTp+3rOPez+cz6tTV3FM7co81rsNmTUqBh1LRPKJaneWmVUItxqirQ6wOt9xdvjcgXKcaGZDzOxZDtIScfeh7p7l7lnVq+s5hVhzWFoy/zivFc9dkcXaLT9zzuMTeX3aKi0vLxIHIioiZpZkZpeY2QdmlgMsBNaZ2Xwze8DMMks25m9z9y/c/SZ3H+DuTx7sWi0FH/tOa1GTj2/uTlb9I7nz3e+47tWZ/LhzT9CxROQgIm2JfA40Bu4Aarl7PXevAXQFpgL3m9llUcizBqiX77hu+JwkiJqV03n5mvb85ayj+WxhDmc+NpGvlmrQXSRWRfqcSKq77y3uNb/xngb895hICrAYOIVQ8ZgOXOLu8wrzuQejKb7xY+6ardw0cjbLN+1kQPfG/PG0pqSlaDNOkSAUa0zE3feaWR0zu8LMBoXHIqzgNYUMNAKYAjQzs2wz6+vuucBAYCywABgVrQKi7qz407JOFcYM6krv4zN45svvueDpr1i2cUfQsUQkn0hbIqcDLwFfALuBY4FKwFXuPqkkA0abWiLx6eO567n9nTns3pvHPecew++z6upJd5FSVNzZWf8Aurl7H3e/yt3bAJcDz5hZ52gGLSlqicS3Hi1r8fHg7rTJOJzb3p7Dja/PYutPhWr8ikgJiLSIpLn70vwn3H0KcD7wz6inKgHaYz3+1aqSzqt9O3D7mc0ZN28DPR6bwNRlm4OOJZLQIi0iu8zsVw9YuPtiIC7+VlZLpGxISjKuO6Ex79zQmfTUZPo8N5Uh45eQl6dnSkSCEGkReQB4z8xq5z9pZtUK8RmBUkukbGld93DGDOpKr2Nr8/Ani7nqxen8oGdKREpdRPuJuPvbZlYOmGJmM4FvgTRCCx/+bwnmEzmgCuVSeOTi4zi+4ZHc8/58zh4ykScvbUvbjCOCjiaSMCJuRbj768DRwBhCXVh7gN6xvn/IfurOKpvMjEs71Oft6zuTkmxc9MwUhk9ariVTREpJpFN8U4DWwGJ3j+uJ+priW3Zt/Wkvt7z5LZ8u2MBZrWpx/wWtqZSeGnQskTKhuFN8RwFvALPNrKuZjTOz2eF1s9KjmlSkiKqUT+W5K9pxx5nNGTtvA+c+MZkF67Rbs0hJirSItAKaAmcT6s56Gbgy/P4HSyaaSOGZGQNOaMyIfh3ZuTuX856czKgZqw/9RhEpkkiLyHYPWQysdfdX3X0O8CegQ8nFix6NiSSW9g2P5IObutGu/hHc9tYcbnvrW3bt1YZXItEWaRGpFV43qzWhAXUAPDSgoim+EpOqVyrHK307MOjkTEbNyOa8JyezfNPOoGOJlCmRFoC7geOBx4G6ZjbPzN40s78D2uVJYlZyknHL6c144erjWb9tFz0fn8RH360LOpZImRHpKr5D3X2Qu5/g7tWAM4DhwE5gQkkGFImGk5rV4IObupFZoyLXvzaLe0bPY09uXtCxROJeRA8bFuTu2YS2rv0ounFESk6dww9j1IBO/PPDBbwweQXfrN7Ck5e0pfbhhwUdTSRuFXs8w8wmRyNISdPAugCkpSRx97nH8OQlbVm8fjtnD5nIl4s3Bh1LJG5FY1C89qEvCZ4G1iW/s1sfxehBXalZOZ2rXviahz9ZzD4t4ihSaBEVETN73Mz6m1knM6tU4GX9yZO41Kh6Rd69oQsXtK3LkPFLuHL412zasTvoWCJxJdKWyHeEHjj8F7DCzJab2ftmdi+hHQ5F4tJhack8+Ptj+fcFrZm+4gfOHjKR6St+CDqWSNyItIhMzjc7qyrQDXga2EZoP3SRuHbR8fX+f4+S3kOn8tyEZVrEUSQCkRaRV/b/YmbXunu2u3/k7vcD/UsmWmTMrIKZzTCzc4LMIfHvmNpVGD2oK6cdXZN7P1zAgFdmsvVnbcErcjCRFhHL9/sNBV6bWJQbm9lwM8sxs7kFzvcws0VmttTMbo/go/5MaIFIkWKrnJ7K05e15a9nH81nC3Po+fgk5q7RjD6RA4m0iORv11uB14o6w+tFoEf+E2aWDDwJnAm0APqYWQsza2VmYwr81DCz04D5QE4RM4j8iplxbbdGvDGgI3v35XH+01/x+rRV6t4S+Q2RPmxYy8yuIrSjYcEiUqQ/We4+wcwaFDjdHljq7ssAzGwk0Mvd7wN+1V1lZicCFQgVnJ/N7EN312PIEhXt6h/JmEFdufmNb7jz3e+YseIH/vG7lpRPK9IzuiJlUqR/Gu4G2gFXE1o7az6wAFgIVItinjpA/nW7sznIKsHu/heAcIHbdKACYmb9CY/dZGRkRCurJICqFcvx4tXtefyzJTw2fglz127lqUvbkVmjYtDRRGJCpHusD81/bGZ1CU35bU0MrJ3l7i8e4vWhZrYO6JmWltaudFJJWZGcZNx8alPa1T+CwSO/odcTk7jvgtace2xcPGcrUqKKNJ4RXjtrtrvf7+6XRTHPGqBevuO64XMigevWpDof3NSV5kdV5qYRs7nrP3PZnas9SiSxFWfZkw+jluIX04EmZtbQzNKA3sD70fhgLXsi0XBUlcMY2b8j/bo15KUpK7nomSlk//hT0LFEAlOcIlJwgL1wbzYbAUwBmplZtpn1dfdcYCChBxgXAKPcfV5x7pPvflqAUaIiNTmJv5zdgmcua8uyjTs5e8gkxi/YEHQskUBYUactmtn17v50lPOUuKysLJ8xY0bQMaSMWLFpJze8Nov567bR+/h6/OXso6mUnhp0LJGoM7OZ7p71q/ORFBEzO2iXkrufW4xspcLMegI9MzMz+y1ZsiToOFKG7Nq7j0c+XcxzE5ZRq3I691/Ymm5NtOGnlC3FLSIbCU29HQFMo0BXlrt/GaWcJU4tESkps1b9yK1vfsv3G3fSp30Gd57VXK0SKTMOVEQiHROpBdwJtAQeA04j9FzGl/FSQDQmIiWtbcYRfHBTNwZ0b8Qb01fR49GJTFyiDa+kbIt0j/V97v6xu18JdASWAl+Y2cASTRdFmp0lpSE9NZk7zjqaN6/rTLmUJC4f9jV3vPMdO3bnBh1NpEREPDvLzMqZ2fnAq8CNwBDg3ZIKJhLP2tU/gg8Hd6N/90aMnL6KMx6ZwKQlm4KOJRJ1kY6JvEyoK+tDYKS7zz3EW2KOBtYlKDNXhsZKlm3ayaUdMrjjrKOpWE7rb0l8Ke7Aeh6wM3xYcEVfd/fKUUlZCjSwLkHYtXcfD41bxPOTllO7ymE8cGFrOmdGc9k5kZJVrIF1d09y90rhn8r5firFUwERCUp6ajJ/ObsFbw7oRFpKEpc8P42/vvcdOzVWInGuOE+sA2BmN0cjiEgiyGpwJB/e1I2+XRvy2rRVnPHoBL76XmMlEr+KXUSAP0bhM0qcpvhKrDgsLZm/ndOCUQM6kZJkXPLcNP723ly1SiQuRaOIFGsNrdKiKb4Sa45vcCQfDe7ONV0a8uq0lfR4bAJTvt8cdCyRQolGEdGeoSJFdFhaMv/TswVv9O9Eshl9npvKXf+Zy0971CqR+BBRETGz7Wa27Td+thPajVBEiqF9w1Cr5OouDXh56kp6PDqRqcvUKpHYF+nsrIKzsvLPzkou6ZAiieCwtGTu6nkMI/t1BKD30Knc/f48tUokphWrO8vMuprZk9EKU5I0sC7xokOjqnx8czeu6tyAF79awZmPTWSaWiUSowq9n4iZtQEuAS4C1gPN3T1uRqv1sKHEk6nLNnPbW3NY/eNPXNmpAbf1aEb5ND3tLqWvWA8bmllTM7vLzBYBzwGbgBPdvQPwQ3Sjish+HcOtkis7/dIq+Xq5/shJ7Ii0O2shcBZwobtnufv97r48/JpmZ4mUoPJpKdx97jGM6NeRPHcuHjqFe0bP4+c9+4KOJhJxETkfWA6MM7NXwuML2m1HpBR1alyVjwd35/KO9Xlh8grOfGwC01eoVSLBinR21nvu3hvIBD4C+gPZZvYCENjaWWZ2oplNNLNnzOzEoHKIlJYK5VL4e6+WvN6vA7l5zkXPTuHvo+erVSKBKdTsLHff6e6vu3tPoDkwBZhTlBub2XAzyzGzuQXO9zCzRWa21MxuP1QkYAeQDmQXJYdIPOrcuBpjb+7OZR3qM3zycs4aMpEZapVIACJdCt78EBdGck2B67sTKgAvu3vL8LlkYDGh7XezgelAHyAZuK/AR1xDaIvePDOrCTzs7pce6r6anSVlzVdLN3Hb23NYs+Vn+nZpyC2nN+OwND2+JdFV3D3WPzezQWaWUeBD08zsZDN7CbiyMIHcfQK/ntnVHljq7svcfQ8wEujl7t+5+zkFfnLcPS/8vh+BcoW5v0hZ0TmzGh/f3J1LO2Tw/KRQq0RjJVJaIi0iPYB9wAgzW2tm881sGbCEUEvhUXd/MQp56gCr8x1nc5BlVczsfDN7FngFeOIg1/U3sxlmNmPjxo1RiCkSWyqWS+Ef57Xi9Ws7sHdfHhc9G5rBpafdpaRF9NSSu+8CngKeCs/Kqgb87O5bSjJcBLneAd6J4LqhZrYO6JmWltau5JOJBKNzZmis5P6PF/LC5BV8tjCHf1/Qmg6NqgYdTcqoQi974u573X1dCRWQNUC9fMd1w+eKTUvBS6LYP4NrRL+OuMPFQ0MrA2u/EikJ0VgKPpqmA03MrKGZpQG9gfej8cFaO0sSTafGv6zB9dKU0H4l2kVRoi3iImJm/2tm9aN1YzMbQWiKcDMzyzazvu6eCwwExgILgFHuPi9a9xRJNPufdh81ILRfiXZRlGiLeAFGM9sGrANWAM8D74b/0o8rmuIriernPft4cNwihk9eTp3DD+P+C1rTJbNa0LEkThR3ii/ABndvBvwLOBdYamYPmFmzaIUsSerOkkS3f2/3Nwd0IjU5iUufn8ad737H9l17g44mcawwRcQB3P1zd78caA38BMw1sxYlES6aNLAuEpLV4Eg+GtyNft0aMuLrVfR4dCITl2jquxRNoQfWzSzJzM4l9GzGxcDfCC3OKCJxIj01mb+c3YK3rutMudQkLh/2NXe8M4dtapVIIRWmiFQ0s38BywjNmnrM3Zu7+7/c/eeSiRc96s4S+bV29Y/gw5u6MeCERrwxfTVnPDKBLxblBB1L4khhisgPhAbW27r7Je7+WQllKhHqzhL5bempydxx5tG8fX1nKpRL4aoXpnPbW9+y9We1SuTQCr09brwys55Az8zMzH5LliwJOo5ITNq1dx9Dxi/hmS+/p0aldO47vxUnNa8RdCyJAQeanRXpKr4Zh7woZIu7bytsuNKkKb4ih/bt6i3c+ta3LN6wgwva1uV/zmlBlfLahy6RFbeIfB7BPRx40d1fLkK+UqMiIhKZ3bn7eHz8Up7+8nuqVkjjn79rxaktagYdSwJSrCJSlqiIiBTOd9lbufWtb1m4fjvnt6nD//RsweHl04KOJaUs4buzNCYiUnR7cvN44vOlPPX5Uo6okMa957Xk9GNqBR1LSpG6s8LUEhEpurlrtnLrW3NYsG4bvY6rzd09j+GICmqVJAJ1Z4WpiIgUz57cPJ76YilPfLaUw8un8o/zWtKj5VFBx5ISVqy1s8zstny//77Aa/8sfjwRiRdpKUncfGpT3h/YlRqV0rnu1VkMfH0Wm3fsDjqaBCDShw175/v9jgKv9YhSFhGJIy1qV+Y/A7twy2lNGTtvPac/MoEPv1sXdCwpZZEWETvA7791HJO07IlI9KUmJzHolCaMHtSVow5P54bXZnHDazPJ2b4r6GhSSiItIn6A33/rOCZp2RORktO8VmXevaELt57RjE/n53DCv7/ggbEL2fqTlk4p6yKdnbUP2Emo1XEYoSXgCR+nu3vcPMqqgXWRkrVs4w4e+XQJo79dS+X0FAac0JiruzSgfFpK0NGkGDQ7K0xFRKR0zFu7lYfHLWb8whyqVSzHwJMa06dDBuVSkoOOJkWgIhKmIiJSumau/IF/f7yIact/oM7hhzH41Cac36YOKcmF3s5IAhSN7XFFRAqtXf0jGdm/I6/0bU+1imnc9tYcTn90AmPmrCUvL7H+EVsWxXURCe+yeK+ZPW5mVwadR0R+m5nRrUl13ruxC89e3o6UJGPg67M55/FJfL4wh0TrESlLAisiZjbczHLMbG6B8z3MbJGZLTWz2w/xMb2AusBeILuksopIdJgZZxxTi48Gd+eRi49lx+5crn5xOr9/ZgrTlm0OOp4UQWBjImbWHdgBvOzuLcPnkoHFwGmEisJ0oA+QDNxX4COuCf/86O7Pmtlb7n7hoe6rMRGR2LEnN49RM1bz+GdL2LBtN92aVOPWM5rRuu7hQUeTAg40JhLYnDt3n2BmDQqcbg8sdfdlAGY2Eujl7vcB5xT8DDPLBvaED/cd6F5m1h/oD5CREemCxCJS0tJSkrisY30ubFeXV6as5KkvlnLuE5PpcUwtbjm9KU1qVgo6ohxCrE3crgOsznecDXQ4yPXvAI+bWTdgwoEucvehZrYO6JmWltYuKklFJGrSU5Pp170RvdvXY9ik5Tw/cTnj5q/nvDZ1+MOpTal3ZPmgI8oBxFoRKRR3/wnoG+G1o4HRWVlZ/Uo2lYgUVaX0VG4+tSlXdGrAM19+z0tfrWD0t2vpfXwGg07OpEbl9KAjSgGxNjtrDVAv33Hd8Lli09pZIvHjyApp3HnW0Xx560lclFWPEV+vovsDn3Pfhwv4ceeeQ3+AlJpYKyLTgSZm1tDM0gitHvx+wJlEJCC1qqRz7+9a8dktJ3JWy6MYOnEZ3XyK+7YAAAtGSURBVP/9OY99uoQdu3ODjicEOztrBHAiUA3YANzl7sPM7CzgUUIzsoa7+73RvK9mZ4nEr8UbtvPQuEWMnbeBIyukccOJjbmsY33SU7WUSklL+GVPtMe6SNnx7eotPDhuEROXbKJW5XRuOqUJv8+qS6qWUikxCV9E9lNLRKTsmPL9Zh4Yu5BZq7ZQv2p5/nhaU3q2rk1SUlxscxRXtHaWiJQ5nRpX5e3rOzP8qizKp6UweOQ3nPnYRMbNW6+lVEpJwrRE1J0lUrbl5TkffLeOhz9ZzPJNOzm23uHccWZzOjaqGnS0MkHdWWHqzhIp23L35fHOrDU88uli1m3dxalH1+D2M5uTWUNPvxeHikiYiohIYti1dx/DJy/n6c+/56e9++h9fD1uPrUp1SuVCzpaXEr4IqLuLJHEtHnHboaMX8Jr01ZRLiWJ609sTN+ujTgsTdOCCyPhi8h+aomIJKZlG3dw/8cLGTtvA7Uqp3PL6U05v21dkjWTKyKanSUiCa1R9Yo8e3kWowZ0omaVdG59aw5nD5nIxCUbg44W1xKmiGjtLBEBaN/wSN67oTOP92nDjt25XD7sa64c/jUL128LOlpcUneWiCSs3bn7eGXKSoaMD63F9ft29fjj6U2pqdWCf0VjImEqIiJS0Jaf9vDEZ0t5acoKUpKS6Ne9EQO6N6JCubjeLSOqNCYiInIAh5dP46/ntODTP57AyUfXYMj4JZzwwBe8Pm0Vufvygo4X01RERETC6letwJOXtOWdGzrToGp57nz3O858bCKfLdygZVQOIGGKiAbWRSRSbTOO4M3rOvHMZW3Zuy+Pa16cwaXPT2PuGv39UZDGREREDmJPbh6vT1vJY+OX8ONPezm/TR1uOaMZdQ4/LOhopUoD62EqIiJSFNt27eWpz79n+OTlAPTt2pDrT2xM5fTUgJOVDg2si4gUQ+X0VG4/szmf3XICZ7c6iqe/+J4TH/iCl75awd4EHnxXERERKYS6R5TnkYuPY/TArjStWZG73p/H6Y9MYGyC7mGiIiIiUgSt6lZhRL+ODLsyiySDAa/M5KJnpzB71Y9BRytVcT0mYmbdgEuBFKCFu3c+1Hs0JiIi0Za7L483ZqzmkU8Ws2nHHs5pfRR/7tGcekeWDzpa1MTcmIiZDTezHDObW+B8DzNbZGZLzez2g32Gu0909+uAMcBLJZlXRORAUpKTuLRDfb649SRuOjmTTxds4JSHvuQfY+az5ac9QccrUYG1RMysO7ADeNndW4bPJQOLgdOAbGA60AdIBu4r8BHXuHtO+H2jgL7uvv1Q91VLRERK2vqtu3ho3CLempVNpXIpXN6pPld2akCNOF6TKyan+JpZA2BMviLSCbjb3c8IH98B4O4FC0j+z8gA/ubu/Q5yTX+gP0BGRka7lStXRus/QUTkgOav3cajny7mkwUbSEkyzj22Dn27NqRF7cpBRyu0AxWRWFtdrA6wOt9xNtDhEO/pC7xwsAvcfaiZrQN6pqWltSteRBGRyLSoXZmhV2SxYtNOXpi8nFEzsnl7VjZdMqtybddGnNC0OklxvilW3M/Ocve73P2rCK4b7e79q1SpUhqxRET+X4NqFbinV0um3nEKf+7RnKU5O7j6xemc9siXvD5tFbv27gs6YpHFWhFZA9TLd1w3fK7YtHaWiAStSvlUrj+xMRNvO5lHLz6O9NRk7nz3Ozr/6zMeHreInO27go5YaLE2JpJCaGD9FELFYzpwibvPi9Y9NbAuIrHC3Zm2/Aeen7ic8Qs3kJqURK/jatO3W0Oa14qtcZOYGxMxsxHAiUA1M8sG7nL3YWY2EBhLaEbW8GgVEDPrCfTMzMyMxseJiBSbmdGxUVU6NqrKso07eGHyCt6cuZo3Z2bTrUk1ru3WiO5NqmEWu+Mmcf2wYVGoJSIisezHnXt4/etVvPTVCnK276ZJjYpc260hvY6rQ3pqcmC5YnKKb2nK1xLpt2TJkqDjiIgc1J7cPMbMWctzE5ezYN02qlZI4/JO9bmsY32qVSxX6nkSvojsp5aIiMQTd2fKss0Mm7ic8QtzSEtJ4vw2oedNmtSsVGo5Er6IqCUiIvFuac4Ohk9eztszs9mdm8cJTatzbbeGdM0s+XGThC8i+6klIiLx7oede3ht6kpemrKSTTt206xmJfp2a0iv42pTLqVkxk1URMJURESkrNidu4/3v1nLsEnLWbh+O9UqluOKTvW5tEMGVaM8bpLwRUTdWSJSVrk7k5du5vlJy/hi0UbKpSRxftu69O3akMwaFaNyj4QvIvupJSIiZdmSDdtD4yaz1rAnN4+Tm9fg2q4N6dS4arHGTVREwlRERCQRbNqxm9emruKVqSvYtGMPzWtV4qVr2lOziMvRx9wT66VNT6yLSCKpVrEcg09twoATGvH+N2v5dMEGqpfA8yVqiYiIyCHF3Pa4IiIS/1RERESkyFRERESkyBKmiGhTKhGR6EuYIqLtcUVEoi9hioiIiESfioiIiBSZioiIiBRZwj1saGYbgZVFfHs1YFMU48Q7fR+/0Hfx3/R9/KKsfBf13b16wZMJV0SKw8xm/NYTm4lK38cv9F38N30fvyjr34W6s0REpMhUREREpMhURApnaNABYoy+j1/ou/hv+j5+Uaa/C42JiIhIkaklIiIiRaYiIiIiRaYiEgEz62Fmi8xsqZndHnSeIJlZPTP73Mzmm9k8MxscdKZYYGbJZjbbzMYEnSVIZna4mb1lZgvNbIGZdQo6U5DM7A/hPydzzWyEmRVtb9oYpiJyCGaWDDwJnAm0APqYWYtgUwUqF7jF3VsAHYEbE/z72G8wsCDoEDHgMeBjd28OHEsCfydmVge4Cchy95ZAMtA72FTRpyJyaO2Bpe6+zN33ACOBXgFnCoy7r3P3WeHftxP6S6JOsKmCZWZ1gbOB54POEiQzqwJ0B4YBuPsed98SbKrApQCHmVkKUB5YG3CeqFMRObQ6wOp8x9kk+F+a+5lZA6ANMC3YJIF7FLgNyAs6SMAaAhuBF8Jde8+bWYWgQwXF3dcADwKrgHXAVncfF2yq6FMRkSIxs4rA28DN7r4t6DxBMbNzgBx3nxl0lhiQArQFnnb3NsBOIGHHEM3sCEK9Fg2B2kAFM7ss2FTRpyJyaGuAevmO64bPJSwzSyVUQF5z93eCzhOwLsC5ZraCUFfnyWb2arCRApMNZLv7/pbpW4SKSqI6FVju7hvdfS/wDtA54ExRpyJyaNOBJmbW0MzSCA2MvR9wpsCYmRHq817g7g8HnSdo7n6Hu9d19waE/t/4zN3L3L82I+Hu64HVZtYsfOoUYH6AkYK2CuhoZuXDf25OoQxONEgJOkCsc/dcMxsIjCU0u2K4u88LOFaQugCXA9+Z2Tfhc3e6+4cBZpLYMQh4LfwPrmXA1QHnCYy7TzOzt4BZhGY1zqYMLoGiZU9ERKTI1J0lIiJFpiIiIiJFpiIiIiJFpiIiIiJFpiIiIiJFpiIiUoLMbEc8fKZIUamIiIhIkamIiJQSM7vVzKab2Rwzuyd87l9mdmO+a+42sz8d6HqRWKMiIlIKzOx0oAmhrQWOA9qZWXfgDeCifJdeBLxxkOtFYoqWPREpHaeHf2aHjysCTdx9mJnVMLPaQHXgR3dfHd4x8lfXAxNKObfIQamIiJQOA+5z92d/47U3gQuBWoRaJoe6XiRmqDtLpHSMBa4J78OCmdUxsxrh194gtALwhYQKyqGuF4kZaomIlAJ3H2dmRwNTQquCswO4jNCGVvPMrBKwxt3XHer6QP4DRA5Aq/iKiEiRqTtLRESKTEVERESKTEVERESKTEVERESKTEVERESKTEVERESKTEVERESK7P8AloAfwTJZPq0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpc.plot_convergence(x_repeated, y_repeated, max_level=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
