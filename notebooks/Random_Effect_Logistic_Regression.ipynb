{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Effect Logistic Regression by MLMC Variational Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Effect Models:\n",
    "For $n=1,...,N$,\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$Z_n \\sim N(0,\\tau^2)$\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$Y_{n,t} \\sim \\text{Bernoulli}\\left(\\frac{1}{1+\\exp(- Z_n - \\beta_0 - \\beta^T x_{n,t})}\\right)$\n",
    "<br>\n",
    "for $t=1, ..., T$. This model carries out dimentionality reduction of binary observations $y_{n,k}$'s. Here, the dimention of $\\beta$ and $x_{n,t}$ is $D$.<br>\n",
    "As variational approximation of the posterior $p(z_n|y_n)$, we use $q(z_n)= N(z_n;\\mu_n, \\sigma_n^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Possible Extension:\n",
    "\n",
    "By adding $\\bar x_n=\\frac{1}{T}\\sum_t x_{n,t}$ to the predictors as \n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$Y_{n,t} \\sim \\text{Bernoulli}\\left(\\frac{1}{1+\\exp(- Z_n - \\beta_0 - \\beta^T x_{n,t}- \\gamma\\bar x_n)}\\right)$,\n",
    "<br>\n",
    "we can obtain correlated random effect models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We do not consider the use of Renyi divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn GPUs off\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import bernoulli, norm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x:1/(1+np.exp(-x))\n",
    "\n",
    "as_tf_float = lambda x: tf.cast(x, tf.float64)\n",
    "\n",
    "def tf_logsumexp(ary, axis=1, keepdims=False):\n",
    "    return tf.math.reduce_logsumexp(ary, axis=axis, keepdims=keepdims)\n",
    "\n",
    "def tf_logmeanexp(ary, axis=1, keepdims=False):\n",
    "    return tf.math.reduce_logsumexp(ary, axis=axis, keepdims=keepdims) \\\n",
    "        - tf.math.log(as_tf_float(ary.shape[axis]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "D = 3\n",
    "T = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "# We assume that we have infinite amount of data.\n",
    "# Thus, generator of the data is implemented.\n",
    "def generate_data(N, D, T, beta0, beta, ln_tau):\n",
    "    z = np.random.randn(N) * np.exp(ln_tau)\n",
    "    x = np.random.randn(N*T*D).reshape([N,T,D])\n",
    "    y = bernoulli(p=sigmoid(beta0+x@beta+z.reshape([N,1]))).rvs()\n",
    "    return x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramters\n",
    "ln_tau = np.float64(0.7)\n",
    "beta0 = np.float64(0.)\n",
    "beta  = np.random.randn(D) / np.sqrt(D)\n",
    "param0 = {\n",
    "    'ln_tau': ln_tau,\n",
    "    'beta0': beta0,\n",
    "    'beta': beta\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y,z = generate_data(N, D, T, beta0, beta, ln_tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Normal Integral Approximation of Evidence\n",
    "\n",
    "Ref: Barber Bishop(1998), PRML(2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_normal_prob(x, beta0, beta, ln_tau):\n",
    "    N, T, D  = x.shape\n",
    "    kappa = 1 / (1 + np.pi*tf.exp(ln_tau*2)/8)**(1/2)\n",
    "    return tf.math.sigmoid( kappa * (beta0 + tf.reshape( x@tf.reshape(beta, [D,1]), [N, T])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_normal_likelihood(x, y, beta0, beta, ln_tau):\n",
    "    pred_prob = sigmoid_normal_prob(x, beta0, beta, ln_tau)\n",
    "    score = tf.reduce_mean(tf.reduce_sum(\n",
    "        tf.math.log(pred_prob)*y + tf.math.log(1-pred_prob)*(1-y), \n",
    "        axis=1))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Approximation of Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_approx(x, y, beta0, beta, ln_tau):\n",
    "    N, T, D  = x.shape\n",
    "    z = np.zeros([N, 1])\n",
    "    _sig = lambda z: sigmoid( z + beta0 + x@beta )\n",
    "    for i in range(10):\n",
    "        sig = _sig(z)\n",
    "        hessian = 1/np.exp(ln_tau*2) + np.sum( sig*(1-sig), axis=1, keepdims=True)\n",
    "        grad    = z/np.exp(ln_tau*2) + np.sum( sig - y,     axis=1, keepdims=True)\n",
    "        z -= grad / hessian\n",
    "    mu = z.reshape([N])\n",
    "    sigma = (1 / hessian).reshape([N])**(1/2)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.040722523167153, 2.0913584603307)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.var(), (z-mu).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IWELBO approximation of Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma):\n",
    "    \"\"\"\n",
    "    Compute IWELBOs for i = 1,...,n using n_MC samples Zn. \n",
    "    Here, we assume that n<N where N is the size of data.\n",
    "    \n",
    "    Arguments:\n",
    "    x: 3-d array of size [N, T, D]\n",
    "    y: 2-d array of size [N, T]\n",
    "    z: 1-d array of size [n_MC, N]\n",
    "    beta: 1-d array of size [D]\n",
    "    mu: 1-d array of [N]\n",
    "    sigma**2: 1-d array of [N]\n",
    "    \n",
    "    Returns:\n",
    "    iwelbo: iwelbo, whose size is [N]\n",
    "    \"\"\"\n",
    "\n",
    "    (N, T, D), (n_MC, n) = x.shape, z.shape\n",
    "    y = as_tf_float( tf.reshape(y, [1,N,T]) )\n",
    "    mu = tf.reshape(mu, [1,N])\n",
    "    sigma = tf.reshape(sigma, [1,N])\n",
    "    \n",
    "    y_logits = tf.convert_to_tensor( beta0\\\n",
    "                                    + tf.reshape( x@tf.reshape(beta, [D,1]), [1, N, T])\\\n",
    "                                    + tf.reshape(z, [n_MC, N, 1]) \n",
    "                                   )\n",
    "    p_y = tfp.distributions.Bernoulli(logits=y_logits)\n",
    "    p_z = tfp.distributions.Normal(loc=np.zeros([1, N]), scale=tf.exp(ln_tau))\n",
    "    q_z = tfp.distributions.Normal(loc=mu, scale=sigma)\n",
    "    \n",
    "    log_prob_ratio = \\\n",
    "        tf.reduce_sum( p_y.log_prob(y), axis=2)\\\n",
    "        + p_z.log_prob(z)\\\n",
    "        - q_z.log_prob(z)\n",
    "    \n",
    "    iwelbo = tf_logmeanexp(log_prob_ratio, axis=0)\n",
    "    return iwelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC):\n",
    "    N, = mu.shape\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    iwelbo = tf.reduce_mean( pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma) )\n",
    "    return iwelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "signorm_likelihood = sigmoid_normal_likelihood(x, y, beta0, beta, ln_tau).numpy()\n",
    "elbo_likelihood = IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=1).numpy()\n",
    "iwelbo_likelihood = IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=64).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.2551747154340933, -1.2160373696810574, -1.2045896910231413)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signorm_likelihood, elbo_likelihood, iwelbo_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood by Different Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training signorm...\n",
      "#iter: 0,\tloss: 1.3862943611198904\n",
      "#iter: 200,\tloss: 1.2217970323912979\n",
      "#iter: 400,\tloss: 1.237592319718629\n",
      "#iter: 600,\tloss: 1.3017981438105557\n",
      "#iter: 800,\tloss: 1.27793907350506\n",
      "#iter: 1000,\tloss: 1.293333759457593\n",
      "#iter: 1200,\tloss: 1.2156717556754963\n",
      "#iter: 1400,\tloss: 1.308241073614156\n",
      "#iter: 1600,\tloss: 1.2951134878649435\n",
      "#iter: 1800,\tloss: 1.2591591275898113\n",
      "#iter: 2000,\tloss: 1.2131721435804903\n",
      "\n",
      "training elbo...\n",
      "#iter: 0,\tloss: 1.3559846013419303\n",
      "#iter: 200,\tloss: 1.352333755944922\n",
      "#iter: 400,\tloss: 1.3232539331865383\n",
      "#iter: 600,\tloss: 1.2142758573708725\n",
      "#iter: 800,\tloss: 1.2728658999639826\n",
      "#iter: 1000,\tloss: 1.252530686934901\n",
      "#iter: 1200,\tloss: 1.3728023136581877\n",
      "#iter: 1400,\tloss: 1.3931981043795685\n",
      "#iter: 1600,\tloss: 1.2946185025280095\n",
      "#iter: 1800,\tloss: 1.312024261335532\n",
      "#iter: 2000,\tloss: 1.2812556448652321\n",
      "\n",
      "training iwelbo8...\n",
      "#iter: 0,\tloss: 1.3609091796448791\n",
      "#iter: 200,\tloss: 1.20924912331626\n",
      "#iter: 400,\tloss: 1.2273941103203396\n",
      "#iter: 600,\tloss: 1.1751503463589978\n",
      "#iter: 800,\tloss: 1.2180657400357777\n",
      "#iter: 1000,\tloss: 1.2438198279305137\n",
      "#iter: 1200,\tloss: 1.28027962919228\n",
      "#iter: 1400,\tloss: 1.2479240172288726\n",
      "#iter: 1600,\tloss: 1.2309711423728829\n",
      "#iter: 1800,\tloss: 1.183820445418628\n",
      "#iter: 2000,\tloss: 1.2685673295723243\n",
      "\n",
      "training iwelbo64...\n",
      "#iter: 0,\tloss: 1.3771262965001143\n",
      "#iter: 200,\tloss: 1.2086724674498572\n",
      "#iter: 400,\tloss: 1.2865288388017577\n",
      "#iter: 600,\tloss: 1.2833430540036357\n",
      "#iter: 800,\tloss: 1.1592099130052242\n",
      "#iter: 1000,\tloss: 1.2008038863841373\n",
      "#iter: 1200,\tloss: 1.2179137673514777\n",
      "#iter: 1400,\tloss: 1.2600895817598745\n",
      "#iter: 1600,\tloss: 1.1806472143670013\n",
      "#iter: 1800,\tloss: 1.2229835412998282\n",
      "#iter: 2000,\tloss: 1.1651664590113904\n",
      "\n",
      "training iwelbo512...\n",
      "#iter: 0,\tloss: 1.352821509715243\n",
      "#iter: 200,\tloss: 1.2825622738469207\n",
      "#iter: 400,\tloss: 1.2454807834361505\n",
      "#iter: 600,\tloss: 1.1911994089974804\n",
      "#iter: 800,\tloss: 1.2054845624456456\n",
      "#iter: 1000,\tloss: 1.2033402126013184\n",
      "#iter: 1200,\tloss: 1.2079681895182892\n",
      "#iter: 1400,\tloss: 1.1880111983618717\n",
      "#iter: 1600,\tloss: 1.259011681039675\n",
      "#iter: 1800,\tloss: 1.2451508793524244\n",
      "#iter: 2000,\tloss: 1.1791000720231208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "objectives = {\n",
    "    \"signorm\": lambda beta0, beta, ln_tau, mu, sigma: sigmoid_normal_likelihood(x, y, beta0, beta, ln_tau),\n",
    "    \"elbo\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=1),\n",
    "    \"iwelbo8\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=8),\n",
    "    \"iwelbo64\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=64),\n",
    "    \"iwelbo512\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=512)\n",
    "}\n",
    "params = {\"ground_truth\": param0}\n",
    "\n",
    "N,T,D = (1000, 2, 3) if tf.test.is_gpu_available() else (100, 2, 3)\n",
    "\n",
    "for obj_name, obj_func in objectives.items():\n",
    "    \n",
    "    print(\"training {}...\".format(obj_name))\n",
    "    \n",
    "    beta0_ = tf.Variable(0, dtype=tf.float64)\n",
    "    beta_  = tf.Variable(np.zeros([D]), dtype=tf.float64)\n",
    "    ln_tau_   = tf.Variable(0, dtype=tf.float64)\n",
    "    \n",
    "    # Gradient Descent\n",
    "    for t in range(2001):\n",
    "        \n",
    "        rho_t = 0.5/(1+t)**0.7\n",
    "        x,y,_ = generate_data(N, D, T, beta0, beta, ln_tau)\n",
    "\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch([beta0_, beta_, ln_tau_])\n",
    "            mu, sigma = laplace_approx(x, y, beta0_.numpy(), beta_.numpy(), ln_tau_.numpy())\n",
    "            score = obj_func(beta0_, beta_, ln_tau_, mu, sigma)\n",
    "        dbeta0_, dbeta_, dln_tau_ = g.gradient(score, [beta0_, beta_, ln_tau_])\n",
    "\n",
    "        beta0_ = beta0_ + rho_t*dbeta0_\n",
    "        beta_ = beta_ + rho_t*dbeta_\n",
    "        ln_tau_ = ln_tau_ + dln_tau_\n",
    "        if t%200==0:\n",
    "            print(\"#iter: {},\\tloss: {}\".format(t, -score.numpy()))\n",
    "    \n",
    "    params[obj_name] = {\n",
    "        'ln_tau': ln_tau_.numpy(),\n",
    "        'beta0': beta0_.numpy(),\n",
    "        'beta': beta_.numpy()\n",
    "    }\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def expand(key, val):\n",
    "    # expand {\"name\":array([1,2,3,4,5])}\n",
    "    # into {\"name1\":1, \"name2\":2, ..., \"name5\":5}\n",
    "    if type(val)==np.ndarray:\n",
    "        return {key+str(i+1): x for i,x in enumerate(val)} \n",
    "    else:\n",
    "        return {key:val} \n",
    "\n",
    "def expand_param(param):\n",
    "    expanded_param = {}\n",
    "    for key, val in param.items():\n",
    "        expanded_param.update(expand(key,val))\n",
    "    return expanded_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ln_tau</th>\n",
       "      <th>beta0</th>\n",
       "      <th>beta1</th>\n",
       "      <th>beta2</th>\n",
       "      <th>beta3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ground_truth</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.618226</td>\n",
       "      <td>-0.661070</td>\n",
       "      <td>0.656738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signorm</th>\n",
       "      <td>-1.031685</td>\n",
       "      <td>-0.001254</td>\n",
       "      <td>-0.382790</td>\n",
       "      <td>-0.413907</td>\n",
       "      <td>0.416211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elbo</th>\n",
       "      <td>-2.617233</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>-0.395766</td>\n",
       "      <td>-0.419168</td>\n",
       "      <td>0.414593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iwelbo8</th>\n",
       "      <td>0.384991</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>-0.521739</td>\n",
       "      <td>-0.546659</td>\n",
       "      <td>0.548213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iwelbo64</th>\n",
       "      <td>0.659334</td>\n",
       "      <td>-0.006210</td>\n",
       "      <td>-0.544958</td>\n",
       "      <td>-0.590992</td>\n",
       "      <td>0.577070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iwelbo512</th>\n",
       "      <td>0.806160</td>\n",
       "      <td>-0.004337</td>\n",
       "      <td>-0.551321</td>\n",
       "      <td>-0.588699</td>\n",
       "      <td>0.583678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ln_tau     beta0     beta1     beta2     beta3\n",
       "ground_truth  0.700000  0.000000 -0.618226 -0.661070  0.656738\n",
       "signorm      -1.031685 -0.001254 -0.382790 -0.413907  0.416211\n",
       "elbo         -2.617233  0.000441 -0.395766 -0.419168  0.414593\n",
       "iwelbo8       0.384991  0.002555 -0.521739 -0.546659  0.548213\n",
       "iwelbo64      0.659334 -0.006210 -0.544958 -0.590992  0.577070\n",
       "iwelbo512     0.806160 -0.004337 -0.551321 -0.588699  0.583678"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({key: expand_param(param) for key,param in params.items()}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bottom Line: IWELBO gives better estiamte than elbo or sigmoid normal integral approximation, even for simple this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptimizer:\n",
    "    \n",
    "    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.ms_and_vs = 'uninitialized'\n",
    "        self.t = 1\n",
    "        \n",
    "    def apply_gradients(self, grads, weights):\n",
    "        \n",
    "        if self.ms_and_vs == 'uninitialized':\n",
    "            self.ms = [0 for _ in weights]\n",
    "            self.vs = [0 for _ in weights]\n",
    "\n",
    "        weights_new = []\n",
    "        ms_new = []\n",
    "        vs_new = []\n",
    "        \n",
    "        for g, w, m, v in zip(grads, weights, self.ms, self.vs):\n",
    "            m = self.beta1 * m + (1 - self.beta1) * g\n",
    "            v = self.beta2 * v + (1 - self.beta2) * np.power(g, 2)\n",
    "            m_hat = m / (1 - np.power(self.beta1, self.t))\n",
    "            v_hat = v / (1 - np.power(self.beta2, self.t))\n",
    "            w.assign_sub( self.learning_rate * m_hat / (np.sqrt(v_hat) + self.epsilon)  )\n",
    "            \n",
    "            ms_new.append(m)\n",
    "            vs_new.append(v)\n",
    "            weights_new.append(w)\n",
    "            \n",
    "        self.ms = ms_new\n",
    "        self.vs = vs_new\n",
    "        self.t += 1\n",
    "        return weights_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training signorm...\n",
      "#iter: 0,\tloss: 1.3862943611198904\n",
      "#iter: 200,\tloss: 1.3551366335215687\n",
      "#iter: 400,\tloss: 1.3161046370038891\n",
      "#iter: 600,\tloss: 1.292064100559634\n",
      "#iter: 800,\tloss: 1.2549904949612898\n",
      "#iter: 1000,\tloss: 1.306765028729184\n",
      "#iter: 1200,\tloss: 1.3057486276918246\n",
      "#iter: 1400,\tloss: 1.3383679797877923\n",
      "#iter: 1600,\tloss: 1.2904242818107678\n",
      "#iter: 1800,\tloss: 1.3044501919772995\n",
      "#iter: 2000,\tloss: 1.3672212871118155\n",
      "\n",
      "training elbo...\n",
      "#iter: 0,\tloss: 1.9059660546817634\n",
      "#iter: 200,\tloss: 1.758962148718304\n",
      "#iter: 400,\tloss: 1.7240334886935704\n",
      "#iter: 600,\tloss: 1.3957022926594274\n",
      "#iter: 800,\tloss: 1.3907655813152235\n",
      "#iter: 1000,\tloss: 1.3791367111618758\n",
      "#iter: 1200,\tloss: 1.4455348164718256\n",
      "#iter: 1400,\tloss: 1.3150371548992927\n",
      "#iter: 1600,\tloss: 1.359940167436805\n",
      "#iter: 1800,\tloss: 1.3227918753386971\n",
      "#iter: 2000,\tloss: 1.34352729767596\n",
      "\n",
      "training iwelbo8...\n",
      "#iter: 0,\tloss: 1.7776374362884935\n",
      "#iter: 200,\tloss: 1.4915073884367767\n",
      "#iter: 400,\tloss: 1.411943190960556\n",
      "#iter: 600,\tloss: 1.326100916504076\n",
      "#iter: 800,\tloss: 1.255221395693692\n",
      "#iter: 1000,\tloss: 1.3161018707205443\n",
      "#iter: 1200,\tloss: 1.1857373380418383\n",
      "#iter: 1400,\tloss: 1.2434358103806076\n",
      "#iter: 1600,\tloss: 1.2478091210613056\n",
      "#iter: 1800,\tloss: 1.2786299753784252\n",
      "#iter: 2000,\tloss: 1.293873045376398\n",
      "\n",
      "training iwelbo64...\n",
      "#iter: 0,\tloss: 1.558397966562419\n",
      "#iter: 200,\tloss: 1.4260216671370662\n",
      "#iter: 400,\tloss: 1.3265861966875172\n",
      "#iter: 600,\tloss: 1.2756732597997402\n",
      "#iter: 800,\tloss: 1.275957580828254\n",
      "#iter: 1000,\tloss: 1.292906562747438\n",
      "#iter: 1200,\tloss: 1.3009831921484771\n",
      "#iter: 1400,\tloss: 1.295302388084161\n",
      "#iter: 1600,\tloss: 1.196603141778506\n",
      "#iter: 1800,\tloss: 1.2522872449898386\n",
      "#iter: 2000,\tloss: 1.2289615489431163\n",
      "\n",
      "training iwelbo512...\n",
      "#iter: 0,\tloss: 1.509320093394324\n",
      "#iter: 200,\tloss: 1.281131109384075\n",
      "#iter: 400,\tloss: 1.2384375257242146\n",
      "#iter: 600,\tloss: 1.3147098830473678\n",
      "#iter: 800,\tloss: 1.2894543351188537\n",
      "#iter: 1000,\tloss: 1.3279116888676505\n",
      "#iter: 1200,\tloss: 1.3040408377635395\n",
      "#iter: 1400,\tloss: 1.278431115159047\n",
      "#iter: 1600,\tloss: 1.286377818984999\n",
      "#iter: 1800,\tloss: 1.291762064242859\n",
      "#iter: 2000,\tloss: 1.2679619930316313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "objectives = {\n",
    "    \"signorm\": lambda beta0, beta, ln_tau, mu, sigma: sigmoid_normal_likelihood(x, y, beta0, beta, ln_tau),\n",
    "    \"elbo\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=1),\n",
    "    \"iwelbo8\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=8),\n",
    "    \"iwelbo64\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=64),\n",
    "    \"iwelbo512\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=512)\n",
    "}\n",
    "params = {\"ground_truth\": param0}\n",
    "\n",
    "N,T,D = 1000 if tf.test.is_gpu_available() else 100, 2, 3\n",
    "\n",
    "optimizer = AdamOptimizer(learning_rate=0.0003)\n",
    "\n",
    "for obj_name, obj_func in objectives.items():\n",
    "    \n",
    "    print(\"training {}...\".format(obj_name))\n",
    "    \n",
    "    beta0_ = tf.Variable(0, dtype=tf.float64)\n",
    "    beta_  = tf.Variable(np.zeros([D]), dtype=tf.float64)\n",
    "    ln_tau_   = tf.Variable(0, dtype=tf.float64)\n",
    "    \n",
    "    weights = [beta0_, beta_, ln_tau_]\n",
    "    \n",
    "    # Adam\n",
    "    for t in range(2001):\n",
    "        \n",
    "        x,y,_ = generate_data(N, D, T, beta0, beta, ln_tau)\n",
    "\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(weights)\n",
    "            score = obj_func(*weights, mu, sigma)\n",
    "            loss = - score\n",
    "            \n",
    "        grads = g.gradient(loss, weights)\n",
    "        optimizer.apply_gradients(grads, weights)\n",
    "        \n",
    "        if t%200==0:\n",
    "            print(\"#iter: {},\\tloss: {}\".format(t, -score.numpy()))\n",
    "    \n",
    "    params[obj_name] = {\n",
    "        'ln_tau': ln_tau_.numpy(),\n",
    "        'beta0': beta0_.numpy(),\n",
    "        'beta': beta_.numpy()\n",
    "    }\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ln_tau</th>\n",
       "      <th>beta0</th>\n",
       "      <th>beta1</th>\n",
       "      <th>beta2</th>\n",
       "      <th>beta3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ground_truth</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.618226</td>\n",
       "      <td>-0.661070</td>\n",
       "      <td>0.656738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signorm</th>\n",
       "      <td>-0.544431</td>\n",
       "      <td>-0.004982</td>\n",
       "      <td>-0.398758</td>\n",
       "      <td>-0.433869</td>\n",
       "      <td>0.427887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elbo</th>\n",
       "      <td>-0.978721</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>-0.379436</td>\n",
       "      <td>-0.410909</td>\n",
       "      <td>0.418437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iwelbo8</th>\n",
       "      <td>-1.025497</td>\n",
       "      <td>-0.004721</td>\n",
       "      <td>-0.381419</td>\n",
       "      <td>-0.424836</td>\n",
       "      <td>0.417281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iwelbo64</th>\n",
       "      <td>-0.880616</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>-0.397441</td>\n",
       "      <td>-0.429447</td>\n",
       "      <td>0.419870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iwelbo512</th>\n",
       "      <td>-0.697200</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>-0.406940</td>\n",
       "      <td>-0.425994</td>\n",
       "      <td>0.437277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ln_tau     beta0     beta1     beta2     beta3\n",
       "ground_truth  0.700000  0.000000 -0.618226 -0.661070  0.656738\n",
       "signorm      -0.544431 -0.004982 -0.398758 -0.433869  0.427887\n",
       "elbo         -0.978721  0.009331 -0.379436 -0.410909  0.418437\n",
       "iwelbo8      -1.025497 -0.004721 -0.381419 -0.424836  0.417281\n",
       "iwelbo64     -0.880616  0.000940 -0.397441 -0.429447  0.419870\n",
       "iwelbo512    -0.697200  0.003073 -0.406940 -0.425994  0.437277"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({key: expand_param(param) for key,param in params.items()}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam does not work at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma):\n",
    "    \n",
    "    (N, T, D), (n_MC, N) = x.shape, z.shape\n",
    "    assert np.log2(n_MC)%1==0\n",
    "    \n",
    "    if n_MC == 1:\n",
    "        scores = pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma)\n",
    "    else:\n",
    "        scores = pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma)\n",
    "        scores -= (1/2.) * pointwise_IWELBO(x, y, z[:n_MC//2 ], beta0, beta, ln_tau, mu, sigma)\n",
    "        scores -= (1/2.) * pointwise_IWELBO(x, y, z[ n_MC//2:], beta0, beta, ln_tau, mu, sigma)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level):\n",
    "    \n",
    "    N, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    \n",
    "    diwelbo = tf.reduce_mean( pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma) )\n",
    "    return diwelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 0.14800048,  2.90518   ],\n",
       "       [-0.07132575,  1.7107816 ],\n",
       "       [ 0.06704418, -0.21650064]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(mean=[0,1], stddev=[0.1,1], shape=[3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=8, w0=1-2.**(-3/2), b=2, randomize=False):\n",
    "    \n",
    "    N, T, D = x.shape\n",
    "\n",
    "    levels = np.arange(max_level)\n",
    "    weights = 2.**(-(b+1)/2*levels)\n",
    "    weights /= sum(weights)\n",
    "    weights = np.concatenate([[w0], (1-w0)*weights])\n",
    "    \n",
    "    if randomize==True:\n",
    "         Ns = np.random.multinomial(n=N, pvals=weights)\n",
    "        \n",
    "    elif randomize==False:\n",
    "        Ns = np.zeros_like(levels)\n",
    "        Ns = np.array([np.math.ceil(w*N) for w in weights], dtype=np.int)\n",
    "        Ns[0] = N - sum(Ns[1:])\n",
    "    \n",
    "    else:\n",
    "        raise(Exception(\"Invarid argument for 'randomize' of function IWELBO_MLMC. It must be True or False.\"))\n",
    "    \n",
    "    N_offset = 0\n",
    "    score = 0\n",
    "    for i, l in enumerate(levels):\n",
    "        if Ns[i]==0:\n",
    "            continue\n",
    "        x_tmp = x[N_offset:N_offset+Ns[i]]\n",
    "        y_tmp = y[N_offset:N_offset+Ns[i]]\n",
    "        mu_tmp = mu[N_offset:N_offset+Ns[i]]\n",
    "        sigma_tmp = sigma[N_offset:N_offset+Ns[i]]\n",
    "                       \n",
    "        if randomize==True:\n",
    "            score += dIWELBO(x_tmp, y_tmp, beta0, beta, ln_tau, mu_tmp, sigma_tmp, level=l) * Ns[i] / N / weights[i]   \n",
    "        elif randomize==False:\n",
    "            score += dIWELBO(x_tmp, y_tmp, beta0, beta, ln_tau, mu_tmp, sigma_tmp, level=l)\n",
    "        \n",
    "        N_offset += Ns[i]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-1.2507511357956038>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=10, w0=0.90, randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-1.2222752474444256>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLMC codition check for objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_stats_dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level=1):\n",
    "    \n",
    "    N, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    \n",
    "    diwelbos = pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma).numpy()\n",
    "    iwelbos = pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma).numpy()\n",
    "    \n",
    "    return {'mean_dIWELBO':np.mean(diwelbos), \n",
    "            'mean_abs_dIWELBO':np.mean(np.abs(diwelbos)), \n",
    "            'mean_squared_dIWELBO':np.mean(diwelbos**2),\n",
    "            'var_dIWELBO':np.var(diwelbos), \n",
    "            'var_IWELBO':np.var(iwelbos)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp(l):\n",
    "    N0 = 2000000\n",
    "    x,y,_ = generate_data(N=N0//2**l, D=3, T=2, beta0=beta0, beta=beta, ln_tau=ln_tau)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)\n",
    "    return conv_stats_dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level=l)\n",
    "\n",
    "conv_stats = [tmp(l) for l in range(10)]\n",
    "conv_stats = pd.DataFrame(conv_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxU1d348c93JhtZIQuQjZ0AAQQhsiriYxWkWNyq4tNaN1Br+yjYPo/Uvp7WX2tta1uXytPWKlW7gNYd3LqopS0RWQRZEhaRJSFAEiALAbLM+f1xZyaTkGUgk7kzk+/79ZrXZO6cufebIXzPueeee44YY1BKKRX5HHYHoJRSKjg04SulVA+hCV8ppXoITfhKKdVDaMJXSqkeIsruADqSnp5uBg0aZHcYSikVVjZs2FBhjMlovT2kE/6gQYNYv3693WEopVRYEZF9bW3XLh2llOohNOErpVQPoQlfKaV6iJBM+CJypYg8XVVVZXcoSikVMUIy4RtjVhpjFqakpNgdilJKRYyQTPhKKaUCTxO+Ukr1EEFL+CKSICLPi8hvReQ/u/NY/9pVwW9X7+nOQyilVNjpUsIXkWUickREtrbaPltEdojIbhF5wL35GuBlY8wC4EtdOW5n3tlaxk/eLeaz8truPIxSSoWVrrbwnwNm+24QESewFLgCyAfmi0g+kAMccBdr6uJxO3TfF/KIjXLwk3eKu/MwSikVVrqU8I0xq4GjrTZPAnYbY/YYY+qBFcA8oAQr6Xf5uJ3JSIrl7plD+cv2w6zdU9mdh1JKqbDRHYk3m+aWPFiJPht4FbhWRH4FrGzvwyKyUETWi8j68vLycw7i9guH0D85jh+9XYTLpcs4KqVU0C7aGmNOGGNuNcbcbYz5YwflngYeAjbGxMSc8/F6xTj51qwRbC6pYuWnB895P0opFSm6I+GXArk+r3Pc24Lu6vOzyc9M5qfv7uBUQ7deNlBKqZDXHQl/HTBcRAaLSAxwI/Dm2ewgUHfaOh3Cg18cRenxkzy/Zm+X9qWUUuGuq8MylwOFwAgRKRGR240xjcA3gPeAIuAlY8y2s9xvwObSmT4snUtGZPDUB7s5eqK+y/tTSqlwJcaE7gXNgoICE4gFUHYermH246u5eeogvv+l0QGITCmlQpeIbDDGFLTeHpJTKwR6tsy8fknccMEA/vDRPj6vOBGQfSqlVLgJyYTfHbNlLrpsuN6MpZTq0UIy4XfHfPh9k+K46+KhvLvtEOv2tr5XTCmlIl9IJvzumg//jouG0C85lh++VUQoX7tQSqnuEJIJv7tWvOoV4+Rbl49g84HjrPq0LKD7VkqpUBeSCb87V7y6ZkIOozKT+cm7xZxu1JuxlFI9R0gm/O7kdAgPzhlFybGTvLBmn93hKKVU0ETZHUB32FO2kcrDm4jKOh+HOHCKs8VzVoaTKSOaeHJ1IdNHOkhNiGtZxnHmZ5ziRETs/tWUUuqchWTCF5ErgSuHDRt2Tp9/9m/38abrGGzuoJADyIUb3vF/vw5xtFmBtFVZeLZ5Hu7fCwcORARBWr52b3OIw/tee68RvJ9zYL3u9LOeY/q83+7z2ZQ5h894v49W34Fnm0OaX3t/Bz+O5/s9+/7+Z3w/7m0egrR49uyjvW2+Ov1MywOdsc1lXGc+cNFkmjDGeJ9932/xHoYml/vZNOEyrhaf82zz7Nflcj/77K/1AAbDmQMa2tzm58AHfz/rEAdRjiiiHFE4xen9OcoRRZREtXzdxjbfz0Q7ojvdh+f9aEe0d5vnb8gTo8H67g2m5Wv3z8YYXLhft1P+bMr6vs5NyiU+Ot6v79hfEXmn7Z7iNyh/fQFNE2+ladRc73+S1s8vrtvHur0VLLpsOH0Soprfc51Z1vPc0XutP+vZBnj/SFy4wNDpP3Z7f1gYvOVa7NvndYs/rFb7aev91vGcTZkW29ooo+znOTtt0QhxV7Ltnbm2qKg82/wt18a2tje13OgyLhpdjdbDNHp/DubfkiemUPj7/d2s31HQ/4ybZf3S3p22IdnC76ohI+cxJPMZ2PwazPw+RPdqs9yk9FPM/NmHbC7K4P/+c2Jwg+whOqsUPA0O72tPhWe8r1pUZO299uzbt5Jqa1++FZ9nH9DyP7j3Z5//8/5+pr0GVFvvG8wZZ4K+CdnhcD+39b7P2aY3cbvPYlpsi4BuyCaX1XhqdDXS4Gqg0dXofd1WBeF531O2rfINroZ29wH4daZ9xus2ztx99+U5e2ivbOt9D+09NODfZUQmfABmfBuevxI++QNMWtBmkb7Jcdw5YyiP/W0nG/YdZeLA1CAHGflad7codbacDidOnMQ4z319DGUJyf+FARmHP+giyJ0C/3ocGtufJXPBjMH0TdKbsZRSkS8kE35AxuGLWK386hLYvLzdYvExUXzr8hF8sv84b23Rm7GUUpErJBN+wAy7FLLOh3/9Apoa2y127cQcRvZP0puxlFIRLbITvqeVf2wvbH253WJOh/CdOaM4cPQkvy/Um7GUUpEpshM+QN4V0G8MrP4ZuNpvvc/Iy2BGXgZP/n0Xx+t0ZSylVOQJWsIXkSEi8qyItN/U7g4OB1x0P1Tugu1vdFj0O3NGUnu6kV++vztIwSmlVPD4lfBFZJmIHBGRra22zxaRHSKyW0Qe6Ggfxpg9xpjbuxLsOcufB+l57la+q91iI/sn8+WJubxQuJd9lboyllIqsvjbwn8OmO27QUScwFLgCiAfmC8i+SIyVkRWtXr0DWjUZ8vhtFr5R7bBzo7nUlh8eR5RDgc/fXdHkIJTSqng8CvhG2NWA62XiZoE7Ha33OuBFcA8Y8wWY8zcVo8j/gYkIgtFZL2IrC8vL/f7F+nUmOugzyBY/Sh0MN6+X3IcC2cM4a0tZWzYdyxwx1dKKZt1pQ8/Gzjg87rEva1NIpImIr8GzheRJe2VM8Y8bYwpMMYUZGRkdCG8VpxRcOFiOPgJ7P57h0UXzhhCRlIsD7+1XW/GUkpFjKBdtDXGVBpj7jLGDDXGPNJR2e5a8Ypx8yE5B1b/tMNWfkJsFPdflsfG/cd5Z+uhwMaglFI26UrCLwVyfV7nuLeFrqgYuPA+OLAW9v6zw6JfLshlRL8kfvxOMfWN7V/oVUqpcNGVhL8OGC4ig0UkBrgReDMQQXXnEoec/xVI7Gf15XfA6RCWzBnJ/qN1/P4jvRlLKRX+/B2WuRwoBEaISImI3G6MaQS+AbwHFAEvGWO2BSKobuvSAWuq5Gn/BZ+vhv1rOyx6cV4GFw1P58m/76KqriHwsSilVBD5O0pnvjEm0xgTbYzJMcY8697+tjEmz90v/3D3hhpABbdCfFqnrXwRYckVo6g+1cBTH+wKUnBKKdU9QnJqhW7t0gGISYCp98Duv0Lpxg6L5mclc92EHJ5fs4/9lXXdE49SSgVBSCb8bu3S8bhgAcSlwD9/3mnR+y8fgcMBP32vuPviUUqpbhaSCb/bW/gAcckw+W4oXgWHO7700D8ljoUXDWHVp2Vs3K83YymlwlNIJvygmXwnxCRac+x0YuHFQ0lPjOVHujKWUipMhWTCD0qXDkB8qrXe7bbXoKLji7KJsVEsviyP9fuO8d42vRlLKRV+QjLhB6VLx2PKPRAV51df/vUFOeT1S9SbsZRSYSkkE35QJWZAwW3w6Utw9PMOi0Y5HSyZM4q9lXX8ca3ejKWUCi8hmfCD1qXjMe2b4IiCfz3WadGZeRlcOCydJ/6+i6qTejOWUip8hGTCD2qXDkByJkz4Kmz6E1SVdFhUxJpyoepkA//3ga6MpZQKHyGZ8G0x/V7AwL+f6LTo6KwUrp2Qw+/+vZcDR/VmLKVUeNCE79F7AIy7ETY8DzWHOy1+/+V5OBzw6Hu6MpZSKjxowvd14WJwNUDhLzstmpnSiwUXDeHNzQfZdOB4EIJTSqmuCcmEH/SLth5pQ62lENctgxOVnRa/8+KhpCfG6M1YSqmwEJIJP+gXbX1ddD801MFH/9dp0cTYKBZdlsfHe4/yl+2ddwMppZSdQjLh26rvSMj/Enz8NJzsvKvmhoJchvW1bsZqaNKbsZRSoUsTfltmfBtOV1tJvxNRTgffmTOSzytO8Ke1+4MQnFJKnRtN+G3pPxbyrrC6dU7XdFr8khF9mTY0jcf/tpPqU3ozllIqNAU14YvIVSLyWxF5UUQuD+axz9qMb8PJY7Du2U6LigjfmTOK4ycb+L8PPgtCcEopdfb8TvgiskxEjojI1lbbZ4vIDhHZLSIPdLQPY8zrxpgFwF3ADecWcpDkTISh/wGFT0F95zdXjclO4erzs1n2788pOaY3YymlQs/ZtPCfA2b7bhARJ7AUuALIB+aLSL6IjBWRVa0efX0++l3350LbjP+GE+Ww8Xm/in/r8hEI8DO9GUspFYL8TvjGmNXA0VabJwG7jTF7jDH1wApgnjFmizFmbqvHEbH8BHjHGNPmYrIislBE1ovI+vLy8nP9vQJj4FQYeKE13ULj6U6LZ/XuxR0XDeb1TQfZrDdjKaVCTFf78LOBAz6vS9zb2vNN4AvAdSJyV1sFjDFPAw8BG2NiYroYXgBc/G2oKYNP/uBX8bsuHkpaQgwPv603YymlQktQL9oaY540xkw0xtxljPl1B+Xsu/GqtcEXQ84F8K/HoanzEThJcdHcd1keH39+lL/qzVhKqRDS1YRfCuT6vM5xb+sS26ZWaDsYa8RO1X749EW/PnLjBbkMzUjQm7GUUiGlqwl/HTBcRAaLSAxwI/Bm18MKMcMvh/7nWcsgupo6LR7tdLDkilHsqTjB997cxr93V1BVp+PzlVL2En/7mUVkOTATSAcOA98zxjwrInOAxwEnsMwY83CggisoKDDr168P1O66Zvub8NJX4Zpn4Lwvd1rcGMM3ln/CW5+WebcNSI1nbE4KY7Otx5isFFLio7szaqVUDyQiG4wxBWdsD8ULiyJyJXDlsGHDFuzatcvucCwuF/xqGmDg7kJw+HdydOxEPVsPVrGltIotJdZzybGT3vcHpsUzJlsrAaVU4IRVwvcIqRY+wJaX4ZXb4frfWxOsnSOtBJRS3SmsEn5ItvDB6r9/6gKISYA7V1sXdAPEUwl8WlLF1tKOK4HzslMYnZ1CSi+tBJRSZwqrhO8Rci18gE/+CG98HW56CfJmdeuhjp2ot84CSjuuBM5zVwRaCSilQBN+4DQ1wC8nQEJfuONvAW3l+8OfSmCsT3eQVgJK9TxhlfBDtkvHY/0yWLUIvvo6DL3E7mg4eqLem/y3llrdQqXHW1YC+ZnJjOifxMj+SYzon8yA1HicjuBWVkqp4AirhO8Rki18sObVeWI8pA6GW9+2O5o2ta4Eig/VsLfyBJ5/7rhoB3n9misA6zmJ9MRYewNXSnVZewk/yo5gwl5ULEy/F979H9j7bxg03e6IzpCaEMOMvAxm5GV4t9XVN7LrcC07DtVQfKiGHYereb/4CC+tL/GWSU+MYUT/JEb0a64E8vol0SvGacevoZQKoJBs4Yd8lw5Aw0l4fCz0GwM3v253NF1SUXu6uRI4VM2OQzXsPFzLyQbrrmIRGJgab1UE7rOBkf2TGJiWoN1CSoUg7dLpDv9+Av76v3DH3yHnjO82rDW5DPuP1rHjULW7IrAeeytP4PLpFhreN8nn2oD1yEiMRYJ8MVsp1UwTfnc4XWO18nOnwE0r7I4mKE41NLHrcC3F7jOBHYetM4Pymub1AlITYhjRr2VFkNcviYRY7UFUKhi0D787xCbBlHvggx9C2aeQeZ7dEXW7uGinNR9QTsupqytrT1vJv8w6Eyg+XMOL6w606BYakBrPiH5JjMzUbiGl7KAt/K46edxq5Q+9BK5/we5oQorLZThwrK5Fl1DxoWo+r2jZLeQ7WmiU+4wgTUcLKXXOwqpLJywu2vp6/4ew+mfw9Y+g70i7owl5vt1CxT4VQUVtvbdMRlKs9yzAc6F4WN9E4qJ1tJBSnQmrhO8RFi18gBOVVit/5Bfh2t/aHU3YKq857U3+xe7nnYdrqW+0FpFxOoTB6QneimBkf+tmspw+vfQisVI+tA+/OyWkwQW3Q+FTMPMBSBtqd0RhKSMploykWC4cnu7d1tjkYm9lnfcicVFZDZtLjrPKZ52BpNgo7wghz/WBEf2TSI7TKSWU8qUt/ECpOQxPnAdjr4N5S+2OJuLVnGpgp6dbyH2huOhQNTWnGr1lsnv38ib/kZnW9YHB6QlEOYO6lLNSQact/O6W1A8m3gLrnoEZ/w19BtodUURLiotm4sA+TBzYx7vNGENZ1anmLiF3RfCPneU0uq8SxzgdDOubyMjMJPIzkxnZP5lRmXqRWPUMQWvhi8go4F6sJRL/boz5VWefCasWPkBVKTw5Hs7/Ksz9hd3RKLfTjU18duQEOw5bZwNFh2ooLqvmiM+9AxlJsYxynwWMykxmZGYSQzMSidazARWGunTRVkSWAXOBI8aYMT7bZwNPYK1n+4wx5sd+7MsBvGCM+UpnZcMu4QOsvA82/RHu/RSSM+2ORnWgsvY0xYdqKCqrpqjMet59pJb6JusisZ4NqHDV1YQ/A6jFStRj3NucwE7gMqAEWAfMx0r+j7TaxW3GmCMi8iXgbuD3xpg/dXbcsEz4x/bCkxNg8p0wu/XXoEJdQ5OLPeUnKD5UzfYy9xmBng2oMNPlYZkiMghY5ZPwpwLfN8bMcr9eAmCM6TTLichbxpgvtvPeQmAhwIABAybu27fPr/hCyutfh62vwn1bIDGj8/Iq5HV2NhDtFIb1TWJUZhKj+idbFYKeDSibdMdF22zggM/rEmByBwHMBK4BYoF2J5E3xjwtImXAlTExMRO7EJ99LlwMm/5kDdO87CG7o1EBkJYYy/RhsUwf1jxktK2zgX/tquDVjaXeMno2oEJJ0EbpGGM+BD4M1vFslT4MxlxjjdiZfi/Ep9odkeoG0U6Hd/z/vPHZ3u1tnQ387rPKM84G8jOTGZ+bwvjcPozMTNJKQHW7riT8UiDX53WOe1uXGWNWAisLCgoWBGJ/trjoW7D1FXj72/CF70Pv3M4+oSKEv2cDH+44wisbrcVnYqMcjMlOYVxOb8YP6M35ub31DmIVcF3pw4/Cumh7KVaiXwfcZIzZ1uWgwm0unfa89yAULrWmisy7AibdAYNngkNbcsq6b6Dk2Ek2HTjO5gPH2XTgOFtKqzjtnkoiLSGGcbm9GZ/b23rO6U1KvN49rDrX1VE6y4GZWGPoDwPfM8Y8KyJzgMexRuYsM8Y8HMigw3KUTmvH9sGG52DjC1BXAalDrWkYxt8Evfp0+nHVszQ0udhxqIZN7gpg04HjfFZe612LeEh6grcSGJ/bm1GZycREaQNCtRRWk6dFTAvfV+Np2P6G1a9/YC1E9bKmYbjgDsgab3d0KoRVn2pgS0lVi0rAs+BMjNNBflYy43N7c/6A3ozL6c3AtHjtCurhwirhe0REC78tZZ9aiX/Ln6GhDrILrMQ/+mqIjrM7OhXijDEcrDrl7QbatN/qCvIsNtMnPppxub291wPG5/SmT0KMzVGrYAqrhB+RLfy2nDwOm1dYyb9yF/RKhQlfhYLboM8gu6NTYaSxycXOw7XuM4BjbDpwnF1HmruCBqXFt+gKys9KJjZK1xaIVGGV8D0itoXfmjHw+WpY91sofhuMC4ZfBhcsgGGXgkP/Y6qzV3u6kU9Ljre4KHy42uoKinaKe1hob8bm9GZ0VjLD+ur9AZEirBJ+j2nht6WqFDY+b13orT0MvQdaLf7zv2rNu69UF5RVnWTT/uNsKmnuCqqrt7qCYpwO8vonkp+ZzOisFPKzrLUFknRdgbATVgnfo8e08NvS1ADFq+DjZ2Dfv8AZa/XxT1oA2ROtoZ5KdVGTy/B5RS3bDlaz/aB1j8C2g9UcPdG83OSgtHjys9yVQGYy+VnJ9E2K1QvDIUwTfjg7UgTrnrX6++trIHOcdZF3zHUQE293dCrCGGM4XH2abQer2H7QqgC2l1Wz/2idt0x6YgyjfM4ERmclMygtAadDK4FQoAk/EpyugU9ftJL/ke0QlwLj/xMKbremc1CqG1WfaqDI5yxg+8Fqdh2poaHJyiG9op2MzExidFYy+ZkpjM6y1hzWheeDL6wSfo/uw/eHMbC/0Brds/0NcDXCkEusVn/ebHDqQmYqOOobXew6UtOiO6joYDU1p62lJp0OYWhGgrcryNMtpMNEu1dYJXwPbeH7oeawdRfvht9BdSkk50DBLTDha5DY1+7oVA9kjOHA0ZNsL2vZJVRWdcpbJisljvysZHdFYJ0N6NxBgaMJP9I1NcLOd61W/54PwBEN+V+yWv0DpupFXmW7ytrTFJXVsL2sytsl9Fl5Le7lhkmOi2JMdgpjs1O8z3rX8LnRhN+TVOyC9cvgkz/C6SroO9qauyd/ns7aqULKyfomdhyuYdvBKraWVrO1tIodh2q8U0knxUUxJiuFMdnJ3kpgUFoCDr043CFN+D1R/Qlriub1y+DgJ9a27AJreKcmfxWi6htd7Dxcw9bSKraUVrG1tIqiQzXUu2cRTYqNIj8rmbHZKYzNSWF0VgpD0rUS8BVWCV8v2naDys+sC7zbXoNDn1rbNPmrMNHQ5GLX4VpvJbCltIqismrvVNIJMU5GZ7m7gnKSGZOVwpCMxB47TDSsEr6HtvC7SbvJ/yp38h9gb3xK+aGxycXu8lq2lFR5K4LtZdWcarAqgfgYJ/mZzV1BY3OsM4GoHjB9hCZ81TZN/iqCNDa52FNxgi0lzd1B2w5We2cSjYt2kJ+Z3HxhOCeFYRmJEVcJaMJXnfMk/+2vQ9lma5smfxXmPNNHbCmtYktJtbsSqOKEew6h2CgHo9yVwNjsFAoG9WFwekJYjw4KiYQvIgnAP4DvG2NWdVZeE76Nju6Bba9r8lcRyeUyfF55wuoKcp8NbDtYTa37hrG+SbFMHpLGlCGpTBmSxpAwqwC6usThMmAucMSzpq17+2zgCawlDp8xxvy4k/38P6AW2K4JP4xo8lc9gKcS+Pjzo3y0p5KP9lR6p5POSIpl8mAr+U8ZksbQjNCuALqa8GdgJeoXfBYxd2ItYn4ZUIK1iPl8rOT/SKtd3AaMA9KAOKBCE36YajP5T/QZ7aPJX0UGYwz7Kuu8yf+jPUc5VG3dLZyeGMuUIalMHpLG1CGpDM1IDKkKoMtdOiIyCFjlk/CnYnXNzHK/XgJgjGmd7D2ffxhIAPKBk8DVxhhXR8fUhB/iNPmrHsQYw/6jdd7kX/hZpU8FEGN1AbnPAob1tbcC6I6Efx0w2xhzh/v1V4HJxphvdLKfW+ighS8iC4GFAAMGDJi4b98+v+JTNtPkr3oYTwWwdo/VBVS4p9I7X1BaQgxThqQx2X0NYHiQK4CQSfh+HktvvApn7SX//HmQOR7ShkFyls7voyKKZ9K4j/ZU8tHnlXz0WSUHfSqAyUNSmTw4zVsBdOedwe0l/K7Mo1sK+N6emePepnq61CFw0WLr4Zv8//q/zWWi4yF1KKQNsSoAzyN1KMSnamWgwo6IMCAtngFp8Vx/QS7GGEqOnaTQfQ1g7Z6jvL3lEACpCTFMHpxqXQgemkZe36SgTA3RlRZ+FNZF20uxEv064CZjzLZABad9+BGm+iBU7ITK3daYf8/zsb1gmprLxfX2qQSGuh/uyiA20bbwleqqAz7XAD7aU0np8ZMA9ImPZvLg5i6gEf26VgF0dZTOcmAmkA4cBr5njHlWROYAj2ONzFlmjHn4nCNseTzt0ulJmhrg2D6rAjjqqQh2Q+UeqC5pWTaxv09F4PPcZxBExdoSvlLn6sDROtb6DAMtOWZVAL3jo/nNVyYyeUjaOe03JG68OlvawlfU11ndQkc/O/PMoK6iuZw4rAvDqUPPPDtIyQWHLrOnQp+nAli7p5JvzRpBv+S4c9pPWCV8beErv5w8Zp0FtDgrcJ8Z1Nc0l3PGWNcVUt0VQN9RMPKL1prASkWgsEr4HtrCV+fEGKg90qqL6DPrcXQPNJ22LhqPuQYm3gbZE/QisYoo3TFKp9v4tPDtDkWFIxFI6mc9Bk1v+Z6rCco2wYbnYMsr8MkfoP9YmHgLjL0e4pLtiFipoNAWvuq5TlXDlj9bC8Af2gLRCTD2Wph4q9XqVypMhVWXjvbhq6AyBko3woZlsPVVaKiDzHFW4h97HcQm2R2hUmclrBK+h7bwVdCdqoJPX4L1v4Mj2yAmEcZ+2eryyRpvd3RK+UUTvlJnwxgoWWf19W99FRpPQtb5Vqt/zLV6A5gKaZrwlTpXJ4+5W/3LoLwYYpLgvOuh4Fbrgq9SISasEr724auQZAwcWGt192x7zRremV1gJf7R10BMvN0RKgWEWcL30Ba+Cll1R2HzCmuET8VOiE2BcTdYXT798u2OTvVwmvCV6g7GwL41VuLf/gY01UPuZOsi7+irIbqX3RGqHkgTvlLd7UQlbF5uJf/K3dbUDePmW63+viPtjk71IGGV8LUPX4U1Y2Dvv9yt/jfB1QADplqJP38eRJ/bhFhK+SusEr6HtvBV2DtRAZv+aA3vPLoHevWBcTdZXT4ZeXZHpyKUJnyl7ORywd7V1gif4lXgaoSBF8LkhTDii+AMyWmtVJgKq8nTlIo4DgcMmWk9ao9Yrf51y+ClmyE5By64HSZ8DRLObcELpfyhLXyl7OJqgp3vwtpfw+erwRlrTeMweaE1l49S58j2Fr6IzAR+AGwDVhhjPgzWsZUKSQ6ntRDLyC/CkSL4+GlrbP+mP1gXeSffCSPngjPa7khVhHD4U0hElonIERHZ2mr7bBHZISK7ReSBTnZjgFogDijppKxSPUvfUTD3MVi8HS5/GGrK4M+3wOPnwepHrYu/SnWRv4uYz8BK1i8YY8a4tzmBncBlWAl8HTAfa0HzR1rt4jagwhjjEpF+wC+MMf/Z2XG1S0f1WK4m2PUXWPsb2POBtUzjmOus7p6s8+2OToW4LnXpGGNWi8igVpsnAbuNMXvcB1gBzDPGPALM7WB3x4DYDgJdCCwEGDBggD/hKRV5HE4YcYX1KN9hdfdsWg6b/2TdyTtpoTWmX7t71Fnwq0unHdnAAZ/XJe5tbRKRa0TkN8DvgafaK2eMedoYU2CMKcjIyOY8dtoAABWbSURBVOhCeEpFiIwR8MWfw/1FMOsRa5TPK7fDY2PgHz+1Xivlh6BdtDXGvAq86k9ZXdNWqTbEpcDUr8Pku2D336zRPR88bPXxj77ausibPdHuKFUI60rCLwVyfV7nuLcppbqTwwF5l1uPil3w8W+tcf2fvmhN1zz5Tsi/CqJi7I5UhZiudOmsA4aLyGARiQFuBN4MTFhKKb+kD4c5P4XFRXDFT+HUcXh1ATw+Bj54BGoO2R2hCiH+jtJZDswE0oHDwPeMMc+KyBzgcayROcuMMQ8HMjgdpaPUWXK54LP34ePfWKN8HNEw+iqYdCfkFICI3RGqIAiruXR0tkylAqDys+buntPV1nDOyXdZ/f1R7Q6UUxEgrBK+R1st/IaGBkpKSjh16pRNUalzFRcXR05ODtHROpQwqE7XWHfwfvy0tTpXQoY1VXPBbZCcaXd0qhuEVcLvqIX/+eefk5SURFpaGqKnp2HDGENlZSU1NTUMHjzY7nB6JmOsm7jWPm3N4eNwwqgvQf6XIKGvVREkpENcb+vCsApbYZXwPdpq4RcVFTFy5EhN9mHIGENxcTGjRo2yOxR1dA+sexY2/h5OV7V8T5wQn2pVAPFpViUQn+6uENLcP7tfx6dbc/xrBRFSbJ88LZA02Ycn/XcLIalDYNbDcMmDcPQza66euko4Ue7+ucJ6PlEBh7ZYz6eOt70vcUCv1OYzhBaVRHqrnzPcFYQzuL+vAkI04euNV0oFSUw89B/rX9mmBnel0KpCqPN9roTD26yfTx5rZ0dinUGccdaQAYkZzd1Lie7n2CQdXRQgIZnwjTErgZUFBQUL7I5FKeXmjIak/tbDH02NcPJoq7MG91mEt5KohCPF1raTx7Am1W0lKs5dMXgqgXSrUvBUCN7tfbV7qRMhmfCVUhHAGWUl4sS+/pVvanRXBOXW/EC+z56fq0uhbLP12tV45j7E2VwhJKQ3VwreyqGv+yzC/ehhk8+FZMIPhy4dp9PJ2LHNp8I33ngjDzzwADNnzuS5555j0KBBALz++utcffXV3ovNHomJidTW1rJo0SIGDhzIfffdB8CsWbPIzc3lmWeeAeD+++8nOzubxYsX+3V83323Vd4Yg9Pp5KmnnmLatGkAlJSUcM8997B9+3ZcLhdz587l0UcfJSbGujW/9e+kVLdwRvl/BuFyWdcUvBXCEagtb/XzEev6RG05NJ5sez+9+vh0IWVAUpY1X1FKTmB/txARkgk/HLp0evXqxaZNmzott3z5cgoKCli+fDkPPfTQGe9Pnz6dl156ifvuuw+Xy0VFRQXV1dXe99esWcNjjz12zsdvq/x7773HkiVL+Mc//oExhmuuuYa7776bN954g6amJhYuXMiDDz7Io48+6vf+lQoqh8N9HSAVGNlxWWOgvtZdOVS4K4RWZw4nyq2L08Vvwb5/w+1/jci5iEIy4fvroZXb2H6wuvOCZyE/K5nvXTk6IPuqra3lww8/5C9/+Qtf/vKX20z406ZNY9GiRQBs27aNMWPGUFZWxrFjx4iPj6eoqIgJEyYEJB6P6upq+vTpA8D7779PXFwct956K2CdCTz22GMMHjyYhx56iPj4+IAeW6mgE7Eu/MYmQdrQjssWrYQXvwLv/wAu/0Fw4guisE74djp58iTjx4/3vl6yZAk33HBDizJvvPEGX/jCFxg3bhyJiYls2LCBiRNbTl+blZVFVFQU+/fvZ82aNUydOpXS0lIKCwtJSUlh7Nix3q6Vsz1+W+VPnTpFWVkZ77//PmBVMq1jSk5OZsCAAezevZvzzjvP/y9FqXA36krrLuQ1T8KQmTDsUrsjCqiwTviBaomfC3+6VJYvX86CBVav1PXXX8/y5cvPSK5gtfLXrFnDmjVrWLx4MaWlpaxZs4aUlBSmT59+zsdvr3xhYSE333wzW7du7eRTSvVAs34E+wvhtbvg7jVW336ECMnxSyJypYg8XVVV1XnhEHX06FHWrl3L7NmzASvhv/jii7R1Z/P06dNZs2YNW7ZsYcyYMUyZMoXCwkLWrFnjvbC6dOlSxo8fz/jx4zl48GCXYps6dSoVFRWUl5eTn5/Phg0bWrxfXV3N/v37CeWL5kp1m5h4uG4ZnKqCN75uXQOIECGZ8I0xK40xC1NSUuwO5Zy9/PLLzJkzh9hYa1bCIUOGkJmZyT//+c8zyk6bNo1Vq1aRmpqK0+kkNTWV48ePU1hY6E3499xzD5s2bWLTpk1kZWV1Kbbi4mKamppIS0vj0ksvpa6ujhdeeAGApqYm7r//fm655Rbtv1c9V7/RcPkP3QvJ/9ruaAImrLt07NS6D3327Nn8+Mc/9r5evnw5mzdvbjGUsbKykuXLlzNjxowW+xo7diwVFRXcdNNNLbbV1taSnp5+1sevq6sjJ6d5WNnixYtblDfG8Pzzz+N0Wre3v/baa3z961/nBz/4AS6Xizlz5vCjH/3obL8SpSLLpAXW2gJ//V8YOA0yx9kdUZdpwj9HTU1NHb7/wQcfdPi+7zh5p9PZYigmwHPPPXfOx3e5XGdsaz2O31dubi4rV67s8HhK9TgiMG8p/Ho6vHw73PkPiEmwO6ouCckuHaWUCgkJaXD1b6ByN7z7gN3RdFnQEr6IOETkYRH5pYh8LVjHDbZbbrmF3r172x1GQEXi76SU34ZcDBcugo0vwLbX7I6mS/xK+CKyTESOiMjWVttni8gOEdktIp1Vf/OAHKABKDm3cENfJCbHSPydlDorl3wHsgvgzXvh+H67ozln/rbwnwNm+24QESewFLgCyAfmi0i+iIwVkVWtHn2BEcAaY8xi4O7A/QpKKdXNnNFw7TNgXPDKAmuitzDkV8I3xqwGjrbaPAnYbYzZY4ypB1YA84wxW4wxc1s9jmC16j0TZLd7xVFEForIehFZX15efva/kVJKdYfUwTD3MTjwEawOz3mmutKHnw0c8Hld4t7WnleBWSLyS2B1e4WMMU8DDwEb25pSQCmlbHPel2HcfFj9U9i3xu5ozlrQLtoaY+qMMbcbY75pjFnaSdmwv/FKKRWh5jwKfQZZXTvtruoVmrqS8EuBXJ/XOe5tXRYJUysopSJUbBJc+yzUHoI3/yuspl7oSsJfBwwXkcEiEgPcCLwZmLCUUiqEZU+AS/8Xit6EDc/ZHY3f/B2WuRwoBEaISImI3G6MaQS+AbwHFAEvGWO2BSIo7dJRSoW8qd+EIZfAu0usdXnDgL+jdOYbYzKNMdHGmBxjzLPu7W8bY/KMMUONMQ8HKqhQ79K55JJLeO+991pse/zxx7n7bv9Hm+7du5devXq1mA/n9ddfR0QoLm75x5OYmAjAokWLePzxx73bZ82axR133OF9ff/99/OLX/yizeM5nU7vbJvjx4/3zrvj2Xd75ceNG8eECRNYs6b5AlVJSQnz5s1j+PDhDB06lHvvvZf6+nrvfD0xMTFUVFT4/V0oFZYcDrj619Z0C6/cDg2n7I6oUyE5tUKot/Dnz5/PihUrWmxbsWIF8+fP7/SzxhjvXDdDhw5tMae973KIbfFMowx4l0Pctq35pMp3OuXWPPPhex6e9W/b4ym/efNmHnnkEZYsWeKN/5prruGqq65i165d7Ny5k9raWh588EHvZ7o6m6dSYSOpP1z1Kzi81ZpkLcSFZMIP9Rb+ddddx1tvvUV9fT1gtdYPHjzIRRddxFVXXcXEiRMZPXo0Tz/9tPf9ESNGcPPNNzNmzBgOHDhwxj49yyE+88wz7Sb8adOmUVhYCDQvh5iUlMSxY8c4ffp0tyyHCP4tibhs2TLq6uoCfmylQl7e5TD5bvj4N7DjXbuj6VBIzpbp9yLm7zxgLTwcSP3HwhU/7rBIamoqkyZN4p133mHevHmsWLGC66+/HhFh2bJlpKamcvLkSS644AKuvfZaAHbt2sXzzz/PlClTAKsS8NWdyyGCLomoVLe67CHY9y9rwZS7/g3JmXZH1KaQbOGHA99uHd/unCeffJJx48YxZcoUDhw4wK5duwAYOHCgN9m3Zfny5Vx//fVA83KIbfFdDnHq1KlMnTrV+7q95RDhzC6djpK9b/ni4mLeffddbr755jZX61JKAVGxcO0yaDgJr90JbUxRHgpCsoUvIlcCV3a6xF4nLfHuNG/ePBYtWsTGjRupq6tj4sSJfPjhh/ztb3+jsLCQ+Ph4Zs6cyalT1oWchIT259H2LIf4yiuvAFbCv/jii3n00UcRkRZlWy+HmJuby89//nOSk5O93SxLly7lt7/9LQBvv/12l/vUWy+J+PLLL7d4X5dEVArIyIPZP4aV/wVrnrBm2AwxIdnCD/WLtmCNbrnkkku47bbbvK37qqoq+vTpQ3x8PMXFxXz00Ud+7SuUl0MEXRJRKb9NuBnyr4L3fwglGzovH2QhmfDDxfz589m8ebM34c+ePZvGxkZGjRrFAw880GEXjq/ly5ezcuVKBg0a5H0UFRW12a3jWQ7Rd99jx44lJSWl3eUQoblP3vPwjNLxLIfoeXiGdfqWv+GGG7xLIooIr732Gn/+858ZPnw4eXl5xMXF6ZKISoG1StaVT0BSJrxyG5yq7vwzQSSh2C/r06WzwNMH7lFUVMSoUaPsCSyA9u7dy9y5c9m6dWvnhcPMoEGDWL9+fZsVUKT8+ynVof0fwe+ugLFfhmueDvrhRWSDMaag9faQbOGHQ5dOVzmdTqqqqlqMnAl3nrOChoYGHI6Q/NNSKjgGTIGL/wc+fRE2r+i8fJCE5EXbniA3N7fN8fjhzDOyRykFXPQt2PMPeOt+yLkA0obaHVFotvCVUirsOaOs7hyHE165Axrr7Y5IE75SSnWb3rnwpV/CwY3wQcCmGztnIZnwQ31qBaWU8lv+PJh4C/z7CfjsA1tDCcmE3xMu2iqlepBZj0B6nnUX7gn7ZpINyYSvlFIRJSYernvWWhLx9a/btkqWJnyllAqG/mPh8h/Crvfg4+CPzYcgJnwRuUhEfi0iz4hI+C33rpRSXTVpIeTNhr98N/Az/frB3yUOl4nIERHZ2mr7bBHZISK7RaTDFTWMMf80xtwFrAKeP/eQlVIqTInAvKXQKxVevg3qg7uGhL8t/OeA2b4bRMQJLAWuAPKB+SKSLyJjRWRVq0dfn4/eBPwpALHbpjuWOAyXZQwBXcpQqa5ISIdrfgMVu+C9JUE9tL9r2q4GjrbaPAnYbYzZY4ypB1YA84wxW4wxc1s9jgCIyACgyhhTE8hfIti6a4lDCP1lDH0/p0sZKnWOhsyE6ffChudg2+tBO2xXplbIBnznBigBJnfymduB33VUQEQWAgsBBgwY0OHOfvLxTyg+GtjV4kemjuR/Jv1Ph2Wuu+46vvvd71JfX09MTMwZSxweOHCAU6dOce+997Jw4UL27t3LrFmzmDx5Mhs2bODtt99ud9/Tpk1j0SJrHm3PMoZlZWUcO3aM+Ph4W5cxHDx4MA899JBOg6xUIPzHd+Hz1db8+dkTrZu0ullQ59IxxnzPjzJPi0gZcGVMTMzEzsrboTuWOPTQZQyV6iGc0dZQzV/PgFcXwtdWWtMxdKOu7L0U8K2Sctzbgqazlnh38nTreBL+s88+C1hLHL722msA3iUO+/fv3+kSh758lzFcvHgxpaWlrFmzhpSUFL+WMfSXb/nCwkJuvvnmiJyuWamQlToEvvhzeG0h/PNnMLPjbtiu6sqwzHXAcBEZLCIxwI3Am4EIKhzutJ03bx5///vf213icPPmzZx//vl+LXHYWutlDKdMmUJhYWGL/vulS5d6L84ePHiwy79P62UMN2xouVqPLmOoVDcZdwOcdwP84yewr7BbD+XvsMzlQCEwQkRKROR2Y0wj8A3gPaAIeMkYs62j/fgrHObSCeQSh63pMoZK9TBzfga9B8KrC6y7cbuJv6N05htjMo0x0caYHGPMs+7tbxtj8owxQ40xAZsKLhxa+BC4JQ5b02UMleph4pKt/vyaMlh5b7dNvRCSC6D4LHFodygduuqqq/BdIjI2NpZ33nmnzbKd9Y3X1tZ6f3Y6nVRXt1wL87nnnus0nqampja3e4aB+lserAVaVq5c2ekxlVIBkj3RGrnzt+/Dxhdg4tcCfoiQnEsnXFr4XRHOSxzqUoZKdZNp91pj9N99AMp3BHz32sK3STgvcahLGSrVTRwOuPo38NpdIM7A7z7gewyAntDCV0qpNiX1h5tfh/TAN3hDMuGHwygdpZQKNyGZ8Dtr4RubFg9QXaP/bkrZKyQTfkfi4uKorKzU5BFmjDFUVlYSFxdndyhK9VghedG2Izk5OZSUlFBeXm53KOosxcXFkZOTY3cYSvVYIZnwOxqlEx0dzeDBg4MflFJKhbmQ7NLRUTpKKRV4IZnwlVJKBZ4mfKWU6iEklEe7iEg5sO8cP54O6IKrzfT7aKbfRUv6fbQUCd/HQGNMRuuNIZ3wu0JE1htjCuyOI1To99FMv4uW9PtoKZK/D+3SUUqpHkITvlJK9RCRnPCftjuAEKPfRzP9LlrS76OliP0+IrYPXymlVEuR3MJXSinlQxO+Ukr1EBGZ8EVktojsEJHdIvKA3fHYRURyReQDEdkuIttE5F67YwoFIuIUkU9EZJXdsdhNRHqLyMsiUiwiRSIy1e6Y7CIii9z/T7aKyHIRibipXSMu4YuIE1gKXAHkA/NFJN/eqGzTCNxvjMkHpgD39ODvwte9QJHdQYSIJ4B3jTEjgXH00O9FRLKB/wIKjDFjACdwo71RBV7EJXxgErDbGLPHGFMPrADm2RyTLYwxZcaYje6fa7D+M2fbG5W9RCQH+CLwjN2x2E1EUoAZwLMAxph6Y8xxe6OyVRTQS0SigHjgoM3xBFwkJvxswHd18BJ6eJIDEJFBwPnAWnsjsd3jwH8DLrsDCQGDgXLgd+4urmdEJMHuoOxgjCkFfgbsB8qAKmPMX+yNKvAiMeGrVkQkEXgFuM8YU213PHYRkbnAEWPMBrtjCRFRwATgV8aY84ETQI+85iUifbB6AgYDWUCCiHzF3qgCLxITfimQ6/M6x72tRxKRaKxk/0djzKt2x2Oz6cCXRGQvVlfff4jIH+wNyVYlQIkxxnPW9zJWBdATfQH43BhTboxpAF4FptkcU8BFYsJfBwwXkcEiEoN14eVNm2OyhYgIVv9skTHmF3bHYzdjzBJjTI4xZhDW38X7xpiIa8X5yxhzCDggIiPcmy4FttsYkp32A1NEJN79/+ZSIvACdkgucdgVxphGEfkG8B7WlfZlxphtNodll+nAV4EtIrLJve07xpi3bYxJhZZvAn90N472ALfaHI8tjDFrReRlYCPW6LZPiMApFnRqBaWU6iEisUtHKaVUGzThK6VUD6EJXymleghN+Eop1UNowldKqR5CE75SSvUQmvCVUqqH+P/2sWvkgz2GCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(conv_stats[['mean_abs_dIWELBO', 'var_dIWELBO', 'var_IWELBO']])\n",
    "plt.legend([r'$\\mathrm{E} | \\Delta \\mathrm{IW}$-$\\mathrm{ELBO}|$', \n",
    "            r'$\\mathrm{Var}[\\Delta \\mathrm{IW}$-$\\mathrm{ELBO}]$', \n",
    "            r'$\\mathrm{Var}[\\mathrm{IW}$-$\\mathrm{ELBO}]$'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_dIWELBO</th>\n",
       "      <th>mean_abs_dIWELBO</th>\n",
       "      <th>mean_squared_dIWELBO</th>\n",
       "      <th>var_dIWELBO</th>\n",
       "      <th>var_IWELBO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.232805</td>\n",
       "      <td>1.234559</td>\n",
       "      <td>1.798791e+00</td>\n",
       "      <td>2.789842e-01</td>\n",
       "      <td>0.278984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006465</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>7.374356e-04</td>\n",
       "      <td>6.956457e-04</td>\n",
       "      <td>0.269283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003608</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>2.205888e-04</td>\n",
       "      <td>2.075699e-04</td>\n",
       "      <td>0.264818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>8.327397e-05</td>\n",
       "      <td>7.860695e-05</td>\n",
       "      <td>0.261204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>5.282083e-05</td>\n",
       "      <td>5.116791e-05</td>\n",
       "      <td>0.257436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>1.643310e-05</td>\n",
       "      <td>1.585988e-05</td>\n",
       "      <td>0.256269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>4.732589e-06</td>\n",
       "      <td>4.567600e-06</td>\n",
       "      <td>0.263609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>3.641679e-06</td>\n",
       "      <td>3.586863e-06</td>\n",
       "      <td>0.264146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>2.786725e-06</td>\n",
       "      <td>2.769487e-06</td>\n",
       "      <td>0.250253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>5.348454e-08</td>\n",
       "      <td>4.945005e-08</td>\n",
       "      <td>0.254525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_dIWELBO  mean_abs_dIWELBO  mean_squared_dIWELBO   var_dIWELBO  \\\n",
       "0     -1.232805          1.234559          1.798791e+00  2.789842e-01   \n",
       "1      0.006465          0.006465          7.374356e-04  6.956457e-04   \n",
       "2      0.003608          0.003608          2.205888e-04  2.075699e-04   \n",
       "3      0.002160          0.002160          8.327397e-05  7.860695e-05   \n",
       "4      0.001286          0.001286          5.282083e-05  5.116791e-05   \n",
       "5      0.000757          0.000757          1.643310e-05  1.585988e-05   \n",
       "6      0.000406          0.000406          4.732589e-06  4.567600e-06   \n",
       "7      0.000234          0.000234          3.641679e-06  3.586863e-06   \n",
       "8      0.000131          0.000131          2.786725e-06  2.769487e-06   \n",
       "9      0.000064          0.000064          5.348454e-08  4.945005e-08   \n",
       "\n",
       "   var_IWELBO  \n",
       "0    0.278984  \n",
       "1    0.269283  \n",
       "2    0.264818  \n",
       "3    0.261204  \n",
       "4    0.257436  \n",
       "5    0.256269  \n",
       "6    0.263609  \n",
       "7    0.264146  \n",
       "8    0.250253  \n",
       "9    0.254525  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLMC codition check for gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_stats_grad_dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level=1):\n",
    "    \n",
    "    N, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N]).T\n",
    "    \n",
    "    param = tf.concat([beta, [beta0], [ln_tau]], axis=0)\n",
    "    param = tf.Variable(param, dtype=tf.float64)\n",
    "    params = tf.reshape(param, [1,D+2]) * np.ones([N,1])\n",
    "\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)        \n",
    "    \n",
    "    def get_grad(args):\n",
    "        \n",
    "        param, x_, y_, z_, mu, sigma = args\n",
    "        z_ = tf.reshape(z_, [-1,1])\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as g:\n",
    "            g.watch(param)\n",
    "            beta_ = param[0,:D]\n",
    "            beta0_ = param[0,D]\n",
    "            ln_tau_ = param[0,D+1]\n",
    "            diwelbos = pointwise_dIWELBO(x_, y_, z_, beta0_, beta_, ln_tau_, mu, sigma)\n",
    "            iwelbos = pointwise_IWELBO(x_, y_, z_, beta0_, beta_, ln_tau_, mu, sigma)\n",
    "            \n",
    "        a = g.gradient(diwelbos, param)\n",
    "        b = g.gradient(iwelbos, param)\n",
    "        \n",
    "        del g\n",
    "        \n",
    "        return a,b\n",
    "    \n",
    "    args = [tf.expand_dims(arg, axis=1) for arg in [params, x, y, z, mu, sigma]]\n",
    "    grads = tf.vectorized_map(get_grad, args)\n",
    "    \n",
    "    grad_diwelbos = tf.squeeze(grads[0])\n",
    "    grad_iwelbos = tf.squeeze(grads[1])\n",
    "    \n",
    "    return {'norm_mean_grad_dIWELBO': np.linalg.norm(np.mean(grad_diwelbos, axis=0)), \n",
    "            'mean_norm_grad_dIWELBO': np.mean(np.linalg.norm(grad_diwelbos, axis=1)), \n",
    "            'mean_squared_norm_grad_dIWELBO': np.mean(np.linalg.norm(grad_diwelbos, axis=1)**2),\n",
    "            'trace_covariance_grad_dIWELBO': np.sum(np.var(grad_diwelbos, axis=0)), \n",
    "            'trace_covariance_grad_IWELBO': np.sum(np.var(grad_iwelbos, axis=0))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp(l):\n",
    "    N0 = 2000000\n",
    "    x,y,_ = generate_data(N=N0//2**l, D=3, T=2, beta0=beta0, beta=beta, ln_tau=ln_tau)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)\n",
    "    return conv_stats_grad_dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level=l)\n",
    "\n",
    "conv_stats = [tmp(l) for l in range(10)]\n",
    "conv_stats = pd.DataFrame(conv_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(conv_stats[['norm_mean_grad_dIWELBO', 'trace_covariance_grad_dIWELBO', 'trace_covariance_grad_IWELBO']])\n",
    "plt.legend([r'$||\\mathrm{E} [\\nabla (\\Delta \\mathrm{IW}$-$\\mathrm{ELBO})]||_2^2$', \n",
    "            r'$\\mathrm{tr}(\\mathrm{Cov}[\\Delta \\mathrm{IW}$-$\\mathrm{ELBO}])$', \n",
    "            r'$\\mathrm{tr}(\\mathrm{Cov}[\\Delta \\mathrm{IW}$-$\\mathrm{ELBO}])$'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$b\\approx1$ for $V_\\ell\\propto 2^{-b\\ell}$!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_mean_grad_dIWELBO</th>\n",
       "      <th>mean_norm_grad_dIWELBO</th>\n",
       "      <th>mean_squared_norm_grad_dIWELBO</th>\n",
       "      <th>trace_covariance_grad_dIWELBO</th>\n",
       "      <th>trace_covariance_grad_IWELBO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.161872</td>\n",
       "      <td>1.350972</td>\n",
       "      <td>2.436254</td>\n",
       "      <td>2.410052</td>\n",
       "      <td>2.410052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052166</td>\n",
       "      <td>0.075348</td>\n",
       "      <td>0.051878</td>\n",
       "      <td>0.049157</td>\n",
       "      <td>1.837297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039383</td>\n",
       "      <td>0.048425</td>\n",
       "      <td>0.025012</td>\n",
       "      <td>0.023461</td>\n",
       "      <td>1.478819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027193</td>\n",
       "      <td>0.031394</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>1.256417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017273</td>\n",
       "      <td>0.019341</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>0.006047</td>\n",
       "      <td>1.100748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010605</td>\n",
       "      <td>0.011623</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>1.008295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006407</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.954304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.915277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.921422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.893999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   norm_mean_grad_dIWELBO  mean_norm_grad_dIWELBO  \\\n",
       "0                0.161872                1.350972   \n",
       "1                0.052166                0.075348   \n",
       "2                0.039383                0.048425   \n",
       "3                0.027193                0.031394   \n",
       "4                0.017273                0.019341   \n",
       "5                0.010605                0.011623   \n",
       "6                0.006407                0.006927   \n",
       "7                0.003513                0.003770   \n",
       "8                0.002227                0.002354   \n",
       "9                0.001259                0.001327   \n",
       "\n",
       "   mean_squared_norm_grad_dIWELBO  trace_covariance_grad_dIWELBO  \\\n",
       "0                        2.436254                       2.410052   \n",
       "1                        0.051878                       0.049157   \n",
       "2                        0.025012                       0.023461   \n",
       "3                        0.012612                       0.011872   \n",
       "4                        0.006346                       0.006047   \n",
       "5                        0.002791                       0.002678   \n",
       "6                        0.001949                       0.001907   \n",
       "7                        0.000343                       0.000331   \n",
       "8                        0.000553                       0.000548   \n",
       "9                        0.000238                       0.000237   \n",
       "\n",
       "   trace_covariance_grad_IWELBO  \n",
       "0                      2.410052  \n",
       "1                      1.837297  \n",
       "2                      1.478819  \n",
       "3                      1.256417  \n",
       "4                      1.100748  \n",
       "5                      1.008295  \n",
       "6                      0.954304  \n",
       "7                      0.915277  \n",
       "8                      0.921422  \n",
       "9                      0.893999  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost comparison of objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMC_ests = []\n",
    "MLMC_ests = []\n",
    "RandMLMC_ests = []\n",
    "for i in range(100):\n",
    "    N0 = 4000\n",
    "    x,y,_ = generate_data(N=N0, D=3, T=2, beta0=beta0, beta=beta, ln_tau=ln_tau)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)\n",
    "    NMC_ests.append( IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=512).numpy() )\n",
    "    MLMC_ests.append( IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=9, w0=0.90, randomize=False).numpy() )\n",
    "    RandMLMC_ests.append( IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=9, w0=0.90, randomize=True).numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std-div of NMC estimator:       0.0024924731194345654\n",
      "std-div of MLMC estimator:      0.0027603319503505283\n",
      "std-div of RandMLMC estimator:  0.003223633615106453\n"
     ]
    }
   ],
   "source": [
    "print(\"std-div of NMC estimator:      \", np.std(NMC_ests))\n",
    "print(\"std-div of MLMC estimator:     \", np.std(MLMC_ests))\n",
    "print(\"std-div of RandMLMC estimator: \", np.std(RandMLMC_ests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12 s ± 5.02 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=2**9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.5 ms ± 441 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=9, w0=0.90, randomize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.4 ms ± 629 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=9, w0=0.90, randomize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost comparison of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMC_ests = []\n",
    "MLMC_ests = []\n",
    "RandMLMC_ests = []\n",
    "for i in range(100):\n",
    "    N0 = 2000\n",
    "    x,y,_ = generate_data(N=N0, D=3, T=2, beta0=beta0, beta=beta, ln_tau=ln_tau)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)\n",
    "    \n",
    "    param = tf.concat([beta, [beta0], [ln_tau]], axis=0)\n",
    "    param = tf.Variable(param, dtype=tf.float64)\n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as g:\n",
    "        g.watch(param)\n",
    "        beta_ = param[:D]\n",
    "        beta0_ = param[D]\n",
    "        ln_tau_ = param[D+1]\n",
    "        nmc_est = IWELBO(x, y, beta0_, beta_, ln_tau_, mu, sigma, n_MC=2**12)\n",
    "        mlmc_est = IWELBO_MLMC(x, y, beta0_, beta_, ln_tau_, mu, sigma, max_level=12, w0=0.8, b=1,  randomize=False)\n",
    "        randmlmc_est = IWELBO_MLMC(x, y, beta0_, beta_, ln_tau_, mu, sigma, max_level=12, w0=0.8, b=1, randomize=True)\n",
    "            \n",
    "    nmc_est = g.gradient(nmc_est, param)\n",
    "    mlmc_est = g.gradient(mlmc_est, param)\n",
    "    randmlmc_est = g.gradient(randmlmc_est, param)\n",
    "    \n",
    "    del g\n",
    "        \n",
    "    NMC_ests.append( nmc_est )\n",
    "    MLMC_ests.append( mlmc_est )\n",
    "    RandMLMC_ests.append( randmlmc_est )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E||grad||^2 of NMC estimator:       0.21549826403397726\n",
      "E||grad||^2 of MLMC estimator:      0.5024365180633751\n",
      "E||grad||^2 of RandMLMC estimator:  0.544721565232442\n"
     ]
    }
   ],
   "source": [
    "print(\"E||grad||^2 of NMC estimator:      \", np.mean(np.linalg.norm(NMC_ests)))\n",
    "print(\"E||grad||^2 of MLMC estimator:     \", np.mean(np.linalg.norm(MLMC_ests)))\n",
    "print(\"E||grad||^2 of RandMLMC estimator: \", np.mean(np.linalg.norm(RandMLMC_ests)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22 s ± 6.46 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with tf.GradientTape(persistent=True) as g:\n",
    "    g.watch(param)\n",
    "    beta_ = param[:D]\n",
    "    beta0_ = param[D]\n",
    "    ln_tau_ = param[D+1]\n",
    "    nmc_est = IWELBO(x, y, beta0_, beta_, ln_tau_, mu, sigma, n_MC=2**12)\n",
    "\n",
    "nmc_est = g.gradient(nmc_est, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 ms ± 1.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with tf.GradientTape(persistent=True) as g:\n",
    "    g.watch(param)\n",
    "    beta_ = param[:D]\n",
    "    beta0_ = param[D]\n",
    "    ln_tau_ = param[D+1]\n",
    "    mlmc_est = IWELBO_MLMC(x, y, beta0_, beta_, ln_tau_, mu, sigma, max_level=12, w0=0.8, b=1, randomize=False)\n",
    "\n",
    "mlmc_est = g.gradient(mlmc_est, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 ms ± 6.15 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with tf.GradientTape(persistent=True) as g:\n",
    "    g.watch(param)\n",
    "    beta_ = param[:D]\n",
    "    beta0_ = param[D]\n",
    "    ln_tau_ = param[D+1]\n",
    "    randmlmc_est = IWELBO_MLMC(x, y, beta0_, beta_, ln_tau_, mu, sigma, max_level=12, w0=0.8, b=1, randomize=True)\n",
    "\n",
    "randmlmc_est = g.gradient(randmlmc_est, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For finding nice configuration where MLMC wins NMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,_ = y.shape\n",
    "n_MC = 2\n",
    "z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "\n",
    "diwelbos = pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma).numpy()\n",
    "score1 = np.var(NMC_ests) / diwelbos.mean()**2\n",
    "score2 = np.var(MLMC_ests) / np.var(NMC_ests)\n",
    "print(score1, score2)\n",
    "\n",
    "print(np.std(x@beta, axis=1).mean(), z.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
