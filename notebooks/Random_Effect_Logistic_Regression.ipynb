{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Effect Logistic Regression by MLMC Variational Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Effect Models:\n",
    "For $n=1,...,N$,\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$Z_n \\sim N(0,\\tau^2)$\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$Y_{n,t} \\sim \\text{Bernoulli}\\left(\\frac{1}{1+\\exp(- Z_n - \\beta_0 - \\beta^T x_{n,t})}\\right)$\n",
    "<br>\n",
    "for $t=1, ..., T$. This model carries out dimentionality reduction of binary observations $y_{n,k}$'s. Here, the dimention of $\\beta$ and $x_{n,t}$ is $D$.<br>\n",
    "As variational approximation of the posterior $p(z_n|y_n)$, we use $q(z_n)= N(z_n;\\mu_n, \\sigma_n^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Possible Extension:\n",
    "\n",
    "By adding $\\bar x_n=\\frac{1}{T}\\sum_t x_{n,t}$ to the predictors as \n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$Y_{n,t} \\sim \\text{Bernoulli}\\left(\\frac{1}{1+\\exp(- Z_n - \\beta_0 - \\beta^T x_{n,t}- \\gamma\\bar x_n)}\\right)$,\n",
    "<br>\n",
    "we can obtain correlated random effect models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We do not consider the use of Renyi divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import bernoulli, norm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x:1/(1+np.exp(-x))\n",
    "\n",
    "as_tf_float = lambda x: tf.cast(x, tf.float64)\n",
    "\n",
    "def tf_logsumexp(ary, axis=1, keepdims=False):\n",
    "    return tf.math.reduce_logsumexp(ary, axis=axis, keepdims=keepdims)\n",
    "\n",
    "def tf_logmeanexp(ary, axis=1, keepdims=False):\n",
    "    return tf.math.reduce_logsumexp(ary, axis=axis, keepdims=keepdims) \\\n",
    "        - tf.math.log(as_tf_float(ary.shape[axis]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "D = 3\n",
    "T = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "# We assume that we have infinite amount of data.\n",
    "# Thus, generator of the data is implemented.\n",
    "def generate_data(N, D, T, beta0, beta, ln_tau):\n",
    "    z = np.random.randn(N) * np.exp(ln_tau)\n",
    "    x = np.random.randn(N*T*D).reshape([N,T,D])\n",
    "    y = bernoulli(p=sigmoid(beta0+x@beta+z.reshape([N,1]))).rvs()\n",
    "    return x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramters\n",
    "ln_tau = np.float64(0.7)\n",
    "beta0 = np.float64(0.)\n",
    "beta  = np.random.randn(D) / np.sqrt(D)\n",
    "param0 = {\n",
    "    'ln_tau': ln_tau,\n",
    "    'beta0': beta0,\n",
    "    'beta': beta\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y,z = generate_data(N, D, T, beta0, beta, ln_tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Normal Integral Approximation of Evidence\n",
    "\n",
    "Ref: Barber Bishop(1998), PRML(2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_normal_prob(x, beta0, beta, ln_tau):\n",
    "    N, T, D  = x.shape\n",
    "    kappa = 1 / (1 + np.pi*tf.exp(ln_tau*2)/8)**(1/2)\n",
    "    return tf.math.sigmoid( kappa * (beta0 + tf.reshape( x@tf.reshape(beta, [D,1]), [N, T])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_normal_likelihood(x, y, beta0, beta, ln_tau):\n",
    "    pred_prob = sigmoid_normal_prob(x, beta0, beta, ln_tau)\n",
    "    score = tf.reduce_mean(tf.reduce_sum(\n",
    "        tf.math.log(pred_prob)*y + tf.math.log(1-pred_prob)*(1-y), \n",
    "        axis=1))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Approximation of Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_approx(x, y, beta0, beta, ln_tau):\n",
    "    N, T, D  = x.shape\n",
    "    z = np.zeros([N, 1])\n",
    "    _sig = lambda z: sigmoid( z + beta0 + x@beta )\n",
    "    for i in range(10):\n",
    "        sig = _sig(z)\n",
    "        hessian = 1/np.exp(ln_tau*2) + np.sum( sig*(1-sig), axis=1, keepdims=True)\n",
    "        grad    = z/np.exp(ln_tau*2) + np.sum( sig - y,     axis=1, keepdims=True)\n",
    "        z -= grad / hessian\n",
    "    mu = z.reshape([N])\n",
    "    sigma = (1 / hessian).reshape([N])**(1/2)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.928849989477483, 2.1424583009621827)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.var(), (z-mu).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IWELBO approximation of Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma):\n",
    "    \"\"\"\n",
    "    Compute IWELBOs for i = 1,...,n using n_MC samples Zn. \n",
    "    Here, we assume that n<N where N is the size of data.\n",
    "    \n",
    "    Arguments:\n",
    "    x: 3-d array of size [N, T, D]\n",
    "    y: 2-d array of size [N, T]\n",
    "    z: 1-d array of size [n_MC, N]\n",
    "    beta: 1-d array of size [D]\n",
    "    mu: 1-d array of [N]\n",
    "    sigma**2: 1-d array of [N]\n",
    "    \n",
    "    Returns:\n",
    "    iwelbo: iwelbo, whose size is [N]\n",
    "    \"\"\"\n",
    "\n",
    "    (N, T, D), (n_MC, n) = x.shape, z.shape\n",
    "    y = np.float64( y.reshape([1,N,T]) )\n",
    "    mu = mu.reshape([1,N])\n",
    "    sigma = sigma.reshape([1,N])\n",
    "    \n",
    "    y_logits = tf.convert_to_tensor( beta0\\\n",
    "                                    + tf.reshape( x@tf.reshape(beta, [D,1]), [1, N, T])\\\n",
    "                                    + tf.reshape(z, [n_MC, N, 1]) \n",
    "                                   )\n",
    "    p_y = tfp.distributions.Bernoulli(logits=y_logits)\n",
    "    p_z = tfp.distributions.Normal(loc=np.zeros([1, N]), scale=tf.exp(ln_tau))\n",
    "    q_z = tfp.distributions.Normal(loc=mu, scale=sigma)\n",
    "    \n",
    "    log_prob_ratio = \\\n",
    "        tf.reduce_sum( p_y.log_prob(y), axis=2)\\\n",
    "        + p_z.log_prob(z)\\\n",
    "        - q_z.log_prob(z)\n",
    "    \n",
    "    iwelbo = tf_logmeanexp(log_prob_ratio, axis=0)\n",
    "    return iwelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC):\n",
    "    N, = mu.shape\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    iwelbo = tf.reduce_mean( pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma) )\n",
    "    return iwelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "signorm_likelihood = sigmoid_normal_likelihood(x, y, beta0, beta, ln_tau).numpy()\n",
    "elbo_likelihood = IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=1).numpy()\n",
    "iwelbo_likelihood = IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=64).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0952656839171677, -1.0601973996791316, -1.0478776195923623)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signorm_likelihood, elbo_likelihood, iwelbo_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood by Different Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training signorm...\n",
      "#iter: 0,\tloss: 1.3862943611198904\n",
      "#iter: 200,\tloss: 1.1972973100753581\n",
      "#iter: 400,\tloss: 1.3765428296780922\n",
      "#iter: 600,\tloss: 1.2863817101036361\n",
      "#iter: 800,\tloss: 1.4237331319111957\n",
      "#iter: 1000,\tloss: 1.2646627380388522\n",
      "#iter: 1200,\tloss: 1.296606908636212\n",
      "#iter: 1400,\tloss: 1.1923068583568535\n",
      "#iter: 1600,\tloss: 1.2963300498464612\n",
      "#iter: 1800,\tloss: 1.2265708550856242\n",
      "#iter: 2000,\tloss: 1.246692349962158\n",
      "\n",
      "training elbo...\n",
      "#iter: 0,\tloss: 1.3339215307286465\n",
      "#iter: 200,\tloss: 1.2470361868106368\n",
      "#iter: 400,\tloss: 1.2299446957709543\n",
      "#iter: 600,\tloss: 1.2072082662756634\n",
      "#iter: 800,\tloss: 1.2166464987359218\n",
      "#iter: 1000,\tloss: 1.2681727374622223\n",
      "#iter: 1200,\tloss: 1.2822739446734972\n",
      "#iter: 1400,\tloss: 1.231007925737668\n",
      "#iter: 1600,\tloss: 1.1907385799239807\n",
      "#iter: 1800,\tloss: 1.2673998690341393\n",
      "#iter: 2000,\tloss: 1.2812046282884773\n",
      "\n",
      "training iwelbo8...\n",
      "#iter: 0,\tloss: 1.3672195993895213\n",
      "#iter: 200,\tloss: 1.2475841711412685\n",
      "#iter: 400,\tloss: 1.2272840120154995\n",
      "#iter: 600,\tloss: 1.306596686879311\n",
      "#iter: 800,\tloss: 1.0869674692358695\n",
      "#iter: 1000,\tloss: 1.2738258502332505\n",
      "#iter: 1200,\tloss: 1.226527162966116\n",
      "#iter: 1400,\tloss: 1.2281456487999243\n",
      "#iter: 1600,\tloss: 1.2304449172166927\n",
      "#iter: 1800,\tloss: 1.1608601200529458\n",
      "#iter: 2000,\tloss: 1.255340579674186\n",
      "\n",
      "training iwelbo64...\n",
      "#iter: 0,\tloss: 1.3138900751201321\n",
      "#iter: 200,\tloss: 1.2186831193239493\n",
      "#iter: 400,\tloss: 1.150378473750767\n",
      "#iter: 600,\tloss: 1.2457166335683538\n",
      "#iter: 800,\tloss: 1.1918454148254094\n",
      "#iter: 1000,\tloss: 1.2088999280789872\n",
      "#iter: 1200,\tloss: 1.2470698580069333\n",
      "#iter: 1400,\tloss: 1.2611272099780308\n",
      "#iter: 1600,\tloss: 1.171719588344559\n",
      "#iter: 1800,\tloss: 1.1799366870426733\n",
      "#iter: 2000,\tloss: 1.1693243269870093\n",
      "\n",
      "training iwelbo512...\n",
      "#iter: 0,\tloss: 1.3628542862549176\n",
      "#iter: 200,\tloss: 1.2831169783703018\n",
      "#iter: 400,\tloss: 1.2199991670104386\n",
      "#iter: 600,\tloss: 1.2243035790729258\n",
      "#iter: 800,\tloss: 1.1344862574880215\n",
      "#iter: 1000,\tloss: 1.2274269140797516\n",
      "#iter: 1200,\tloss: 1.1362096779951434\n",
      "#iter: 1400,\tloss: 1.1754646486577007\n",
      "#iter: 1600,\tloss: 1.1643276557921134\n",
      "#iter: 1800,\tloss: 1.1405681471160944\n",
      "#iter: 2000,\tloss: 1.1849639553037221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "objectives = {\n",
    "    \"signorm\": lambda beta0, beta, ln_tau, mu, sigma: sigmoid_normal_likelihood(x, y, beta0, beta, ln_tau),\n",
    "    \"elbo\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=1),\n",
    "    \"iwelbo8\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=8),\n",
    "    \"iwelbo64\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=64),\n",
    "    \"iwelbo512\": lambda beta0, beta, ln_tau, mu, sigma: IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=512)\n",
    "}\n",
    "params = {\"ground_truth\": param0}\n",
    "\n",
    "N,T,D = 100, 2, 3\n",
    "\n",
    "for obj_name, obj_func in objectives.items():\n",
    "    \n",
    "    print(\"training {}...\".format(obj_name))\n",
    "    \n",
    "    beta0_ = tf.Variable(0, dtype=tf.float64)\n",
    "    beta_  = tf.Variable(np.zeros([D]), dtype=tf.float64)\n",
    "    ln_tau_   = tf.Variable(0, dtype=tf.float64)\n",
    "    \n",
    "    # Gradient Descent\n",
    "    for t in range(2001):\n",
    "        \n",
    "        rho_t = 0.5/(1+t)**0.7\n",
    "        x,y,_ = generate_data(N, D, T, beta0, beta, ln_tau)\n",
    "\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch([beta0_, beta_, ln_tau_])\n",
    "            mu, sigma = laplace_approx(x, y, beta0_.numpy(), beta_.numpy(), ln_tau_.numpy())\n",
    "            score = obj_func(beta0_, beta_, ln_tau_, mu, sigma)\n",
    "        dbeta0_, dbeta_, dln_tau_ = g.gradient(score, [beta0_, beta_, ln_tau_])\n",
    "\n",
    "        beta0_ = beta0_ + rho_t*dbeta0_\n",
    "        beta_ = beta_ + rho_t*dbeta_\n",
    "        ln_tau_ = ln_tau_ + dln_tau_\n",
    "        if t%200==0:\n",
    "            print(\"#iter: {},\\tloss: {}\".format(t, -score.numpy()))\n",
    "    \n",
    "    params[obj_name] = {\n",
    "        'ln_tau': ln_tau_.numpy(),\n",
    "        'beta0': beta0_.numpy(),\n",
    "        'beta': beta_.numpy()\n",
    "    }\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def expand(key, val):\n",
    "    # expand {\"name\":array([1,2,3,4,5])}\n",
    "    # into {\"name1\":1, \"name2\":2, ..., \"name5\":5}\n",
    "    if type(val)==np.ndarray:\n",
    "        return {key+str(i+1): x for i,x in enumerate(val)} \n",
    "    else:\n",
    "        return {key:val} \n",
    "\n",
    "def expand_param(param):\n",
    "    expanded_param = {}\n",
    "    for key, val in param.items():\n",
    "        expanded_param.update(expand(key,val))\n",
    "    return expanded_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ln_tau</th>\n",
       "      <th>beta0</th>\n",
       "      <th>beta1</th>\n",
       "      <th>beta2</th>\n",
       "      <th>beta3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ground_truth</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430122</td>\n",
       "      <td>0.673026</td>\n",
       "      <td>0.869993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signorm</th>\n",
       "      <td>-0.987636</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>-0.268291</td>\n",
       "      <td>0.435698</td>\n",
       "      <td>0.549871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elbo</th>\n",
       "      <td>-4.357932</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>-0.298313</td>\n",
       "      <td>0.468683</td>\n",
       "      <td>0.612275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iwelbo8</th>\n",
       "      <td>0.532295</td>\n",
       "      <td>-0.003339</td>\n",
       "      <td>-0.368858</td>\n",
       "      <td>0.572142</td>\n",
       "      <td>0.750772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iwelbo64</th>\n",
       "      <td>0.714111</td>\n",
       "      <td>-0.001580</td>\n",
       "      <td>-0.389843</td>\n",
       "      <td>0.610216</td>\n",
       "      <td>0.796548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iwelbo512</th>\n",
       "      <td>0.645257</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>-0.401040</td>\n",
       "      <td>0.622878</td>\n",
       "      <td>0.817333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ln_tau     beta0     beta1     beta2     beta3\n",
       "ground_truth  0.700000  0.000000 -0.430122  0.673026  0.869993\n",
       "signorm      -0.987636  0.004602 -0.268291  0.435698  0.549871\n",
       "elbo         -4.357932  0.005055 -0.298313  0.468683  0.612275\n",
       "iwelbo8       0.532295 -0.003339 -0.368858  0.572142  0.750772\n",
       "iwelbo64      0.714111 -0.001580 -0.389843  0.610216  0.796548\n",
       "iwelbo512     0.645257  0.009477 -0.401040  0.622878  0.817333"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({key: expand_param(param) for key,param in params.items()}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bottom Line: IWELBO gives better estiamte than elbo or sigmoid normal integral approximation, even for simple this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma):\n",
    "    \n",
    "    (N, T, D), (n_MC, N) = x.shape, z.shape\n",
    "    assert np.log2(n_MC)%1==0\n",
    "    \n",
    "    if n_MC == 1:\n",
    "        scores = pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma)\n",
    "    else:\n",
    "        scores = pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma)\n",
    "        scores -= (1/2.) * pointwise_IWELBO(x, y, z[:n_MC//2 ], beta0, beta, ln_tau, mu, sigma)\n",
    "        scores -= (1/2.) * pointwise_IWELBO(x, y, z[ n_MC//2:], beta0, beta, ln_tau, mu, sigma)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level):\n",
    "    \n",
    "    N, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    \n",
    "    diwelbo = tf.reduce_mean( pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma) )\n",
    "    return diwelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=8, w0=1-2.**(-3/2), randomize=False):\n",
    "    \n",
    "    N, T, D = x.shape\n",
    "\n",
    "    levels = np.arange(max_level)\n",
    "    weights = 2.**(-3/2*levels)\n",
    "    weights /= sum(weights)\n",
    "    weights = np.concatenate([[w0], (1-w0)*weights])\n",
    "    \n",
    "    if randomize==True:\n",
    "         Ns = np.random.multinomial(n=N, pvals=weights)\n",
    "        \n",
    "    elif randomize==False:\n",
    "        Ns = np.zeros_like(levels)\n",
    "        Ns = np.array([np.math.ceil(w*N) for w in weights], dtype=np.int)\n",
    "        Ns[0] = N - sum(Ns[1:])\n",
    "    \n",
    "    else:\n",
    "        raise(Exception(\"Invarid argument for 'randomize' of function IWELBO_MLMC. It must be True or False.\"))\n",
    "    \n",
    "    N_offset = 0\n",
    "    score = 0\n",
    "    for i, l in enumerate(levels):\n",
    "        if Ns[i]==0:\n",
    "            continue\n",
    "        x_tmp = x[N_offset:N_offset+Ns[i]]\n",
    "        y_tmp = y[N_offset:N_offset+Ns[i]]\n",
    "        mu_tmp = mu[N_offset:N_offset+Ns[i]]\n",
    "        sigma_tmp = sigma[N_offset:N_offset+Ns[i]]\n",
    "                       \n",
    "        if randomize==True:\n",
    "            score += dIWELBO(x_tmp, y_tmp, beta0, beta, ln_tau, mu_tmp, sigma_tmp, level=l) * Ns[i] / N / weights[i]   \n",
    "        elif randomize==False:\n",
    "            score += dIWELBO(x_tmp, y_tmp, beta0, beta, ln_tau, mu_tmp, sigma_tmp, level=l)\n",
    "        \n",
    "        N_offset += Ns[i]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-1.0742302070986356>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=10, w0=0.90, randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-1.0483677316301432>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLMC codition check for objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_stats_dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level=1):\n",
    "    \n",
    "    N, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    \n",
    "    diwelbos = pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma).numpy()\n",
    "    iwelbos = pointwise_IWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma).numpy()\n",
    "    \n",
    "    return {'mean_dIWELBO':np.mean(diwelbos), \n",
    "            'mean_abs_dIWELBO':np.mean(np.abs(diwelbos)), \n",
    "            'mean_squared_dIWELBO':np.mean(diwelbos**2),\n",
    "            'var_dIWELBO':np.var(diwelbos), \n",
    "            'var_IWELBO':np.var(iwelbos)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp(l):\n",
    "    N0 = 200000 if tf.test.is_gpu_available() else 10000 \n",
    "    x,y,_ = generate_data(N=N0//2**l, D=3, T=2, beta0=beta0, beta=beta, ln_tau=ln_tau)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)\n",
    "    return conv_stats_dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level=l)\n",
    "\n",
    "conv_stats = [tmp(l) for l in range(10)]\n",
    "conv_stats = pd.DataFrame(conv_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(conv_stats[['mean_abs_dIWELBO', 'var_dIWELBO', 'var_IWELBO']])\n",
    "plt.legend([r'$\\mathrm{E} | \\Delta \\mathrm{IW}$-$\\mathrm{ELBO}|$', \n",
    "            r'$\\mathrm{Var}[\\Delta \\mathrm{IW}$-$\\mathrm{ELBO}]$', \n",
    "            r'$\\mathrm{Var}[\\mathrm{IW}$-$\\mathrm{ELBO}]$'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_dIWELBO</th>\n",
       "      <th>mean_abs_dIWELBO</th>\n",
       "      <th>mean_squared_dIWELBO</th>\n",
       "      <th>var_dIWELBO</th>\n",
       "      <th>var_IWELBO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.105712</td>\n",
       "      <td>1.107827</td>\n",
       "      <td>1.610085e+00</td>\n",
       "      <td>3.874866e-01</td>\n",
       "      <td>0.387487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.005920</td>\n",
       "      <td>7.786304e-04</td>\n",
       "      <td>7.435898e-04</td>\n",
       "      <td>0.393635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>1.625274e-04</td>\n",
       "      <td>1.529779e-04</td>\n",
       "      <td>0.395425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>5.492146e-05</td>\n",
       "      <td>5.167855e-05</td>\n",
       "      <td>0.393086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>1.321623e-05</td>\n",
       "      <td>1.226341e-05</td>\n",
       "      <td>0.395515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>1.140798e-05</td>\n",
       "      <td>1.102940e-05</td>\n",
       "      <td>0.394883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>2.764867e-06</td>\n",
       "      <td>2.656589e-06</td>\n",
       "      <td>0.388482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>3.289712e-07</td>\n",
       "      <td>3.038934e-07</td>\n",
       "      <td>0.390376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>1.581575e-07</td>\n",
       "      <td>1.512942e-07</td>\n",
       "      <td>0.394209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>1.094377e-07</td>\n",
       "      <td>1.073244e-07</td>\n",
       "      <td>0.396185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_dIWELBO  mean_abs_dIWELBO  mean_squared_dIWELBO   var_dIWELBO  \\\n",
       "0     -1.105712          1.107827          1.610085e+00  3.874866e-01   \n",
       "1      0.005920          0.005920          7.786304e-04  7.435898e-04   \n",
       "2      0.003090          0.003090          1.625274e-04  1.529779e-04   \n",
       "3      0.001801          0.001801          5.492146e-05  5.167855e-05   \n",
       "4      0.000976          0.000976          1.321623e-05  1.226341e-05   \n",
       "5      0.000615          0.000615          1.140798e-05  1.102940e-05   \n",
       "6      0.000329          0.000329          2.764867e-06  2.656589e-06   \n",
       "7      0.000158          0.000158          3.289712e-07  3.038934e-07   \n",
       "8      0.000083          0.000083          1.581575e-07  1.512942e-07   \n",
       "9      0.000046          0.000046          1.094377e-07  1.073244e-07   \n",
       "\n",
       "   var_IWELBO  \n",
       "0    0.387487  \n",
       "1    0.393635  \n",
       "2    0.395425  \n",
       "3    0.393086  \n",
       "4    0.395515  \n",
       "5    0.394883  \n",
       "6    0.388482  \n",
       "7    0.390376  \n",
       "8    0.394209  \n",
       "9    0.396185  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLMC codition check for gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_stats_grad_dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level=1):\n",
    "    \n",
    "    N, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    \n",
    "    param = tf.concat([beta, [beta0], [ln_tau]], axis=0)\n",
    "    param = tf.Variable(param, dtype=tf.float64)\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as g:\n",
    "        g.watch(param)\n",
    "        beta_  = param[:D]\n",
    "        beta0_ = param[D]\n",
    "        ln_tau_  = param[D+1]\n",
    "        mu, sigma = laplace_approx(x, y, beta0_.numpy(), beta_.numpy(), ln_tau_.numpy())\n",
    "        diwelbos = pointwise_dIWELBO(x, y, z, beta0_, beta_, ln_tau_, mu, sigma)\n",
    "        iwelbos = pointwise_IWELBO(x, y, z, beta0_, beta_, ln_tau_, mu, sigma)\n",
    "    \n",
    "    grad_iwelbos = g.jacobian(iwelbos, param)\n",
    "    grad_diwelbos = g.jacobian(diwelbos, param)\n",
    "    \n",
    "    del g\n",
    "    \n",
    "    return {'norm_mean_grad_dIWELBO': np.linalg.norm(np.mean(grad_diwelbos, axis=0)), \n",
    "            'mean_norm_grad_dIWELBO': np.mean(np.linalg.norm(grad_diwelbos, axis=1)), \n",
    "            'mean_squared_norm_grad_dIWELBO': np.mean(np.linalg.norm(grad_diwelbos, axis=1)**2),\n",
    "            'trace_covariance_grad_dIWELBO': np.sum(np.var(grad_diwelbos, axis=0)), \n",
    "            'trace_covariance_grad_IWELBO': np.sum(np.var(grad_iwelbos, axis=0))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp(l):\n",
    "    N0 = 200000 if tf.test.is_gpu_available() else 10000 \n",
    "    x,y,_ = generate_data(N=N0//2**l, D=3, T=2, beta0=beta0, beta=beta, ln_tau=ln_tau)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)\n",
    "    return conv_stats_grad_dIWELBO(x, y, beta0, beta, ln_tau, mu, sigma, level=l)\n",
    "\n",
    "conv_stats = [tmp(l) for l in range(10)]\n",
    "conv_stats = pd.DataFrame(conv_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(conv_stats[['norm_mean_grad_dIWELBO', 'trace_covariance_grad_dIWELBO', 'trace_covariance_grad_IWELBO']])\n",
    "plt.legend([r'$||\\mathrm{E} [\\nabla (\\Delta \\mathrm{IW}$-$\\mathrm{ELBO})]||_2^2$', \n",
    "            r'$\\mathrm{tr}(\\mathrm{Cov}[\\Delta \\mathrm{IW}$-$\\mathrm{ELBO}]) \\ = \\ \\mathrm{E}||\\nabla(\\Delta \\mathrm{IW}$-$\\mathrm{ELBO})||_2^2$', \n",
    "            r'$\\mathrm{tr}(\\mathrm{Cov}[\\Delta \\mathrm{IW}$-$\\mathrm{ELBO}]) \\ = \\ \\mathrm{E}||\\nabla(\\mathrm{IW}$-$\\mathrm{ELBO})||_2^2$'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_dIWELBO</th>\n",
       "      <th>mean_abs_dIWELBO</th>\n",
       "      <th>mean_squared_dIWELBO</th>\n",
       "      <th>var_dIWELBO</th>\n",
       "      <th>var_IWELBO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.105712</td>\n",
       "      <td>1.107827</td>\n",
       "      <td>1.610085e+00</td>\n",
       "      <td>3.874866e-01</td>\n",
       "      <td>0.387487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.005920</td>\n",
       "      <td>7.786304e-04</td>\n",
       "      <td>7.435898e-04</td>\n",
       "      <td>0.393635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>1.625274e-04</td>\n",
       "      <td>1.529779e-04</td>\n",
       "      <td>0.395425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>5.492146e-05</td>\n",
       "      <td>5.167855e-05</td>\n",
       "      <td>0.393086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>1.321623e-05</td>\n",
       "      <td>1.226341e-05</td>\n",
       "      <td>0.395515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>1.140798e-05</td>\n",
       "      <td>1.102940e-05</td>\n",
       "      <td>0.394883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>2.764867e-06</td>\n",
       "      <td>2.656589e-06</td>\n",
       "      <td>0.388482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>3.289712e-07</td>\n",
       "      <td>3.038934e-07</td>\n",
       "      <td>0.390376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>1.581575e-07</td>\n",
       "      <td>1.512942e-07</td>\n",
       "      <td>0.394209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>1.094377e-07</td>\n",
       "      <td>1.073244e-07</td>\n",
       "      <td>0.396185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_dIWELBO  mean_abs_dIWELBO  mean_squared_dIWELBO   var_dIWELBO  \\\n",
       "0     -1.105712          1.107827          1.610085e+00  3.874866e-01   \n",
       "1      0.005920          0.005920          7.786304e-04  7.435898e-04   \n",
       "2      0.003090          0.003090          1.625274e-04  1.529779e-04   \n",
       "3      0.001801          0.001801          5.492146e-05  5.167855e-05   \n",
       "4      0.000976          0.000976          1.321623e-05  1.226341e-05   \n",
       "5      0.000615          0.000615          1.140798e-05  1.102940e-05   \n",
       "6      0.000329          0.000329          2.764867e-06  2.656589e-06   \n",
       "7      0.000158          0.000158          3.289712e-07  3.038934e-07   \n",
       "8      0.000083          0.000083          1.581575e-07  1.512942e-07   \n",
       "9      0.000046          0.000046          1.094377e-07  1.073244e-07   \n",
       "\n",
       "   var_IWELBO  \n",
       "0    0.387487  \n",
       "1    0.393635  \n",
       "2    0.395425  \n",
       "3    0.393086  \n",
       "4    0.395515  \n",
       "5    0.394883  \n",
       "6    0.388482  \n",
       "7    0.390376  \n",
       "8    0.394209  \n",
       "9    0.396185  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMC_ests = []\n",
    "MLMC_ests = []\n",
    "RandMLMC_ests = []\n",
    "for i in range(10):\n",
    "    N0 = 200000 if tf.test.is_gpu_available() else 10000 \n",
    "    x,y,_ = generate_data(N=N0, D=3, T=2, beta0=beta0, beta=beta, ln_tau=ln_tau)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, ln_tau)\n",
    "    NMC_ests.append( IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=512).numpy() )\n",
    "    MLMC_ests.append( IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=9, w0=0.9, randomize=False).numpy() )\n",
    "    RandMLMC_ests.append( IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=9, w0=0.9, randomize=True).numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std-div of NMC estimator:       0.002744448413707762\n",
      "std-div of MLMC estimator:      0.002959000711463536\n",
      "std-div of RandMLMC estimator:  0.01612633467973764\n"
     ]
    }
   ],
   "source": [
    "print(\"std-div of NMC estimator:      \", np.std(NMC_ests))\n",
    "print(\"std-div of MLMC estimator:     \", np.std(MLMC_ests))\n",
    "print(\"std-div of RandMLMC estimator: \", np.std(RandMLMC_ests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 ms ± 2.41 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "IWELBO(x, y, beta0, beta, ln_tau, mu, sigma, n_MC=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.2 ms ± 1.29 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=9, randomize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.2 ms ± 1.29 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "IWELBO_MLMC(x, y, beta0, beta, ln_tau, mu, sigma, max_level=9, randomize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For finding nice configuration where MLMC wins NMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04788357011927915 1.9797961449704604\n",
      "0.5448827651998229 2.0100303328671436\n"
     ]
    }
   ],
   "source": [
    "N,_ = y.shape\n",
    "n_MC = 2\n",
    "z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "\n",
    "diwelbos = pointwise_dIWELBO(x, y, z, beta0, beta, ln_tau, mu, sigma).numpy()\n",
    "score1 = np.var(NMC_ests) / diwelbos.mean()**2\n",
    "score2 = np.var(MLMC_ests) / np.var(NMC_ests)\n",
    "print(score1, score2)\n",
    "\n",
    "print(np.std(x@beta, axis=1).mean(), z_.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
