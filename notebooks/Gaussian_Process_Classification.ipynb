{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse GP Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$f \\sim\\mathcal{SPGP}(K, z_{1:M})$\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$Y_n \\sim \\mathrm{Bernoulli}(\\sigma(f))$,\n",
    "\n",
    "where $K(x_1,x_2) = \\exp\\left(\\beta - \\sum_{d=1,2}\\mathrm{softplus}({\\alpha_d})\\cdot(x_{1d} - x_{2d})^2\\right)$.\n",
    "<br>\n",
    "Here, latent process $f\\sim\\mathcal{SPGP}(K, z_{1:M})$ is defined as:\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$u=f_0\\small{(z_{1:M})}$ for $f_0\\sim\\mathcal{GP}(K)$\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$f(x)\\sim\\mathcal{GP}(K| f\\small{(z_{1:M})}=u)$ <br>\n",
    "Additionally, conditional independence of process $f$ among any points given $u=f_0\\small{(z_{1:M})} = \\left(f_0(z_1), ..., f_0(z_M)\\right)$ is assumed. <br>\n",
    "That is, for any $n_1$ and $n_2$, $f(x_{n_1})\\perp \\!\\!\\! \\perp f(x_{n_1})|u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Marginalization of Evidece Lower Bound\n",
    "By simplifying notation as $f_{1:N} = f(x_{1:N})$ and $u = f(z_{1:M})$, we can write evidence lower bound (ELBO) and locally margianlized likelihood (LM-ELBO)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathrm{LM}\\text{-}\\mathrm{ELBO}\n",
    "&= \\log p(y_{1:N}) - \\mathrm{KL}\\left[\\ q(u)\\ ||\\ p(u|y_{1:N})\\ \\right] \\\\\n",
    "&= \\mathrm{E}_{u\\sim q}\\left[\\ \\log p(y_{1:N}|u)\\ \\right]\n",
    " - \\mathrm{KL}\\left[\\ q(u)\\ ||\\ p(u)\\ \\right] \\\\\n",
    "&\\geq \\mathrm{E}_{u\\sim q}\\left[\\ \\log p(y_{1:N}|u)\n",
    "- \\mathrm{KL}\\left[\\ p(f_{1:N}|u)\\ ||\\ p(f_{1:N}| y_{1:N}, u)\\ \\right]\\ \\right]\n",
    " - \\mathrm{KL}\\left[\\ q(u)\\ ||\\ p(u)\\ \\right] \\\\\n",
    "&= \\log p(y_{1:N}) - \\mathrm{KL}\\left[ p(f_{1:N}|u)q(u) || p(y_{1:N}, f_{1:N}, u) \\right]\\\\\n",
    "&= \\mathrm{E}_{u\\sim q} \\mathrm{E}_{f_{1:N}\\sim p(f_{1:N}|u)}\\left[\n",
    "\\log \\left(\\frac{p(y_{1:N}, f_{1:N}, u)}{p(f_{1:N}| u)q(u)}\\right) \n",
    "\\right] \\\\\n",
    "&= \\sum_{n=1}^N\\mathrm{E}_{u\\sim q} \\mathrm{E}_{f_n\\sim p(f_n|u)}\n",
    "\\left[ \\log p(y_n| f_n) \\right] \n",
    "- \\mathrm{KL}\\left[\\ q(u)\\ ||\\ p(u)\\ \\right] \\\\\n",
    "&= \\mathrm{ELBO}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Datasets\n",
    "- http://archive.ics.uci.edu/ml/datasets/Adult\n",
    "- http://archive.ics.uci.edu/ml/datasets/Bar+Crawl%3A+Detecting+Heavy+Drinking\n",
    "- http://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008\n",
    "- http://archive.ics.uci.edu/ml/datasets/Buzz+in+social+media+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn GPUs off\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import bernoulli, norm\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1/(1+np.exp(-x))\n",
    "softplus = lambda x: np.log(1+np.exp(x))\n",
    "as_tf_float = lambda x: tf.cast(x, tf.float64)\n",
    "\n",
    "def tf_logsumexp(ary, axis=1, keepdims=False):\n",
    "    return tf.math.reduce_logsumexp(ary, axis=axis, keepdims=keepdims)\n",
    "\n",
    "def tf_logmeanexp(ary, axis=1, keepdims=False):\n",
    "    return tf.math.reduce_logsumexp(ary, axis=axis, keepdims=keepdims) \\\n",
    "        - tf.math.log(as_tf_float(ary.shape[axis]))\n",
    "\n",
    "def timestamp():\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y%m%d%H%M%S\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "D = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramters\n",
    "b0 = np.float64(0.)\n",
    "b  = np.random.randn(D) / np.sqrt(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that we have infinite amount of data.\n",
    "# Thus, generator of the data is implemented.\n",
    "def generate_data(N, D, b0, b):\n",
    "    \"\"\"\n",
    "    Genarate N samples of data from the model with parameter [beta0, beta, alpha]. \n",
    "    Returns:\n",
    "    x: 3-d array of size [N, D]\n",
    "    y: 2-d array of size [N]\n",
    "    \"\"\"\n",
    "    x = np.random.randn(N*D).reshape([N,D])\n",
    "    logit = lambda x: b0+x@b\n",
    "    y = bernoulli(p=sigmoid(logit(x))).rvs()\n",
    "    likelihood = np.sum(y*np.log(sigmoid(logit(x))) + (1-y)*np.log(1-sigmoid(logit(x))))\n",
    "    print('test_likelihood: {}'.format( likelihood ) )\n",
    "    return x,y, logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_likelihood: -560.6633839821673\n"
     ]
    }
   ],
   "source": [
    "x,y,logit = generate_data(N, D, b0, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 30\n",
    "theta = {\n",
    "    'z': tf.Variable(2.*np.random.randn(M*D).reshape([M,D])),\n",
    "    'alpha': tf.Variable(np.ones([D]), dtype=tf.float64),\n",
    "    'beta': tf.Variable(1., dtype=tf.float64)\n",
    "}\n",
    "phi = {\n",
    "    'm': tf.Variable(np.zeros([M]), dtype=tf.float64),\n",
    "    'S': tf.Variable(np.eye(M), dtype=tf.float64)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_K(alpha, beta):\n",
    "    # define Kernel\n",
    "    D = alpha.shape[0]\n",
    "    sp_alpha = tf.reshape( tf.math.softplus( alpha ), [1,1,D])\n",
    "    def K(x1,x2):\n",
    "        n1 = x1.shape[0]\n",
    "        n2 = x2.shape[0]\n",
    "        x1 = tf.reshape(x1, [n1, 1, 2])\n",
    "        x2 = tf.reshape(x2, [1 ,n2, 2])\n",
    "        return tf.exp(beta - tf.reduce_sum( sp_alpha*(x1-x2)**2, axis=2))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELBO(x, y, theta, phi, N_total):\n",
    "    '''\n",
    "    Inputs:\n",
    "    x: 2-d array of shape [N,D]\n",
    "    y: 1-d array of shape [N]\n",
    "    theta: disctionary of model parameters\n",
    "    phi: disctionary of variational parameters\n",
    "    \n",
    "    Returns:\n",
    "    elbo: scalar\n",
    "    '''\n",
    "    \n",
    "    z = theta['z']\n",
    "    alpha = theta['alpha']\n",
    "    beta = theta['beta']\n",
    "    K = get_K(alpha, beta)\n",
    "    \n",
    "    N = y.shape[0]\n",
    "    M = z.shape[0]\n",
    "    \n",
    "    m = phi['m']\n",
    "    S = phi['S'] + 1e-6 * tf.eye(M, dtype=tf.float64)\n",
    "    CholS = tf.linalg.cholesky(S)\n",
    "    \n",
    "    # sample u = f_0(z_1,...,z_M) from q\n",
    "    K_mm = K(z, z) + 1e-6 * tf.eye(M, dtype=tf.float64)\n",
    "    CholK_mm = tf.linalg.cholesky(K_mm)\n",
    "    \n",
    "    p_u = tfp.distributions.MultivariateNormalTriL(loc=0., scale_tril=CholK_mm)\n",
    "    q_u = tfp.distributions.MultivariateNormalTriL(loc=m, scale_tril=CholS)\n",
    "    u = q_u.sample(N)\n",
    "    \n",
    "    \n",
    "    # sample f conditionally given u = f_0(z_1,...,z_M)\n",
    "    inv_CholK_mm = tf.linalg.inv(CholK_mm)\n",
    "    inv_K_mm = tf.transpose(inv_CholK_mm)@inv_CholK_mm\n",
    "    K_nm = K(x, z)\n",
    "    K_mn = tf.transpose(K_nm)\n",
    "    \n",
    "    mean_f = tf.linalg.einsum('ni,ij,nj->n', K_nm, inv_K_mm, u)\n",
    "    var_f = tf.vectorized_map(lambda x:K(x,x), tf.expand_dims(x, axis=1))\n",
    "    var_f = tf.reshape(var_f, [N])\n",
    "    var_f = var_f - tf.linalg.einsum('ni,ij,jn->n', K_nm, inv_K_mm, K_mn)\n",
    "    \n",
    "    q_f = tfp.distributions.Normal(loc=mean_f, scale=var_f)\n",
    "    f = q_f.sample()\n",
    "\n",
    "    # compute ELBO estimate\n",
    "    p_y = tfp.distributions.Bernoulli(logits=f)\n",
    "    kl_qu_pu = tfp.distributions.kl_divergence(q_u, p_u)\n",
    "    elbo = tf.reduce_mean(p_y.log_prob(y)) - kl_qu_pu / N_total\n",
    "    return elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMELBO(x, y, theta, phi, N_total, n_MC):\n",
    "    \n",
    "    z = theta['z']\n",
    "    alpha = theta['alpha']\n",
    "    beta = theta['beta']\n",
    "    K = get_K(alpha, beta)\n",
    "    \n",
    "    N = y.shape[0]\n",
    "    M = z.shape[0]\n",
    "    \n",
    "    m = phi['m']\n",
    "    S = phi['S'] + 1e-6 * tf.eye(M, dtype=tf.float64)\n",
    "    CholS = tf.linalg.cholesky(S)\n",
    "    \n",
    "    # sample u = f_0(z_1,...,z_M) from q\n",
    "    K_mm = K(z, z) + 1e-6 * tf.eye(M, dtype=tf.float64)\n",
    "    CholK_mm = tf.linalg.cholesky(K_mm)\n",
    "    \n",
    "    p_u = tfp.distributions.MultivariateNormalTriL(loc=0., scale_tril=CholK_mm)\n",
    "    q_u = tfp.distributions.MultivariateNormalTriL(loc=m, scale_tril=CholS)\n",
    "    u = q_u.sample(N)\n",
    "    \n",
    "    \n",
    "    # sample f conditionally given u = f_0(z_1,...,z_M)\n",
    "    inv_CholK_mm = tf.linalg.inv(CholK_mm)\n",
    "    inv_K_mm = tf.transpose(inv_CholK_mm)@inv_CholK_mm\n",
    "    K_nm = K(x, z)\n",
    "    K_mn = tf.transpose(K_nm)\n",
    "    \n",
    "    mean_f = tf.linalg.einsum('ni,ij,nj->n', K_nm, inv_K_mm, u)\n",
    "    var_f = tf.vectorized_map(lambda x:K(x,x), tf.expand_dims(x, axis=1))\n",
    "    var_f = tf.reshape(var_f, [N])\n",
    "    var_f = var_f - tf.linalg.einsum('ni,ij,jn->n', K_nm, inv_K_mm, K_mn)\n",
    "    \n",
    "    q_f = tfp.distributions.Normal(loc=mean_f, scale=var_f)\n",
    "    f = q_f.sample(n_MC)\n",
    "\n",
    "    # compute LMELBO estimate\n",
    "    p_y = tfp.distributions.Bernoulli(logits=f)\n",
    "    log_prob_y = tf.reduce_mean( tf_logmeanexp( p_y.log_prob(y) , axis=0) ) \n",
    "    kl_qu_pu = tfp.distributions.kl_divergence(q_u, p_u)\n",
    "    lmelbo = log_prob_y - kl_qu_pu / N_total\n",
    "    return lmelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_dconditional_likelihood(x, y, theta, phi, level):\n",
    "    \n",
    "    z = theta['z']\n",
    "    alpha = theta['alpha']\n",
    "    beta = theta['beta']\n",
    "    K = get_K(alpha, beta)\n",
    "    \n",
    "    N = y.shape[0]\n",
    "    M = z.shape[0]\n",
    "    \n",
    "    m = phi['m']\n",
    "    S = phi['S'] + 1e-6 * tf.eye(M, dtype=tf.float64)\n",
    "    CholS = tf.linalg.cholesky(S)\n",
    "    \n",
    "    # sample u = f_0(z_1,...,z_M) from q\n",
    "    K_mm = K(z, z) + 1e-6 * tf.eye(M, dtype=tf.float64)\n",
    "    CholK_mm = tf.linalg.cholesky(K_mm)\n",
    "    \n",
    "    p_u = tfp.distributions.MultivariateNormalTriL(loc=0., scale_tril=CholK_mm)\n",
    "    q_u = tfp.distributions.MultivariateNormalTriL(loc=m, scale_tril=CholS)\n",
    "    u = q_u.sample(N)\n",
    "    \n",
    "    # sample f conditionally given u = f_0(z_1,...,z_M)\n",
    "    inv_CholK_mm = tf.linalg.inv(CholK_mm)\n",
    "    inv_K_mm = tf.transpose(inv_CholK_mm)@inv_CholK_mm\n",
    "    K_nm = K(x, z)\n",
    "    K_mn = tf.transpose(K_nm)\n",
    "    \n",
    "    mean_f = tf.linalg.einsum('ni,ij,nj->n', K_nm, inv_K_mm, u)\n",
    "    var_f = tf.vectorized_map(lambda x:K(x,x), tf.expand_dims(x, axis=1))\n",
    "    var_f = tf.reshape(var_f, [N])\n",
    "    var_f = var_f - tf.linalg.einsum('ni,ij,jn->n', K_nm, inv_K_mm, K_mn)\n",
    "    \n",
    "    q_f = tfp.distributions.Normal(loc=mean_f, scale=var_f)\n",
    "    n_MC = 2**level\n",
    "    f = q_f.sample(n_MC)\n",
    "\n",
    "    # compute ELBO estimate\n",
    "    p_y = tfp.distributions.Bernoulli(logits=f)\n",
    "    w = p_y.log_prob(y)\n",
    "    w = tf.reshape(w, [n_MC,N])\n",
    "    if level==0:\n",
    "        return tf_logmeanexp(w, axis=0) \n",
    "    else:\n",
    "        return tf_logmeanexp(w, axis=0)\\\n",
    "                - (1/2.) * tf_logmeanexp(w[:n_MC//2 ], axis=0)\\\n",
    "                - (1/2.) * tf_logmeanexp(w[ n_MC//2:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_var = lambda l: pointwise_dconditional_likelihood(x, y, theta, phi, level=l).numpy().var()\n",
    "plt.plot([get_var(l) for l in range(10)])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03126870259468976"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointwise_dconditional_likelihood(x, y, theta, phi, level=1).numpy().var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0041383015103111515"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointwise_dconditional_likelihood(x, y, theta, phi, level=2).numpy().var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013936474982571894"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointwise_dconditional_likelihood(x, y, theta, phi, level=3).numpy().var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012949616413605766"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointwise_dconditional_likelihood(x, y, theta, phi, level=4).numpy().var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dconditional_likelihood(x, y, mean_f, var_f, level):\n",
    "    \n",
    "    N = y.shape[0]\n",
    "    # sample f_n's\n",
    "    q_f = tfp.distributions.Normal(loc=mean_f, scale=var_f)\n",
    "    n_MC = 2**level\n",
    "    f = q_f.sample(n_MC)\n",
    "    \n",
    "    # sample conditional likelihoods\n",
    "    p_y = tfp.distributions.Bernoulli(logits=f)\n",
    "    w = p_y.log_prob(y)\n",
    "    w = tf.reshape(w, [n_MC,N])\n",
    "    \n",
    "    if level==0:\n",
    "        dL = tf_logmeanexp(w, axis=0) \n",
    "    else:\n",
    "        dL = tf_logmeanexp(w, axis=0)\\\n",
    "                - (1/2.) * tf_logmeanexp(w[:n_MC//2 ], axis=0)\\\n",
    "                - (1/2.) * tf_logmeanexp(w[ n_MC//2:], axis=0)\n",
    "    return tf.reduce_mean( dL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMELBO_MLMC(x, y, theta, phi, N_total, max_level=8, w0=1-2.**(-3/2), b=2, randomize=False):\n",
    "    \"\"\"\n",
    "    Compute IWELBO by MLMC\n",
    "    \n",
    "    Arguments:\n",
    "    x: 3-d array of size [N, T, D]\n",
    "    y: 2-d array of size [N, T]\n",
    "    beta0: scalar\n",
    "    beta: 1-d array of size [D]\n",
    "    alpha: scalar\n",
    "    mu: 1-d array of size [N]\n",
    "    sigma: 1-d array of size [N]\n",
    "    max_level: integer\n",
    "    w0: the proportion of total samples in (x,y) used at the level 0.\n",
    "        in other words, 100*(1-w0) % of the total samples are used for estimating the correction term.\n",
    "    b: scalar. the second moment of the coupled difference estimator (dIWELBO) must decrease at a rate of O(2^(-b*level)).\n",
    "    randomize: whether to use randomization of MLMC.\n",
    "    \n",
    "    Returns:\n",
    "    iwelbo: scalar estimate of average iwelbo over sample points.\n",
    "    \"\"\"\n",
    "    # unpack parameters\n",
    "    z = theta['z']\n",
    "    alpha = theta['alpha']\n",
    "    beta = theta['beta']\n",
    "    K = get_K(alpha, beta)\n",
    "    \n",
    "    N = y.shape[0]\n",
    "    M = z.shape[0]\n",
    "    \n",
    "    m = phi['m']\n",
    "    S = phi['S'] + 1e-6 * tf.eye(M, dtype=tf.float64)\n",
    "    CholS = tf.linalg.cholesky(S)\n",
    "    \n",
    "    # calculate KL divergence of p(u) and q(u) of u = f_0(z_1,...,z_M)\n",
    "    K_mm = K(z, z) + 1e-6 * tf.eye(M, dtype=tf.float64)\n",
    "    CholK_mm = tf.linalg.cholesky(K_mm)\n",
    "    \n",
    "    p_u = tfp.distributions.MultivariateNormalTriL(loc=0., scale_tril=CholK_mm)\n",
    "    q_u = tfp.distributions.MultivariateNormalTriL(loc=m, scale_tril=CholS)\n",
    "    kl_qu_pu = tfp.distributions.kl_divergence(q_u, p_u)\n",
    "      \n",
    "    # calculate distribution of f conditionally on u = f_0(z_1,...,z_M)\n",
    "    u = q_u.sample(N)\n",
    "    inv_CholK_mm = tf.linalg.inv(CholK_mm)\n",
    "    inv_K_mm = tf.transpose(inv_CholK_mm)@inv_CholK_mm\n",
    "    K_nm = K(x, z)\n",
    "    K_mn = tf.transpose(K_nm)\n",
    "    \n",
    "    mean_f = tf.linalg.einsum('ni,ij,nj->n', K_nm, inv_K_mm, u)\n",
    "    var_f = tf.vectorized_map(lambda x:K(x,x), tf.expand_dims(x, axis=1))\n",
    "    var_f = tf.reshape(var_f, [N])\n",
    "    var_f = var_f - tf.linalg.einsum('ni,ij,jn->n', K_nm, inv_K_mm, K_mn)\n",
    "    \n",
    "    # determine proportions of the number of smaples among levels\n",
    "    if max_level==0:\n",
    "        levels = np.array([0])\n",
    "        weights = np.array([1.])\n",
    "    else:\n",
    "        weights = 2.**(-(b+1)/2*np.arange(max_level))\n",
    "        weights /= sum(weights)\n",
    "        weights = np.concatenate([[w0], (1-w0)*weights])\n",
    "        levels = np.arange(max_level+1)\n",
    "    \n",
    "    # determine the N_l's\n",
    "    if randomize==True:\n",
    "        Ns = np.random.multinomial(n=N, pvals=weights)    \n",
    "    elif randomize==False:\n",
    "        Ns = np.array([np.math.ceil(w*N) for w in weights], dtype=np.int)\n",
    "        Ns[0] = N - sum(Ns[1:])\n",
    "    else:\n",
    "        raise(Exception(\"Invarid argument for 'randomize' of function IWELBO_MLMC. It must be True or False.\"))\n",
    "    \n",
    "    # compute dIWELBO's using disjoint samples at each level and sum them up\n",
    "    offset = 0\n",
    "    lmelbo = kl_qu_pu / N_total\n",
    "    for i, l in enumerate(levels):\n",
    "        if Ns[i]==0:\n",
    "            continue\n",
    "        x_tmp = x[offset:offset+Ns[i]]\n",
    "        y_tmp = y[offset:offset+Ns[i]]\n",
    "        mean_f_tmp = mean_f[offset:offset+Ns[i]]\n",
    "        var_f_tmp = var_f[offset:offset+Ns[i]]\n",
    "                       \n",
    "        if randomize==True:\n",
    "            lmelbo += dconditional_likelihood(x_tmp, y_tmp, mean_f_tmp, var_f_tmp, level=l) * Ns[i] / N / weights[i]   \n",
    "        elif randomize==False:\n",
    "            lmelbo += dconditional_likelihood(x_tmp, y_tmp, mean_f_tmp, var_f_tmp, level=l)\n",
    "    \n",
    "        offset += Ns[i]\n",
    "          \n",
    "    return lmelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-0.901020819650497>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ELBO(x, y, theta, phi, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-0.8438692044035605>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LMELBO(x, y, theta, phi, 10000, n_MC=2**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-0.8029116955270268>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LMELBO_MLMC(x, y, theta, phi, N_total=10000, max_level=10, w0=1-2.**(-3/2), b=2, randomize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_grad(param, dparam, learning_rate):\n",
    "    for p, dp in zip(param.values(), dparam.values()):\n",
    "        p.assign_add(learning_rate * dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_natgrad_phi(phi, deta, learning_rate):\n",
    "    m = phi['m']\n",
    "    S = phi['S']\n",
    "    deta_m = deta['m']\n",
    "    deta_S = deta['S']\n",
    "    phi['m'].assign_add(learning_rate * tf.einsum('ni,i->n',S,deta_m))\n",
    "    phi['S'].assign_add(learning_rate * S@deta_S@S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_to_eta = lambda phi: {\n",
    "    'm': phi['m'],\n",
    "    'S': tf.einsum('i,j->ij', phi['m'], phi['m']) + phi['S']\n",
    "}\n",
    "eta_to_phi = lambda eta: {\n",
    "            'm': eta['m'],\n",
    "            'S': eta['S'] - tf.einsum('i,j->ij', eta['m'], eta['m'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#iter: 0\t-599.3167285009555\n",
      "#iter: 20\t-596.3427775834537\n",
      "#iter: 40\t-603.8747974515564\n",
      "#iter: 60\t-593.5232744364357\n",
      "#iter: 80\t-595.1759263598262\n",
      "#iter: 100\t-592.170186114221\n",
      "#iter: 120\t-594.96390174708\n",
      "#iter: 140\t-587.0179151632208\n",
      "#iter: 160\t-591.8284663629383\n",
      "#iter: 180\t-601.2980219786311\n",
      "#iter: 200\t-592.8169245706313\n",
      "#iter: 220\t-592.02140801903\n",
      "#iter: 240\t-597.9149655230425\n",
      "#iter: 260\t-604.2983377092937\n",
      "#iter: 280\t-597.4702607026721\n",
      "#iter: 300\t-587.6159067373495\n",
      "#iter: 320\t-590.761479947319\n",
      "#iter: 340\t-608.3326405899463\n",
      "#iter: 360\t-584.0611601590609\n",
      "#iter: 380\t-589.2489495774226\n",
      "#iter: 400\t-592.1154299144698\n",
      "#iter: 420\t-590.9475840693109\n",
      "#iter: 440\t-593.6364162912218\n",
      "#iter: 460\t-596.8169698733567\n",
      "#iter: 480\t-587.6703645613358\n",
      "#iter: 500\t-604.2846950350487\n",
      "#iter: 520\t-595.1472798077003\n",
      "#iter: 540\t-593.5570482408993\n",
      "#iter: 560\t-594.2744375230079\n",
      "#iter: 580\t-590.9963358440752\n",
      "#iter: 600\t-593.807442863517\n",
      "#iter: 620\t-584.0488757204727\n",
      "#iter: 640\t-599.9984482362213\n",
      "#iter: 660\t-596.4256614320229\n",
      "#iter: 680\t-584.8362535061797\n",
      "#iter: 700\t-593.333414784777\n",
      "#iter: 720\t-600.6409932598519\n",
      "#iter: 740\t-588.0255898505154\n",
      "#iter: 760\t-597.8056877762682\n",
      "#iter: 780\t-594.7645523214593\n",
      "#iter: 800\t-593.6264296254783\n",
      "#iter: 820\t-585.887543605163\n",
      "#iter: 840\t-586.8016130500476\n",
      "#iter: 860\t-583.5479000697487\n",
      "#iter: 880\t-592.7560791358004\n",
      "#iter: 900\t-589.029538159237\n",
      "#iter: 920\t-591.8056491823544\n",
      "#iter: 940\t-594.0830655248826\n",
      "#iter: 960\t-587.5065868900708\n",
      "#iter: 980\t-590.4825593768497\n"
     ]
    }
   ],
   "source": [
    "for t in range(1000):\n",
    "    rho_t = 10/(10+t)**0.7\n",
    "    \n",
    "    with tf.GradientTape() as g:\n",
    "        eta = phi_to_eta(phi)\n",
    "        g.watch([theta, eta])\n",
    "        phi_tmp = eta_to_phi(eta)\n",
    "        lmelbo = LMELBO(x, y, theta, phi_tmp, n_MC=10)\n",
    "    dtheta, deta = g.gradient(lmelbo, [theta, eta])\n",
    "    \n",
    "    apply_grad(theta, dtheta, rho_t)\n",
    "    apply_natgrad_phi(phi, deta, rho_t)\n",
    "    \n",
    "    if t%20==0:\n",
    "        print('#iter: {}\\t{}'.format(t, lmelbo.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#iter: 0\t-890.8624765026154\n",
      "#iter: 20\t-697.8474758725588\n",
      "#iter: 40\t-665.919811764245\n",
      "#iter: 60\t-657.3072190558822\n",
      "#iter: 80\t-662.1433414510145\n",
      "#iter: 100\t-667.5221570997699\n",
      "#iter: 120\t-639.7643349423189\n",
      "#iter: 140\t-638.9777205587757\n",
      "#iter: 160\t-645.0049310390618\n",
      "#iter: 180\t-643.3594486077355\n",
      "#iter: 200\t-627.0965103636099\n",
      "#iter: 220\t-628.1768501878715\n",
      "#iter: 240\t-615.8963230770331\n",
      "#iter: 260\t-632.7243975856217\n",
      "#iter: 280\t-641.0877760231249\n",
      "#iter: 300\t-626.4418771867704\n",
      "#iter: 320\t-619.4794970808142\n",
      "#iter: 340\t-624.5115608854521\n",
      "#iter: 360\t-625.5142580741636\n",
      "#iter: 380\t-607.8812043772948\n",
      "#iter: 400\t-628.6381653396292\n",
      "#iter: 420\t-607.8471703727811\n",
      "#iter: 440\t-640.1321093605526\n",
      "#iter: 460\t-638.2483232931978\n",
      "#iter: 480\t-625.9379517414916\n",
      "#iter: 500\t-615.162652231652\n",
      "#iter: 520\t-634.6126625663886\n",
      "#iter: 540\t-627.1681618615042\n",
      "#iter: 560\t-623.0588398487761\n",
      "#iter: 580\t-619.9994226416111\n",
      "#iter: 600\t-611.5802187291014\n",
      "#iter: 620\t-625.134025580645\n",
      "#iter: 640\t-610.713602660471\n",
      "#iter: 660\t-608.8578182812253\n",
      "#iter: 680\t-607.6196524984312\n",
      "#iter: 700\t-615.8107542437557\n",
      "#iter: 720\t-603.4922896016466\n",
      "#iter: 740\t-616.3957911398843\n",
      "#iter: 760\t-618.5631798854174\n",
      "#iter: 780\t-630.0745279751493\n",
      "#iter: 800\t-613.583376965025\n",
      "#iter: 820\t-611.1857090931202\n",
      "#iter: 840\t-609.1591417218767\n",
      "#iter: 860\t-609.0003116337197\n",
      "#iter: 880\t-610.2440202925231\n",
      "#iter: 900\t-630.4592518092185\n",
      "#iter: 920\t-603.3828741986708\n",
      "#iter: 940\t-595.6059968803725\n",
      "#iter: 960\t-616.8711523125793\n",
      "#iter: 980\t-610.2689797532215\n"
     ]
    }
   ],
   "source": [
    "for t in range(1000):\n",
    "    rho_t = 10/(10+t)**0.7\n",
    "    \n",
    "    with tf.GradientTape() as g:\n",
    "        eta = phi_to_eta(phi)\n",
    "        g.watch([theta, eta])\n",
    "        phi_tmp = eta_to_phi(eta)\n",
    "        elbo = ELBO(x, y, theta, phi_tmp)\n",
    "    dtheta, deta = g.gradient(elbo, [theta, eta])\n",
    "    \n",
    "    apply_grad(theta, dtheta, rho_t)\n",
    "    apply_natgrad_phi(phi, deta, rho_t)\n",
    "    \n",
    "    if t%20==0:\n",
    "        print('#iter: {}\\t{}'.format(t, elbo.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(x, theta, phi):\n",
    "    \n",
    "    z = theta['z']\n",
    "    alpha = theta['alpha']\n",
    "    beta = theta['beta']\n",
    "    K = get_K(alpha, beta)\n",
    "    m = phi['m']\n",
    "    S = phi['S']\n",
    "    CholS = tf.linalg.cholesky(S)\n",
    "    \n",
    "    N = x.shape[0]\n",
    "    M = z.shape[0]\n",
    "    \n",
    "    K_mm = K(z, z) + 1e-6 * tf.eye(M, dtype=tf.float64)\n",
    "    CholK_mm = tf.linalg.cholesky(K_mm)\n",
    "    inv_CholK_mm = tf.linalg.inv(CholK_mm)\n",
    "    inv_K_mm = tf.transpose(inv_CholK_mm)@inv_CholK_mm\n",
    "    K_nm = K(x, z)\n",
    "    K_mn = tf.transpose(K_nm)\n",
    "    \n",
    "    mean_f = tf.linalg.einsum('ni,ij,j->n', K_nm, inv_K_mm, m)\n",
    "    var_f = tf.vectorized_map(lambda x:K(x,x), tf.expand_dims(x, axis=1))\n",
    "    var_f = tf.reshape(var_f, [N])\n",
    "    var_f = var_f - tf.linalg.einsum('ni,ij,jn->n', K_nm, inv_K_mm, K_mn)\n",
    "    \n",
    "    return mean_f, var_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_heat = (np.linspace(start=-4,stop=4).reshape([1,50])*np.ones([50,1])).reshape([2500])\n",
    "x2_heat = np.repeat(np.linspace(start=-4,stop=4), 50)\n",
    "x_heat = np.array([x1_heat, x2_heat]).T\n",
    "logits_heat = get_logits(x_heat, theta, phi)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap2d(arr: np.ndarray, cmap='viridis'):\n",
    "    plt.imshow(arr, cmap=cmap, extent=[-4,4,-4,4],origin='lower', alpha=1, vmin=0, vmax=1)\n",
    "    plt.colorbar()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[15,4])\n",
    "cmap = matplotlib.cm.get_cmap('bwr')#('viridis')\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Observations')\n",
    "idx = (y==True)\n",
    "plt.scatter(x[idx,0], x[idx,1], s=2, alpha=0.5, marker='o', c=[cmap(1.)])\n",
    "plt.scatter(x[~idx,0], x[~idx,1], s=2, alpha=0.5, marker='o', c=[cmap(0.)])\n",
    "plt.legend(['y=1','y=0'])\n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Ground Truth p(y=1|x)')\n",
    "heatmap2d(sigmoid(logit(x_heat)).reshape([50,50]), 'bwr')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(r'Variational GP posterior $q(y=1|x)$')\n",
    "#plt.scatter(x[idx,0], x[idx,1], s=0.3, alpha=1, marker='x', c=[cmap(1.)])\n",
    "#plt.scatter(x[~idx,0], x[~idx,1], s=0.3, alpha=1, marker='x', c=[cmap(0.)])\n",
    "a = plt.scatter(theta['z'][:,0], theta['z'][:,1], s=4, alpha=1, marker='o', c='black')\n",
    "plt.legend([a],['pseudo input'])\n",
    "heatmap2d(sigmoid(logits_heat.reshape([50,50])), 'bwr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IW-ELBO approximation of Evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance weighted evidence lower bound (IW-ELBO) is an approximation of the evidence, and its Monte Carlo estimator is defined as:\n",
    "$$\\mathrm{IW}\\text{-}\\mathrm{ELBO}(x,z_{1:K}):=\\frac{1}{N}\\sum_{n=1}^{N}\\log \\frac{1}{K}\\sum_{k=1}^{K}\\left(\\frac{p(x_n,z_{nk})}{q(z_{nk};x_n)}\\right),$$\n",
    "where $z_{nk}$ is sampled as $z_{nk}\\sim q(z;x_n)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_IWELBO(x, y, z, beta0, beta, alpha, mu, sigma):\n",
    "    \"\"\"\n",
    "    Compute IWELBOs using n_MC inner Monte Carlo samples of Z's at each sample point. \n",
    "    \n",
    "    Arguments:\n",
    "    x: 3-d array of size [N, T, D]\n",
    "    y: 2-d array of size [N, T]\n",
    "    z: 1-d array of size [n_MC, N]\n",
    "    beta0: scalar\n",
    "    beta: 1-d array of size [D]\n",
    "    alpha: scalar\n",
    "    mu: 1-d array of size [N]\n",
    "    sigma: 1-d array of size [N]\n",
    "     \n",
    "    Returns:\n",
    "    iwelbos: 1-d array of size [N]\n",
    "    \"\"\"\n",
    "\n",
    "    (N, T, D), (n_MC, n) = x.shape, z.shape\n",
    "    y = as_tf_float( tf.reshape(y, [1,N,T]) )\n",
    "    mu = tf.reshape(mu, [1,N])\n",
    "    sigma = tf.reshape(sigma, [1,N])\n",
    "    \n",
    "    y_logits = tf.convert_to_tensor( beta0\\\n",
    "                                    + tf.reshape( x@tf.reshape(beta, [D,1]), [1, N, T])\\\n",
    "                                    + tf.reshape(z, [n_MC, N, 1]) \n",
    "                                   )\n",
    "    p_y = tfp.distributions.Bernoulli(logits=y_logits)\n",
    "    p_z = tfp.distributions.Normal(loc=np.zeros([1, N]), scale=tf.math.softplus(alpha)**(1/2.))\n",
    "    q_z = tfp.distributions.Normal(loc=mu, scale=sigma)\n",
    "    \n",
    "    log_prob_ratio = \\\n",
    "        tf.reduce_sum( p_y.log_prob(y), axis=2)\\\n",
    "        + p_z.log_prob(z)\\\n",
    "        - q_z.log_prob(z)\n",
    "    \n",
    "    iwelbos = tf_logmeanexp(log_prob_ratio, axis=0)\n",
    "    return iwelbos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWELBO(x, y, beta0, beta, alpha, mu, sigma, n_MC):\n",
    "    \"\"\"\n",
    "    Compute IWELBO\n",
    "    \n",
    "    Arguments:\n",
    "    x: 3-d array of size [N, T, D]\n",
    "    y: 2-d array of size [N, T]\n",
    "    beta0: scalar\n",
    "    beta: 1-d array of size [D]\n",
    "    alpha: scalar\n",
    "    mu: 1-d array of size [N]\n",
    "    sigma: 1-d array of size [N]\n",
    "     \n",
    "    Returns:\n",
    "    iwelbo: scalar value of average of iwelbo's at each sample point.\n",
    "    \"\"\"\n",
    "\n",
    "    N, = mu.shape\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    iwelbo = tf.reduce_mean( pointwise_IWELBO(x, y, z, beta0, beta, alpha, mu, sigma) )\n",
    "    return iwelbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_dIWELBO(x, y, z, beta0, beta, alpha, mu, sigma):\n",
    "    \"\"\"\n",
    "    Compute the coupled differences of IWELBO's at each sample point.\n",
    "    Differences between \"IWELBO with n_MC inner Monte Carlo samples\" \n",
    "    and \"IWELBO with n_MC/2 inner Monte Carlo samples\" are taken.\n",
    "    \n",
    "    Note that difference is not taken when n_MC = 1. \n",
    "    In that case, IWELBO with n_MC = 1 is Evaluated.\n",
    "    \n",
    "    Arguments:\n",
    "    x: 3-d array of size [N, T, D]\n",
    "    y: 2-d array of size [N, T]\n",
    "    z: 1-d array of size [n_MC, N]\n",
    "    beta0: scalar\n",
    "    beta: 1-d array of size [D]\n",
    "    alpha: scalar\n",
    "    mu: 1-d array of [N]\n",
    "    sigma: 1-d array of [N]\n",
    "     \n",
    "    Returns:\n",
    "    scores: 1-d array of size [N]\n",
    "    \"\"\"\n",
    "    \n",
    "    (N, T, D), (n_MC, N) = x.shape, z.shape\n",
    "    assert np.log2(n_MC)%1==0\n",
    "    \n",
    "    if n_MC == 1:\n",
    "        scores = pointwise_IWELBO(x, y, z, beta0, beta, alpha, mu, sigma)\n",
    "    else:\n",
    "        scores = pointwise_IWELBO(x, y, z, beta0, beta, alpha, mu, sigma)\n",
    "        scores -= (1/2.) * pointwise_IWELBO(x, y, z[:n_MC//2 ], beta0, beta, alpha, mu, sigma)\n",
    "        scores -= (1/2.) * pointwise_IWELBO(x, y, z[ n_MC//2:], beta0, beta, alpha, mu, sigma)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dIWELBO(x, y, beta0, beta, alpha, mu, sigma, level):\n",
    "    \"\"\"\n",
    "    Compute average of the coupled differences of IWELBO's with n_MC.\n",
    "    Differences between \"IWELBO with n_MC inner Monte Carlo samples\" \n",
    "    and \"IWELBO with n_MC/2 inner Monte Carlo samples\" are taken.\n",
    "    \n",
    "    Note that difference is not taken when n_MC = 1. \n",
    "    In that case, average IWELBO with n_MC = 1 is Evaluated.\n",
    "    \n",
    "    Arguments:\n",
    "    x: 3-d array of size [N, T, D]\n",
    "    y: 2-d array of size [N, T]\n",
    "    beta0: scalar\n",
    "    beta: 1-d array of size [D]\n",
    "    alpha: scalar\n",
    "    mu: 1-d array of size [N]\n",
    "    sigma: 1-d array of size [N]\n",
    "     \n",
    "    Returns:\n",
    "    score: scalar value of average of differnece of iwelbo's at each sample point (except when n_MC=1).\n",
    "    \"\"\"\n",
    "\n",
    "    N, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    \n",
    "    score = tf.reduce_mean( pointwise_dIWELBO(x, y, z, beta0, beta, alpha, mu, sigma) )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=8, w0=1-2.**(-3/2), b=2, randomize=False):\n",
    "    \"\"\"\n",
    "    Compute IWELBO by MLMC\n",
    "    \n",
    "    Arguments:\n",
    "    x: 3-d array of size [N, T, D]\n",
    "    y: 2-d array of size [N, T]\n",
    "    beta0: scalar\n",
    "    beta: 1-d array of size [D]\n",
    "    alpha: scalar\n",
    "    mu: 1-d array of size [N]\n",
    "    sigma: 1-d array of size [N]\n",
    "    max_level: integer\n",
    "    w0: the proportion of total samples in (x,y) used at the level 0.\n",
    "        in other words, 100*(1-w0) % of the total samples are used for estimating the correction term.\n",
    "    b: scalar. the second moment of the coupled difference estimator (dIWELBO) must decrease at a rate of O(2^(-b*level)).\n",
    "    randomize: whether to use randomization of MLMC.\n",
    "    \n",
    "    Returns:\n",
    "    iwelbo: scalar estimate of average iwelbo over sample points.\n",
    "    \"\"\"\n",
    "    \n",
    "    N, T, D = x.shape\n",
    "    \n",
    "    # determine proportions of the number of smaples among levels\n",
    "    if max_level==0:\n",
    "        levels = np.array([0])\n",
    "        weights = np.array([1.])\n",
    "    else:\n",
    "        weights = 2.**(-(b+1)/2*np.arange(max_level))\n",
    "        weights /= sum(weights)\n",
    "        weights = np.concatenate([[w0], (1-w0)*weights])\n",
    "        levels = np.arange(max_level+1)\n",
    "    \n",
    "    # determine the N_l's\n",
    "    if randomize==True:\n",
    "        Ns = np.random.multinomial(n=N, pvals=weights)    \n",
    "    elif randomize==False:\n",
    "        Ns = np.array([np.math.ceil(w*N) for w in weights], dtype=np.int)\n",
    "        Ns[0] = N - sum(Ns[1:])\n",
    "    else:\n",
    "        raise(Exception(\"Invarid argument for 'randomize' of function IWELBO_MLMC. It must be True or False.\"))\n",
    "    \n",
    "    # compute dIWELBO's using disjoint samples at each level and sum them up\n",
    "    offset = 0\n",
    "    iwelbo = 0\n",
    "    for i, l in enumerate(levels):\n",
    "        if Ns[i]==0:\n",
    "            continue\n",
    "        x_tmp = x[offset:offset+Ns[i]]\n",
    "        y_tmp = y[offset:offset+Ns[i]]\n",
    "        mu_tmp = mu[offset:offset+Ns[i]]\n",
    "        sigma_tmp = sigma[offset:offset+Ns[i]]\n",
    "                       \n",
    "        if randomize==True:\n",
    "            iwelbo += dIWELBO(x_tmp, y_tmp, beta0, beta, alpha, mu_tmp, sigma_tmp, level=l) * Ns[i] / N / weights[i]   \n",
    "        elif randomize==False:\n",
    "            iwelbo += dIWELBO(x_tmp, y_tmp, beta0, beta, alpha, mu_tmp, sigma_tmp, level=l)\n",
    "        \n",
    "        offset += Ns[i]\n",
    "    \n",
    "    return iwelbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance Analysis of SUMO:\n",
    "We assume that $\\mathbb{P}(k\\leq\\mathcal{K})=\\frac{1}{k}$ for $\\mathcal{K}\\leq K_{\\text{max}}$, and accordingly, $\\mathbb{P}(k\\leq\\mathcal{K})=\\frac{1}{k(k+1)}$. Also, we know convergence rate of $\\Delta_k:=\\mathrm{IWELBO(x,z_{1:k})} - \\mathrm{IWELBO(x,z_{1:k-1})}$ is as following:\n",
    "\n",
    "- $\\mathrm{E}|\\Delta_k| = \\mathcal{O}(1/k)$\n",
    "- $\\mathrm{E}|\\Delta_k|^2 = \\mathcal{O}(1/k^2) \\geq \\mathrm{Var}[\\Delta_k]$\n",
    "- $\\mathrm{E}[\\Delta_k] = \\mathcal{O}(1/k^2)$$\\sum_{k=K}^{\\infty}\\mathrm{E}[\\Delta_k] = \\mathcal{O}(\\frac{1}{K})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using above properties, we can analyze the order of magnitude of the variance of SUMO as:\n",
    "\\begin{align}\n",
    "\\mathrm{Var}[\\Delta SUMO]\n",
    "&= \\mathrm{Var}_{\\mathcal{K}, \\Delta_{1:K_{\\text{max}}}} \n",
    "\\left( \\sum_{k=1}^{K_{\\text{max}}} \\frac { \\mathbb{1}_{(k\\leq\\mathcal{K})} } \n",
    "{ \\mathbb{P}(k\\leq\\mathcal{K}) } \\Delta_k \\right) \\\\\n",
    "&= \\mathrm{E}_{\\mathcal{K}}\\mathrm{Var}_{\\Delta_{1:K_{\\text{max}}}}\n",
    "\\left( \\sum_{k=1}^{\\mathcal{K}} k \\Delta_k | \\mathcal {K}\\right)\n",
    " + \\mathrm{Var}_{\\mathcal{K}}\\mathrm{E}_{\\Delta_{1:K_{\\text{max}}}}\n",
    "\\left( \\sum_{k=1}^{\\mathcal{K}} k \\Delta_k | \\mathcal {K}\\right) \\\\\n",
    "&= \\mathrm{E}_{\\mathcal{K}}\\sum_{k=1}^{\\mathcal{K}} k^2 \\mathrm{Var}_{\\Delta_{1:K_{\\text{max}}}}\n",
    "\\left( \\Delta_k | \\mathcal {K}\\right)\n",
    " + \\mathrm{Var}_{\\mathcal{K}} \\sum_{k=1}^{\\mathcal{K}} k \\mathrm{E}_{\\Delta_{1:K_{\\text{max}}}}\n",
    "\\left( \\Delta_k | \\mathcal {K}\\right) \\\\\n",
    "&= \\mathrm{E}_{\\mathcal{K}}\\sum_{k=1}^{\\mathcal{K}} k^2 \\mathcal{O}(1/k^2)\n",
    " + \\mathrm{Var}_{\\mathcal{K}} \\sum_{k=1}^{\\mathcal{K}} k \\mathcal{O}(1/k^2) \\\\\n",
    "&= \\mathrm{E}_{\\mathcal{K}} \\mathcal{O}(\\mathcal{K})\n",
    " + \\mathrm{Var}_{\\mathcal{K}}\\mathcal{O}(\\log \\mathcal{K}) \\\\\n",
    "&= \\mathcal{O}(\\log K_{\\text{max}}) + \\text{const.}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the expected complexity of SUMO is $\\mathrm{E}[\\mathcal{\\mathcal{K}}] = \\mathcal{O}(\\log K_{\\text{max}})$. Therefore, the \"variance per reciprocal complexity\" for SUMO is $\\mathcal{O}\\left((\\log K_{\\text{max}})^2\\right)$. Those for NMC and MLMC are $\\mathcal{O}(K_{\\text{max}})$ and $\\mathcal{O}(1)$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_IWELBO_SUMO(x, y, beta0, beta, alpha, mu, sigma, K):\n",
    "    \"\"\"\n",
    "    Compute IWELBO by SUMO for one sample point, given K\n",
    "    \n",
    "    Arguments:\n",
    "    x: 3-d array of size [N, T, D]\n",
    "    y: 2-d array of size [N, T]\n",
    "    beta0: scalar\n",
    "    beta: 1-d array of size [D]\n",
    "    alpha: scalar\n",
    "    mu: 1-d array of size [N]\n",
    "    sigma: 1-d array of size [N]\n",
    "    K: integer \n",
    "    \n",
    "    Returns:\n",
    "    iwelbo: scalar estimate of iwelbo at the given sample point.\n",
    "    \"\"\"\n",
    "    N,T,D = x.shape\n",
    "    z = tf.random.normal(mean=mu, stddev=sigma, shape=[K,N], dtype=tf.float64)\n",
    "\n",
    "    # compute prob ratio of shape [K,N]\n",
    "    y_logit = beta0 + tf.reshape( x @ tf.reshape(beta,[D,1]), [1,N,T] ) + tf.reshape(z,[K,N,1]) \n",
    "    p_y = tfp.distributions.Bernoulli(logits=y_logit)\n",
    "    p_z = tfp.distributions.Normal(loc=0, scale=tf.math.softplus(alpha)**(1/2.))\n",
    "    q_z = tfp.distributions.Normal(loc=mu, scale=sigma)\n",
    "    \n",
    "    log_prob_ratio = \\\n",
    "        tf.reduce_sum( p_y.log_prob(y), axis=2)\\\n",
    "        + p_z.log_prob(z)\\\n",
    "        - q_z.log_prob(z)\n",
    "    \n",
    "    # compute SUMO est.\n",
    "    ks = tf.reshape( tf.cast( tf.range(0,K) + 1, tf.float64), [K,1])\n",
    "    cum_iwelbo = tf.math.cumulative_logsumexp(log_prob_ratio, axis=0) - tf.math.log(ks)\n",
    "    inv_weights = ks\n",
    "    iwelbo = cum_iwelbo[0,:] + tf.reduce_sum(inv_weights[1:] * (cum_iwelbo[1:] - cum_iwelbo[:K-1]), axis=0)\n",
    "    \n",
    "    return iwelbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWELBO_SUMO(x, y, beta0, beta, alpha, mu, sigma, K_max=64):\n",
    "    \"\"\"\n",
    "    Compute IWELBO by MLMC\n",
    "    \n",
    "    Arguments:\n",
    "    x: 3-d array of size [N, T, D]\n",
    "    y: 2-d array of size [N, T]\n",
    "    beta0: scalar\n",
    "    beta: 1-d array of size [D]\n",
    "    alpha: scalar\n",
    "    mu: 1-d array of size [N]\n",
    "    sigma: 1-d array of size [N]\n",
    "    K_max: integer \n",
    "    \n",
    "    Returns:\n",
    "    iwelbo: scalar estimate of average iwelbo over sample points.\n",
    "    \"\"\"\n",
    "    \n",
    "    N,T,D = x.shape\n",
    "    \n",
    "    Us = tf.random.uniform(shape=[N], dtype=tf.float64)\n",
    "    Ks = tf.minimum(1/Us, tf.cast(K_max, tf.float64))\n",
    "    Ks = tf.cast(tf.math.floor(Ks), tf.int64)\n",
    "    unique, _, counts =  tf.unique_with_counts(tf.sort(Ks))\n",
    "    \n",
    "    offset = 0\n",
    "    iwelbo = 0\n",
    "    for K, cnt in zip(unique, counts):\n",
    "        x_tmp = x[offset:offset+cnt]\n",
    "        y_tmp = y[offset:offset+cnt]\n",
    "        mu_tmp = mu[offset:offset+cnt]\n",
    "        sigma_tmp = sigma[offset:offset+cnt]\n",
    "        iwelbo += (1/N) * tf.reduce_sum( conditional_IWELBO_SUMO(x_tmp, y_tmp, beta0, beta, alpha, mu_tmp, sigma_tmp, K) ) \n",
    "        offset += cnt\n",
    "    \n",
    "    return iwelbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure that implementations are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'beta0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-76d49e4a717e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaplace_approx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'beta0' is not defined"
     ]
    }
   ],
   "source": [
    "x,y,_ = generate_data(N=10000, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "mu, sigma = laplace_approx(x, y, beta0, beta, alpha)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signorm_likelihood = sigmoid_normal_likelihood(x, y, beta0, beta, alpha).numpy()\n",
    "elbo_likelihood = IWELBO(x, y, beta0, beta, alpha, mu, sigma, n_MC=1).numpy()\n",
    "iwelbo_likelihood = IWELBO(x, y, beta0, beta, alpha, mu, sigma, n_MC=64).numpy()\n",
    "iwelbo_likelihood_mlmc = IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=6, w0=0.9, randomize=False).numpy()\n",
    "iwelbo_likelihood_randmlmc = IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=6, w0=0.9, randomize=True).numpy()\n",
    "iwelbo_likelihood_sumo = IWELBO_SUMO(x, y, beta0, beta, alpha, mu, sigma, K_max=10000).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signorm_likelihood, elbo_likelihood, iwelbo_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwelbo_likelihood_mlmc, iwelbo_likelihood_randmlmc, iwelbo_likelihood_sumo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLMC codition check for objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_stats_dIWELBO(x, y, beta0, beta, alpha, mu, sigma, level=1):\n",
    "    # Compute dIWELBO (and IWELBO) for each sample and \n",
    "    # summarize them into several statistics.\n",
    "\n",
    "    N, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    \n",
    "    diwelbos = pointwise_dIWELBO(x, y, z, beta0, beta, alpha, mu, sigma).numpy()\n",
    "    iwelbos = pointwise_IWELBO(x, y, z, beta0, beta, alpha, mu, sigma).numpy()\n",
    "    \n",
    "    return {'mean_dIWELBO':np.mean(diwelbos), \n",
    "            'mean_abs_dIWELBO':np.mean(np.abs(diwelbos)), \n",
    "            'mean_squared_dIWELBO':np.mean(diwelbos**2),\n",
    "            'var_dIWELBO':np.var(diwelbos), \n",
    "            'var_IWELBO':np.var(iwelbos)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp(l):\n",
    "    N0 = 2000000\n",
    "    x,y,_ = generate_data(N=N0//2**l, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, alpha)\n",
    "    return conv_stats_dIWELBO(x, y, beta0, beta, alpha, mu, sigma, level=l)\n",
    "L=13\n",
    "conv_stats = [tmp(l) for l in range(L)]\n",
    "conv_stats = pd.DataFrame(conv_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "plt.plot(conv_stats[['mean_abs_dIWELBO', 'var_dIWELBO', 'var_IWELBO']])\n",
    "\n",
    "# plot O(2^{-l/2}), O(2^{-l}), O(2^{-2l})\n",
    "s,t = conv_stats[['mean_abs_dIWELBO', 'var_dIWELBO']].iloc[0]\n",
    "plt.plot(t*2.**(-np.arange(L)/2), c='grey')\n",
    "plt.plot(t*2.**(-np.arange(L)), c='grey')\n",
    "plt.plot(t*2.**(-np.arange(L)*2), c='grey')\n",
    "\n",
    "plt.legend([r'$\\mathrm{E} | \\Delta \\mathrm{IW}$-$\\mathrm{ELBO}|$', \n",
    "            r'$\\mathrm{Var}[\\Delta \\mathrm{IW}$-$\\mathrm{ELBO}]$', \n",
    "            r'$\\mathrm{Var}[\\mathrm{IW}$-$\\mathrm{ELBO}]$',\n",
    "            r'$O(2^{-\\ell/2}), O(2^{-\\ell}), O(2^{-2\\ell})$'])\n",
    "plt.xlabel('Level')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cost-variance efficiency of MLMC \n",
    "C = [1 if l==0 else 2**(l+1) for l in range(L)]\n",
    "V = conv_stats['var_dIWELBO']\n",
    "N = np.sqrt(V/C)\n",
    "cost_mlmc = [np.sum([np.sqrt(c*v) for c,v in zip(C[:l+1], V[:l+1])])**2  for l in range(L)]\n",
    "cost_nmc = [2**l * v for l,v in enumerate(conv_stats['var_IWELBO'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,4])\n",
    "# plot theoretical computational efficiency\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(cost_mlmc)\n",
    "plt.plot(cost_nmc)\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Variance per Reciprocal Complexity')\n",
    "plt.xlabel('level')\n",
    "plt.legend(['MLMC', 'Nested MC'])\n",
    "# plot N_l's for MLMC\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(N)\n",
    "plt.yscale('log')\n",
    "plt.ylabel(r'$N_l$')\n",
    "plt.xlabel('level')\n",
    "print('(Theoretical) Variance per Reciprocal Complexity and N_l\\'s for MLMC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLMC codition check for gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_stats_grad_dIWELBO(x, y, beta0, beta, alpha, mu, sigma, level=1):\n",
    "    # Compute the gradient of dIWELBO (and IWELBO) for each sample and \n",
    "    # summarize them into several statistics.\n",
    "\n",
    "    N, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N]).T\n",
    "    \n",
    "    param = tf.concat([beta, [beta0], [alpha]], axis=0)\n",
    "    param = tf.Variable(param, dtype=tf.float64)\n",
    "    params = tf.reshape(param, [1,D+2]) * np.ones([N,1])\n",
    "\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, alpha)        \n",
    "    \n",
    "    # Define a gradient function to be vectorized (vectorization for better performance)\n",
    "    def get_grad(args):\n",
    "        # get gradient of dIWELBO (and IWELBO) given one sample\n",
    "        param, x_, y_, z_, mu, sigma = args\n",
    "        z_ = tf.reshape(z_, [-1,1])\n",
    "        with tf.GradientTape(persistent=True) as g:\n",
    "            g.watch(param)\n",
    "            beta_ = param[0,:D]\n",
    "            beta0_ = param[0,D]\n",
    "            alpha_ = param[0,D+1]\n",
    "            diwelbos = pointwise_dIWELBO(x_, y_, z_, beta0_, beta_, alpha_, mu, sigma)\n",
    "            iwelbos = pointwise_IWELBO(x_, y_, z_, beta0_, beta_, alpha_, mu, sigma)    \n",
    "        a = g.gradient(diwelbos, param)\n",
    "        b = g.gradient(iwelbos, param)\n",
    "        del g\n",
    "        return a,b\n",
    "    \n",
    "    # Compute the gradient of dIWELBO (and IWELBO) for each sample\n",
    "    args = [tf.expand_dims(arg, axis=1) for arg in [params, x, y, z, mu, sigma]]\n",
    "    grads = tf.vectorized_map(get_grad, args)\n",
    "    \n",
    "    grad_diwelbos = tf.squeeze(grads[0])#[:D+1]\n",
    "    grad_iwelbos = tf.squeeze(grads[1])#[:D+1]\n",
    "    \n",
    "    # return summary statistics of the gradients\n",
    "    return {'norm_mean_grad_dIWELBO': np.linalg.norm(np.mean(grad_diwelbos, axis=0)), \n",
    "            'mean_norm_grad_dIWELBO': np.mean(np.linalg.norm(grad_diwelbos, axis=1)), \n",
    "            'mean_squared_norm_grad_dIWELBO': np.mean(np.linalg.norm(grad_diwelbos, axis=1)**2),\n",
    "            'trace_covariance_grad_dIWELBO': np.sum(np.var(grad_diwelbos, axis=0)), \n",
    "            'trace_covariance_grad_IWELBO': np.sum(np.var(grad_iwelbos, axis=0))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp(l):\n",
    "    N0 = 2000000\n",
    "    x,y,_ = generate_data(N=N0//2**l, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, alpha)\n",
    "    return conv_stats_grad_dIWELBO(x, y, beta0, beta, alpha, mu, sigma, level=l)\n",
    "L=13\n",
    "conv_stats = [tmp(l) for l in range(L)]\n",
    "conv_stats = pd.DataFrame(conv_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot results\n",
    "plt.plot(conv_stats[['norm_mean_grad_dIWELBO', 'trace_covariance_grad_dIWELBO', 'trace_covariance_grad_IWELBO']])\n",
    "\n",
    "# plot O(2^{-l/2}), O(2^{-l}), O(2^{-2l})\n",
    "s,t = conv_stats[['norm_mean_grad_dIWELBO', 'trace_covariance_grad_dIWELBO']].iloc[0]\n",
    "plt.plot(t*2.**(-np.arange(L)/2), c='grey')\n",
    "plt.plot(t*2.**(-np.arange(L)), c='grey')\n",
    "plt.plot(t*2.**(-np.arange(L)*2), c='grey')\n",
    "\n",
    "plt.legend([r'$||\\mathrm{E} [\\nabla (\\Delta \\mathrm{IW}$-$\\mathrm{ELBO})]||_2$', \n",
    "            r'$\\mathrm{tr}(\\mathrm{Cov}[\\nabla(\\Delta \\mathrm{IW}$-$\\mathrm{ELBO})])$', \n",
    "            r'$\\mathrm{tr}(\\mathrm{Cov}[\\nabla(\\mathrm{IW}$-$\\mathrm{ELBO})])$',\n",
    "            r'$O(2^{-\\ell/2}), O(2^{-\\ell}), O(2^{-2\\ell})$'])\n",
    "plt.xlabel('Level')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cost-variance efficiency of MLMC \n",
    "C = [1 if l==0 else 2**(l+1) for l in range(L)]\n",
    "V = conv_stats['trace_covariance_grad_dIWELBO']\n",
    "N = np.sqrt(V/C)\n",
    "cost_mlmc = [np.sum([np.sqrt(c*v) for c,v in zip(C[:l+1], V[:l+1])])**2  for l in range(L)]\n",
    "cost_nmc = [2**l * v for l,v in enumerate(conv_stats['trace_covariance_grad_IWELBO'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,4])\n",
    "# plot theoretical computational efficiency\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(cost_mlmc)\n",
    "plt.plot(cost_nmc)\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Variance per Reciprocal Complexity')\n",
    "plt.xlabel('level')\n",
    "plt.legend(['MLMC', 'Nested MC'])\n",
    "# plot N_l's for MLMC\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(N)\n",
    "plt.yscale('log')\n",
    "plt.ylabel(r'$N_l$')\n",
    "plt.xlabel('level')\n",
    "print('(Theoretical) Variance per Reciprocal Complexity and N_l\\'s for MLMC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_stats_dSUMO(x, y, beta0, beta, alpha, mu, sigma, level=1):\n",
    "    # Compute dIWELBO (and IWELBO) for each sample and \n",
    "    # summarize them into several statistics.\n",
    "\n",
    "    N, = mu.shape\n",
    "    n_MC = 2**level\n",
    "    z = norm(loc=mu, scale=sigma).rvs([n_MC, N])\n",
    "    \n",
    "    dsumos = 0\n",
    "    dsumos += pointwise_IWELBO(x, y, z[ :,:], beta0, beta, alpha, mu, sigma).numpy()\n",
    "    dsumos -= pointwise_IWELBO(x, y, z[1:,:], beta0, beta, alpha, mu, sigma).numpy()\n",
    "    \n",
    "    dN = N//10\n",
    "    var_sumos = dN * np.var([\n",
    "        IWELBO_SUMO(\n",
    "            x[dN*i:dN*(i+1)], y[dN*i:dN*(i+1)], beta0, beta, alpha,\n",
    "            mu[dN*i:dN*(i+1)], sigma[dN*i:dN*(i+1)], K_max=2**level\n",
    "            ) \n",
    "        for i in range(10)])\n",
    "    \n",
    "    return {'mean_dSUMO':np.mean(dsumos), \n",
    "            'mean_abs_dSUMO':np.mean(np.abs(dsumos)), \n",
    "            'mean_squared_dSUMO':np.mean(dsumos**2),\n",
    "            'var_dSUMO':np.var(dsumos),\n",
    "            'var_SUMO':var_sumos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp(l):\n",
    "    N0 = 2000000\n",
    "    x,y,_ = generate_data(N=N0//2**l, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, alpha)\n",
    "    return conv_stats_dSUMO(x, y, beta0, beta, alpha, mu, sigma, level=l)\n",
    "L=13\n",
    "conv_stats = [tmp(l) for l in range(L)]\n",
    "conv_stats = pd.DataFrame(conv_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "plt.plot(conv_stats[['mean_abs_dSUMO', 'var_dSUMO', 'var_SUMO']])\n",
    "\n",
    "# plot O(2^{-l/2}), O(2^{-l}), O(2^{-2l})\n",
    "s,t = conv_stats[['mean_abs_dSUMO', 'var_dSUMO']].iloc[1]\n",
    "plt.plot(s*2.**(-np.arange(L)), c='grey')\n",
    "plt.plot(t*2.**(-np.arange(L)*2), c='grey')\n",
    "\n",
    "plt.legend([r'$\\mathrm{E}  |\\Delta^{\\mathrm{SUMO}}_{2^{\\ell}}|$', \n",
    "            r'$\\mathrm{Var}[\\Delta^{\\mathrm{SUMO}}_{2^{\\ell}}]$', \n",
    "            r'$\\mathrm{Var}[\\mathrm{SUMO}_{2^{\\ell}}]$', \n",
    "            r'$O(2^{-\\ell}), O(2^{-2\\ell})$'])\n",
    "plt.xlabel('Level')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost comparison of objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 13\n",
    "objectives = {\n",
    "    'NMC':      lambda x,y,mu,sigma,level: IWELBO(x, y, beta0, beta, alpha, mu, sigma, n_MC=2**level),\n",
    "    'MLMC':     lambda x,y,mu,sigma,level: IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=level, w0=0.99, b=1.8, randomize=False),\n",
    "    'RandMLMC': lambda x,y,mu,sigma,level: IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=level, w0=0.99, b=1.8, randomize=True),\n",
    "    'SUMO':     lambda x,y,mu,sigma,level: IWELBO_SUMO(x, y, beta0, beta, alpha, mu, sigma, K_max=2**level)\n",
    "}\n",
    "results = {'NMC':[], 'MLMC':[], 'RandMLMC':[], 'SUMO':[]}\n",
    "runtime = {'NMC':[], 'MLMC':[], 'RandMLMC':[], 'SUMO':[]}\n",
    "\n",
    "for name, obj in objectives.items():\n",
    "    \n",
    "    # evaluate variance\n",
    "    for i in range(100):\n",
    "        results[name].append([])\n",
    "        x,y,_ = generate_data(N=4000, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "        mu, sigma = laplace_approx(x, y, beta0, beta, alpha)\n",
    "        for level in range(L):\n",
    "            results[name][i].append( obj(x,y,mu,sigma,level).numpy() )\n",
    "    \n",
    "    # evaluate runtime\n",
    "    x,y,_ = generate_data(N=20000, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, alpha)    \n",
    "    for level in range(L):\n",
    "        if level>10 and name=='NMC':\n",
    "            start = time.time()\n",
    "            obj(*[vec[:200] for vec in [x,y,mu,sigma]], level)\n",
    "            end = time.time()\n",
    "            runtime[name].append((end - start)*100)\n",
    "        else:\n",
    "            start = time.time()\n",
    "            obj(x,y,mu,sigma,level)\n",
    "            end = time.time()\n",
    "            runtime[name].append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ests, rtime in zip(results.values(), runtime.values()):\n",
    "    var_per_recip_runtime = np.array(ests).var(axis=0) * np.array(rtime)\n",
    "    plt.plot(var_per_recip_runtime)\n",
    "plt.legend([name for name in results.keys()])\n",
    "plt.xlabel('Level')\n",
    "plt.ylabel('Variance per Reciprocal Runtime')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance per \"reciprocal of the runtime\" is considered because the varince is propotional to the  \"reciprocal of the runtime\". As we increase the computational complexity (runtime), the decrease in varince is inversely propotional to the complexity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost comparison of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 13\n",
    "objectives = {\n",
    "    'NMC':      lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO(x, y, beta0, beta, alpha, mu, sigma, n_MC=2**level),\n",
    "    'MLMC':     lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=level, w0=0.99, b=1.8, randomize=False),\n",
    "    'RandMLMC': lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=level, w0=0.99, b=1.8, randomize=True),\n",
    "    'SUMO':     lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO_SUMO(x, y, beta0, beta, alpha, mu, sigma, K_max=2**level)\n",
    "}\n",
    "\n",
    "def d(f):\n",
    "    # return the derivative of f\n",
    "    # returned value is a function\n",
    "    def df(x,y,mu,sigma,level):\n",
    "        param = tf.concat([beta, [beta0], [alpha]], axis=0)\n",
    "        param = tf.Variable(param, dtype=tf.float64)\n",
    "        with tf.GradientTape(persistent=True) as g:\n",
    "            g.watch(param)\n",
    "            beta_ = param[:D]\n",
    "            beta0_ = param[D]\n",
    "            alpha_ = param[D+1]\n",
    "            target = f(x,y,beta0_,beta_,alpha_,mu,sigma,level)\n",
    "        est = g.gradient(target, param)\n",
    "        return est\n",
    "    return df\n",
    "\n",
    "results = {'NMC':[], 'MLMC':[], 'RandMLMC':[], 'SUMO':[]}\n",
    "runtime = {'NMC':[], 'MLMC':[], 'RandMLMC':[], 'SUMO':[]}\n",
    "\n",
    "for name, obj in objectives.items():\n",
    "    \n",
    "    # evaluate variance\n",
    "    for i in range(100):\n",
    "        results[name].append([])\n",
    "        x,y,_ = generate_data(N=4000, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "        mu, sigma = laplace_approx(x, y, beta0, beta, alpha)\n",
    "        for level in range(L):\n",
    "            results[name][i].append( d(obj)(x,y,mu,sigma,level).numpy() )\n",
    "    \n",
    "    # evaluate runtime\n",
    "    x,y,_ = generate_data(N=20000, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, alpha)    \n",
    "    for level in range(L):\n",
    "        # Avoid the memery runout by \n",
    "        # manipulating the case of NMC with large n_MC (large level)\n",
    "        if level>10 and name=='NMC':\n",
    "            start = time.time()\n",
    "            d(obj)(*[vec[:200] for vec in [x,y,mu,sigma]], level)\n",
    "            end = time.time()\n",
    "            runtime[name].append((end - start)*100)\n",
    "        else:\n",
    "            start = time.time()\n",
    "            d(obj)(x,y,mu,sigma,level)\n",
    "            end = time.time()\n",
    "            runtime[name].append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ests, rtime in zip(results.values(), runtime.values()):\n",
    "    var_per_recip_runtime = np.array(ests).var(axis=0).sum(axis=1) * np.array(rtime)\n",
    "    plt.plot(var_per_recip_runtime)\n",
    "plt.legend([name for name in results.keys()])\n",
    "plt.xlabel('Level')\n",
    "plt.ylabel(r'Variance ( tr(Cov) ) per Reciprocal Runtime')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 13\n",
    "objectives = {\n",
    "    'NMC':      lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO(x, y, beta0, beta, alpha, mu, sigma, n_MC=2**level),\n",
    "    'MLMC':     lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=level, w0=0.98, b=1.8, randomize=False),\n",
    "    'RandMLMC': lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=level, w0=0.98, b=1.8, randomize=True),\n",
    "    'SUMO':     lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO_SUMO(x, y, beta0, beta, alpha, mu, sigma, K_max=2**level)\n",
    "}\n",
    "\n",
    "def d(f):\n",
    "    # return the derivative of f\n",
    "    # returned value is a function\n",
    "    def df(x,y,mu,sigma,level):\n",
    "        param = tf.concat([beta, [beta0], [alpha]], axis=0)\n",
    "        param = tf.Variable(param, dtype=tf.float64)\n",
    "        with tf.GradientTape(persistent=True) as g:\n",
    "            g.watch(param)\n",
    "            beta_ = param[:D]\n",
    "            beta0_ = param[D]\n",
    "            alpha_ = param[D+1]\n",
    "            target = f(x,y,beta0_,beta_,alpha_,mu,sigma,level)\n",
    "        est = g.gradient(target, param)\n",
    "        return est\n",
    "    return df\n",
    "\n",
    "results = {'NMC':[], 'MLMC':[], 'RandMLMC':[], 'SUMO':[]}\n",
    "runtime = {'NMC':[], 'MLMC':[], 'RandMLMC':[], 'SUMO':[]}\n",
    "\n",
    "for name, obj in objectives.items():\n",
    "    \n",
    "    # evaluate variance\n",
    "    for i in range(100):\n",
    "        results[name].append([])\n",
    "        x,y,_ = generate_data(N=4000, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "        mu, sigma = laplace_approx(x, y, beta0, beta, alpha)\n",
    "        for level in range(L):\n",
    "            results[name][i].append( d(obj)(x,y,mu,sigma,level).numpy() )\n",
    "    \n",
    "    # evaluate runtime\n",
    "    x,y,_ = generate_data(N=20000, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, alpha)    \n",
    "    for level in range(L):\n",
    "        # Avoid the memery runout by \n",
    "        # manipulating the case of NMC with large n_MC (large level)\n",
    "        if level>10 and name=='NMC':\n",
    "            start = time.time()\n",
    "            d(obj)(*[vec[:200] for vec in [x,y,mu,sigma]], level)\n",
    "            end = time.time()\n",
    "            runtime[name].append((end - start)*100)\n",
    "        else:\n",
    "            start = time.time()\n",
    "            d(obj)(x,y,mu,sigma,level)\n",
    "            end = time.time()\n",
    "            runtime[name].append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ests, rtime in zip(results.values(), runtime.values()):\n",
    "    var_per_recip_runtime = np.array(ests).var(axis=0).sum(axis=1) * np.array(rtime)\n",
    "    plt.plot(var_per_recip_runtime)\n",
    "plt.legend([name for name in results.keys()])\n",
    "plt.xlabel('Level')\n",
    "plt.ylabel(r'Variance ( tr(Cov) ) per Reciprocal Runtime')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 13\n",
    "objectives = {\n",
    "    'NMC':      lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO(x, y, beta0, beta, alpha, mu, sigma, n_MC=2**level),\n",
    "    'MLMC':     lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=level, w0=0.95, b=1.8, randomize=False),\n",
    "    'RandMLMC': lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=level, w0=0.95, b=1.8, randomize=True),\n",
    "    'SUMO':     lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO_SUMO(x, y, beta0, beta, alpha, mu, sigma, K_max=2**level)\n",
    "}\n",
    "\n",
    "def d(f):\n",
    "    # return the derivative of f\n",
    "    # returned value is a function\n",
    "    def df(x,y,mu,sigma,level):\n",
    "        param = tf.concat([beta, [beta0], [alpha]], axis=0)\n",
    "        param = tf.Variable(param, dtype=tf.float64)\n",
    "        with tf.GradientTape(persistent=True) as g:\n",
    "            g.watch(param)\n",
    "            beta_ = param[:D]\n",
    "            beta0_ = param[D]\n",
    "            alpha_ = param[D+1]\n",
    "            target = f(x,y,beta0_,beta_,alpha_,mu,sigma,level)\n",
    "        est = g.gradient(target, param)\n",
    "        return est\n",
    "    return df\n",
    "\n",
    "results = {'NMC':[], 'MLMC':[], 'RandMLMC':[], 'SUMO':[]}\n",
    "runtime = {'NMC':[], 'MLMC':[], 'RandMLMC':[], 'SUMO':[]}\n",
    "\n",
    "for name, obj in objectives.items():\n",
    "    \n",
    "    # evaluate variance\n",
    "    for i in range(100):\n",
    "        results[name].append([])\n",
    "        x,y,_ = generate_data(N=4000, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "        mu, sigma = laplace_approx(x, y, beta0, beta, alpha)\n",
    "        for level in range(L):\n",
    "            results[name][i].append( d(obj)(x,y,mu,sigma,level).numpy() )\n",
    "    \n",
    "    # evaluate runtime\n",
    "    x,y,_ = generate_data(N=20000, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, alpha)    \n",
    "    for level in range(L):\n",
    "        # Avoid the memery runout by \n",
    "        # manipulating the case of NMC with large n_MC (large level)\n",
    "        if level>10 and name=='NMC':\n",
    "            start = time.time()\n",
    "            d(obj)(*[vec[:200] for vec in [x,y,mu,sigma]], level)\n",
    "            end = time.time()\n",
    "            runtime[name].append((end - start)*100)\n",
    "        else:\n",
    "            start = time.time()\n",
    "            d(obj)(x,y,mu,sigma,level)\n",
    "            end = time.time()\n",
    "            runtime[name].append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ests, rtime in zip(results.values(), runtime.values()):\n",
    "    var_per_recip_runtime = np.array(ests).var(axis=0).sum(axis=1) * np.array(rtime)\n",
    "    plt.plot(var_per_recip_runtime)\n",
    "plt.legend([name for name in results.keys()])\n",
    "plt.xlabel('Level')\n",
    "plt.ylabel(r'Variance ( tr(Cov) ) per Reciprocal Runtime')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 13\n",
    "objectives = {\n",
    "    'NMC':      lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO(x, y, beta0, beta, alpha, mu, sigma, n_MC=2**level),\n",
    "    'MLMC':     lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=level, w0=0.90, b=1.8, randomize=False),\n",
    "    'RandMLMC': lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=level, w0=0.90, b=1.8, randomize=True),\n",
    "    'SUMO':     lambda x,y,beta0,beta,alpha,mu,sigma,level: IWELBO_SUMO(x, y, beta0, beta, alpha, mu, sigma, K_max=2**level)\n",
    "}\n",
    "\n",
    "def d(f):\n",
    "    # return the derivative of f\n",
    "    # returned value is a function\n",
    "    def df(x,y,mu,sigma,level):\n",
    "        param = tf.concat([beta, [beta0], [alpha]], axis=0)\n",
    "        param = tf.Variable(param, dtype=tf.float64)\n",
    "        with tf.GradientTape(persistent=True) as g:\n",
    "            g.watch(param)\n",
    "            beta_ = param[:D]\n",
    "            beta0_ = param[D]\n",
    "            alpha_ = param[D+1]\n",
    "            target = f(x,y,beta0_,beta_,alpha_,mu,sigma,level)\n",
    "        est = g.gradient(target, param)\n",
    "        return est\n",
    "    return df\n",
    "\n",
    "results = {'NMC':[], 'MLMC':[], 'RandMLMC':[], 'SUMO':[]}\n",
    "runtime = {'NMC':[], 'MLMC':[], 'RandMLMC':[], 'SUMO':[]}\n",
    "\n",
    "for name, obj in objectives.items():\n",
    "    \n",
    "    # evaluate variance\n",
    "    for i in range(100):\n",
    "        results[name].append([])\n",
    "        x,y,_ = generate_data(N=4000, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "        mu, sigma = laplace_approx(x, y, beta0, beta, alpha)\n",
    "        for level in range(L):\n",
    "            results[name][i].append( d(obj)(x,y,mu,sigma,level).numpy() )\n",
    "    \n",
    "    # evaluate runtime\n",
    "    x,y,_ = generate_data(N=20000, D=3, T=2, beta0=beta0, beta=beta, alpha=alpha)\n",
    "    mu, sigma = laplace_approx(x, y, beta0, beta, alpha)    \n",
    "    for level in range(L):\n",
    "        # Avoid the memery runout by \n",
    "        # manipulating the case of NMC with large n_MC (large level)\n",
    "        if level>10 and name=='NMC':\n",
    "            start = time.time()\n",
    "            d(obj)(*[vec[:200] for vec in [x,y,mu,sigma]], level)\n",
    "            end = time.time()\n",
    "            runtime[name].append((end - start)*100)\n",
    "        else:\n",
    "            start = time.time()\n",
    "            d(obj)(x,y,mu,sigma,level)\n",
    "            end = time.time()\n",
    "            runtime[name].append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ests, rtime in zip(results.values(), runtime.values()):\n",
    "    var_per_recip_runtime = np.array(ests).var(axis=0).sum(axis=1) * np.array(rtime)\n",
    "    plt.plot(var_per_recip_runtime)\n",
    "plt.legend([name for name in results.keys()])\n",
    "plt.xlabel('Level')\n",
    "plt.ylabel(r'Variance ( tr(Cov) ) per Reciprocal Runtime')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood by Different Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlmc_cost(N, max_level, b, w0):\n",
    "    # compute the cost of MLMC estimation \n",
    "    # when the size of x (and that of y) is N\n",
    "    if max_level==0:\n",
    "        levels = np.array([0])\n",
    "        weights = np.array([1.])\n",
    "    else:\n",
    "        weights = 2.**(-(b+1)/2*np.arange(max_level))\n",
    "        weights /= sum(weights)\n",
    "        weights = np.concatenate([[w0], (1-w0)*weights])\n",
    "        levels = np.arange(max_level+1)\n",
    "    cost = np.ceil(N * weights[0])\\\n",
    "            + N * sum( np.ceil(weights[1:] * (2**levels[1:] + 2**(levels[1:]-1))) )\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives = {\n",
    "    \"signorm\":   lambda x, y, beta0, beta, alpha, mu, sigma: sigmoid_normal_likelihood(x, y, beta0, beta, alpha),\n",
    "    \"elbo\":      lambda x, y, beta0, beta, alpha, mu, sigma: IWELBO(x, y, beta0, beta, alpha, mu, sigma, n_MC=1),\n",
    "    \"iwelbo8\":   lambda x, y, beta0, beta, alpha, mu, sigma: IWELBO(x, y, beta0, beta, alpha, mu, sigma, n_MC=8),\n",
    "    \"iwelbo64\":  lambda x, y, beta0, beta, alpha, mu, sigma: IWELBO(x, y, beta0, beta, alpha, mu, sigma, n_MC=64),\n",
    "    \"iwelbo512\": lambda x, y, beta0, beta, alpha, mu, sigma: IWELBO(x, y, beta0, beta, alpha, mu, sigma, n_MC=512),\n",
    "    \"iwelbo512_mlmc\": lambda x, y, beta0, beta, alpha, mu, sigma: IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=9, w0=0.90, b=1.8, randomize=False),\n",
    "    \"iwelbo512_randmlmc\": lambda x, y, beta0, beta, alpha, mu, sigma: IWELBO_MLMC(x, y, beta0, beta, alpha, mu, sigma, max_level=9, w0=0.90, b=1.8, randomize=True),\n",
    "    \"iwelbo512_sumo\": lambda x, y, beta0, beta, alpha, mu, sigma: IWELBO_SUMO(x, y, beta0, beta, alpha, mu, sigma, K_max=512),\n",
    "\n",
    "}\n",
    "N,T,D = (1000, 2, 3) if tf.test.is_gpu_available() else (200, 2, 3)\n",
    "\n",
    "n_repeat = 10\n",
    "params_repeated = {name:[] for name in objectives.keys()}\n",
    "\n",
    "for name, obj in objectives.items():\n",
    "    alpha_s = []\n",
    "    beta0_s = []\n",
    "    beta_s = []\n",
    "    for i in range(n_repeat):\n",
    "        print(\"training {}.... #iter:{} \".format(name,i))\n",
    "\n",
    "        beta0_ = tf.Variable(0., dtype=tf.float64)\n",
    "        beta_  = tf.Variable(np.zeros([D]), dtype=tf.float64)\n",
    "        alpha_   = tf.Variable(1., dtype=tf.float64)\n",
    "\n",
    "        # Gradient Descent\n",
    "        for t in range(2001):\n",
    "\n",
    "            rho_t = 0.5/(1+t)**0.7\n",
    "            x,y,_ = generate_data(N, D, T, beta0, beta, alpha)\n",
    "            # balance the cost of mlmc and nmc when level=9 (n_MC=512)\n",
    "            if 'mlmc' in name:\n",
    "                cost_nmc  = N * 2**9\n",
    "                cost_mlmc = get_mlmc_cost(N, max_level=9, b=1.8, w0=0.9)\n",
    "                N_mlmc = np.math.ceil(N * (cost_nmc / cost_mlmc))\n",
    "                x,y,_ = generate_data(N_mlmc, D, T, beta0, beta, alpha)    \n",
    "\n",
    "            with tf.GradientTape() as g:\n",
    "                g.watch([beta0_, beta_, alpha_])\n",
    "                mu, sigma = laplace_approx(x, y, beta0_.numpy(), beta_.numpy(), alpha_.numpy())\n",
    "                score = obj(x, y, beta0_, beta_, alpha_, mu, sigma)\n",
    "            dbeta0_, dbeta_, dalpha_ = g.gradient(score, [beta0_, beta_, alpha_])\n",
    "\n",
    "            beta0_ = beta0_ + rho_t*dbeta0_\n",
    "            beta_ = beta_ + rho_t*dbeta_\n",
    "            alpha_ = alpha_ + dalpha_\n",
    "            if t%200==0 and i==0:\n",
    "                print(\"#iter: {},\\tloss: {}\".format(t, -score.numpy()))\n",
    "        alpha_s.append(alpha_.numpy())\n",
    "        beta0_s.append(beta0_.numpy())\n",
    "        beta_s.append(beta_.numpy())\n",
    "    print()\n",
    "    params_repeated[name] = {\n",
    "            'alpha': np.array(alpha_s),\n",
    "            'beta0': np.array(beta0_s),\n",
    "            'beta': np.array(beta_s)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def expand(key, val):\n",
    "    # expand {\"name\":array([1,2,3,4,5])}\n",
    "    # into {\"name1\":1, \"name2\":2, ..., \"name5\":5}\n",
    "    if type(val)==np.ndarray:\n",
    "        return {key+str(i+1): x for i,x in enumerate(val)} \n",
    "    else:\n",
    "        return {key:val} \n",
    "\n",
    "def expand_param(param):\n",
    "    expanded_param = {}\n",
    "    for key, val in param.items():\n",
    "        expanded_param.update(expand(key,val))\n",
    "    return expanded_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'ground_truth': expand_param(param0)}\n",
    "params['ground_truth'].update({'MSE':0})\n",
    "for name in objectives.keys():\n",
    "    param_repeated = params_repeated[name]\n",
    "    param_mean   = expand_param({name: array.mean(axis=0) for name, array in  param_repeated.items()})\n",
    "    param_var = expand_param({name: array.std(axis=0) for name, array in  param_repeated.items()})\n",
    "    param = {name_:'{:.5f}  {:.5f}'.format(mean,var**(1/2.)) \n",
    "             for name_, mean, var \n",
    "             in zip( param_mean.keys(), param_mean.values(), param_var.values() )}\n",
    "    error = [var+(mean-true_mean)**2 \n",
    "             for var, mean, true_mean \n",
    "             in zip( param_var.values(), param_mean.values(), params['ground_truth'].values() )]\n",
    "    MSE = sum(error)\n",
    "    param.update({'MSE':MSE})\n",
    "    params.update({name :param})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(params).T\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../out/random_effect_logistic_regression/MLE_error_{}.csv'.format(timestamp()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottom Line: \n",
    "- IWELBO with large number of inner MC samples gives better estiamte than ELBO or sigmoid normal integral approximation, even for this simple model. \n",
    "- MLMC is more effective than nested MC when used for maximum likelihood estimation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
